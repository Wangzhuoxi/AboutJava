# 1 布隆过滤器

**题目**

不安全的网页的黑名单包含100亿个黑名单网页，每个网页的URL最多占用64B。现在想要实现一种网页过滤系统，可以根据网页的URL判断该网页是否在黑名单上，请设计该系统。

**要求**

1. 该系统允许有万分之一以下的判断失误率。
2. 使用的额外空间不要超过30GB。

**解法**

如果把黑名单中所有的URL通过数据库或者哈希表存下来，就可以对每条URL进行查询，但是每个URL有64B，数量是100亿个，所以至少需要640GB的空间，不满足要求2。

布隆过滤器适用于网页黑名单系统、垃圾邮件过滤系统、爬虫的网址判重系统等题目。

一个布隆过滤器精确的代表一个集合，并可以精确的判断一个元素是否在集合中，注意不能做到完全正确。

**哈希函数**

哈希函数的输入域可以是非常大的范围，但是输出域是固定的范围，假设是S，并具有如下性质：

1. 典型的哈希函数都是有无限的输入域。
2. 当给哈希函数传入相同的输入值时，返回值一样。
3. 当给哈希函数传入不同的输入值时，返回值可能一样，也可能不一样。
4. 最重要的性质是很多不同的输入值所得到的返回值会均匀地分布在S上。

如果一个优秀的哈希函数能够做到很多不同的输入值所得到的返回值非常均匀的分布在S上，那么将所有的返回值对m取余(%m)，可以认为所有的返回值也会均匀的分布在0~m-1的空间上。

**布隆过滤器**

假设一个长度为m的bit类型的数组，再假设一共有k个哈希函数，这些函数的输出域都大于等于m，并且这些函数彼此独立。那么对同一个输入对象（假设是一个字符串URL），经过k个函数算出来的结果也是互相独立的，对算出来的结果都对m取余，然后在bit数组上相应的位置设置为1。

至此，一个输入对象对bitMap的影响过程就结束了，接下来按照该方法处理所有的输入对象，如果某些位置已经变为1则不变即可，每个对象都将bitMap中的一些位置置为1，至此，一个布隆过滤器生成完毕，代表之前所有的输入对象组成的集合。

检查阶段：假设一个对象为a，想检查它是否是之前的输入对象，就把a通过k个哈希函数算出k个值，然后把k个值取余，就得到在[0，m-1]范围上的k个值，接下来看在bitMap中这些位置是否都为1。如果有一个不为1，则a一定不在集合里，如果都为1，说明a在集合里，但可能有误判。bit数组空间越大，误判越少。

**参数设定**

比特数组大小m（其中n代表样本量，P代表预测失误率）
$$
m = - \frac{n\cdot lnP}{(ln2)^{2}}
$$
哈希函数的个数k
$$
k = ln2\cdot \frac{m}{n}
$$
真实失误率P‘（其中m、k经过取整操作）
$$
p' = (1-e^{-\frac{n\cdot k}{m}})^{k}
$$


# 2 只用2GB内存在20亿个整数中找到出现次数最多的数

**题目**

有一个包含20亿个全是32位整数的大文件，在其中找到出现次数最多的数。

**要求**

内存限制为2GB。

**解答**

通常的做法是使用哈希表对出现的每一个数做词频统计，哈希表的key是某一个整数，value是这个数出现的次数。但是本题共20亿个数，哪怕只是一个数出现了20亿次，用32位整数也可以表示其出现的次数而不会溢出，所以哈希表的key需要占用4B，value也是4B，那么哈希表的一条记录需要占用8B，当哈希表的记录数为2亿个时，需要至少1.6GB的内存。但是如果其中不同的数超过2亿种，那么记录数所占的内存就不够用。

解决办法：把包含20亿个数的大文件用哈希函数分成16个小文件，感觉哈希函数的性质，同一种数不可能被哈希到不同的小文件上，同时每个小文件中中不同的数一定不会大于2亿种。

然后对每个小文件用哈希表来统计其中每种数出现的次数，这样就得到了16个小文件种各自出现次数最多的数，还有各自的次数统计，接下来只要选出16个小文件各自的第一名种谁出现的次数最多即可。

把一个大的集合通过哈希函数分配到多台机器中，或者分配到多个文件里，是处理大数据面试题的常用技巧之一。



# 3 40亿个非负整数中找到没出现的数

**题目**

32位无符号整数的范围是0~4294967295（42亿），现在有一个正好包含40亿个无符号整数的文件，所以在整个范围中必然有没出现过的数。可以使用最多1GB的内存，怎么找到所有没出现过的数？

**进阶**

内存限制位10MB，但是只要找到一个没出现过的数即可。

**解答**

**1 原问题**

如果用哈希表保存，那么如果40亿个数都不同，则哈希表的记录为40亿条，存一个32位整数需要4B，所以最差情况需要40亿 x 4B = 160亿字节，大约需要16GB的空间，不符合要求。

解决方法是使用 bitMap 的方式，申请一个4294967295的bit类型的数组 bitArr，bitArr的每个位置只能是0或1。8个bit为1B，所以长度为4294967295的bit类型的数组占用500MB的空间。

遍历这40亿个无符号数，遇到所有的数时，就把bitArr相应的位置置为1。

然后再次遍历bitArr，哪个位置的值没有被置为1，哪个数就不在40亿个数中。

**2 进阶问题**

首先把0~4294967295这个范围平均分成64个区间，每个区间是67108864个数，因为一共只有40亿个数，所以如果统计落在每个区间上的数有多少，肯定有至少一个区间上的计数少于67108864，利用这点可以找到其中一个没有出现过的数。

具体过程如下：

1. 第一次遍历，申请长度为64的整型数组countArr[0...63]，用来统计区间i上的数有多少。
2. 遍历完40亿个数之后遍历countArr，必然有某一个位置上的值小于67108864，表示在区间i上至少有一个数没出现过，此时使用的内存就是countArr的大小（64x4B）。
3. 针对某个计数小于67108864的区间i，进行第二次遍历。
4. 申请长度为67108864的bit map，这占用大约8MB的空间，记位bitArr。
5. 再遍历一次40亿个数，此时只关注落在区间i上的数，记位num。
6. 如果num在区间i上，将bitArr[num-67108864*i)]的值设置为1，也就是只做区间i上的数的bitArr映射。
7. 遍历完后，在bitArr上必然存在没有被设置为1的位置，那么对应的数就是没出现过的数。

总结如下：

1. 根据10MB的内存限制，确定统计区间的大小，就是第二次遍历时的bitArr大小。
2. 利用区间计数的方式，找到那个计数不足的区间，这个区间上肯定有没出现的数。
3. 对这个区间上的数做bit map映射，再遍历bit map，找到一个没出现的数即可。



# 4 找到100亿个URL中重复的URL以及搜索词汇的top K问题

**题目**

有一个包含100亿个URL的大文件，假设每个URL占用64B，请找出其中所有重复的URL。

**解答**

解决方法：把大文件通过哈希函数分配到机器，或者通过哈希函数把大文件拆成小文件。一直进行这种划分，直到划分的结果满足资源限制的要求。

例如：将100亿字节的大文件通过哈希函数分配到100台机器上，然后每一台机器分别统计分给自己的URL中是否有重复的URL，同时哈希函数的性质决定了同一条URL不可能分别不同的机器；或者在单机上将大文件通过哈希函数拆成1000个小文件，对每一个小文件再利用哈希表遍历，找到重复的URL；或者在分给机器或拆成文件之后进行排序，排序之后再看是否有重复的URL出现。

**补充问题**

某搜索公司一天的用户搜索词汇是海量的（百亿数据量），请设计一种求出每天最热top 100词汇的可行方法。

**解答**

还是用哈希分流的思路。

1. 把百亿数据量的词汇文件分流到不同的机器上，对每台机器来说，如果分到的文件依然很大，可以再用哈希函数把每台机器的分流文件拆成更小的文件处理。
2. 处理每个小文件时，哈希表统计每种词及其词频。
3. 哈希表建立完成后，再遍历哈希表，遍历的过程使用大小为100的大根堆，按照词频排序得到每个小文件的top 100。
4. 然后把各个小文件的top 100进行外排或者继续使用大根堆，就可以选出每台机器上的top 100。
5. 不同机器之间再利用外排序或者继续使用大根堆最终求出整个百亿数据量种的top 100。



# 5 40亿个非负整数中找到出现两次的数和所有数的中位数

**题目**

32位无符号整数的范围是0~429496295，现在有40亿个无符号整数，可以使用最多1GB的内存，找出所有出现了两次的数。

**解答**

使用bit map的方式来表示数出现的情况。

1. 申请一个长度为4294967295x2的bit类型的数组bitArr，用2个位置表示一个数出现的词频，1B占用8个bit，所以bitArr的数组占用1GB的空间。
2. 遍历这40亿个无符号数，如果初次遇到num，就把bitArr[num\*2 + 1]和bitArr[num\*2]设置为01；如果第二次遇到num，就把bitArr[num\*2 + 1]和bitArr[num\*2]设置为10；如果第三次遇到num，就把bitArr[num\*2 + 1]和bitArr[num\*2]设置为11，以后再遇到num，发现以及被设置为11则不做任何处理。
3. 遍历完成后再依次遍历bitArr，如果发现bitArr[i\*2 + 1]和bitArr[i\*2]设置为10，那么i就是出现了两次的数。

**补充题目**

可以使用最多10MB的内存，怎么找到这40亿个整数的中位数。

**解答**

用分区间的方式处理。

1. 长度为2MB的无符号整型数组占用的空间为8MB，所以将区间的数量定为429496295/2M，向上取整为2148个区间。
2. 申请一个长度为2148的无符号整型数组arr[0...2147]，arr[i]表示第i个区间有多少个数，arr必然小于10MB。
3. 遍历40亿个数，如果遍历到当前数num，先看num落在哪个区间上（num/2M），然后将对应的arr[num/2M]++,这样遍历后，得到了每个区间的数的情况。
4. 通过累加每个区间的出现次数，就可以找到40亿个数的中位数（也就是第20亿个数）到底落在哪个区间上。
5. 接下来申请一个长度为2MB的无符号整型数组countArr[0...2M-1]，占用空间8MB，然后遍历40亿个数，此时只关心在第K区间的数记为num_i，其他的数省略，然后将countArr[num_i-K\*2M]++，也就是只对第K区间的数做词频统计。
6. 遍历完后就得到了第K区间的词频统计结果countArr，最后只在第K区间上找到第0.002亿个数。



# 6 一致性哈希算法的基本原理

**题目**

工程师常使用服务器集群来设计和实现数据缓存，以下是常见的策略：

1. 无论是添加、查询还是删除数据，都先将数据的id通过哈希函数转换成一个哈希值，记位key。
2. 如果目前机器有N台，则计算key%N的值，这个值是该数据所属的机器编号，后续操作都只在这台机器上进行。

请分析这种缓存策略可能带来的问题，并提出改进的方案。

**解答**

上述策略的问题：如果增加和删除机器时（N变化）代价会很高，所以的数据都不得不根据id重新计算一遍哈希值，并将哈希值对新的机器数进行取模操作，然后进行大规模的数据迁移。

一致性哈希算法是一种很好的数据缓存设计方案。

1. Hash范围0~2^64，组成环结构，3台服务器m1、m2和m3哈希到环上。
2. 针对某个值哈希到换上P，则顺时针方向的下一个服务器负责它。
3. 添加机器时，将m4哈希到环上，只用将原m3负责的部分数据交给m4服务器。

**还存在的问题**

服务器较少时，不能保证m1、m2、m3将环均分，则各服务器的负载不均，增加服务器会破坏均衡性。

解决方法：虚拟节点技术

将m1、m2、m3都各分配1000个虚拟节点，用虚拟节点哈希到环上，此时用3000个节点将环均分。