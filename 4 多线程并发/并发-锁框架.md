# 1 接口

## 1.1 Lock接口

Lock接口可以视为synchronized的增强版，提供了更灵活的功能。该接口提供了限时锁等待、锁中断、锁尝试等功能。

需要注意`lock()`和`lockInterruptibly()`这两个方法的区别：

- `lock()方法`类似于使用synchronized关键字加锁，如果锁不可用，出于线程调度目的，将禁用当前线程，并且在获得锁之前，该线程将一直处于休眠状态。
- `lockInterruptibly()`方法顾名思义，就是如果锁不可用，那么当前正在等待的线程是可以被中断的，这比synchronized关键字更加灵活。

## 1.2 Condition接口

Condition可以看做是Obejct类的`wait()`、`notify()`、`notifyAll()`方法的替代品，与Lock配合使用。

当线程执行condition对象的`await`方法时，当前线程会立即释放锁，并进入对象的等待区，等待其它线程唤醒或中断。

JUC在实现Conditon对象时，其实是通过实现AQS框架，来实现了一个Condition等待队列，这个在后面讲AQS框架时会详细介绍，目前只要了解Condition如何使用即可。

等待 Condition 时，为了防止发生“虚假唤醒”， Condition 一般都是在一个循环中被等待，并测试正被等待的状态声明.

## 1.3 ReadWriteLock接口

ReadWriteLock接口是一个单独的接口（未继承Lock接口），该接口提供了获取读锁和写锁的方法。

所谓读写锁，是一对相关的锁——读锁和写锁，读锁用于只读操作，写锁用于写入操作。读锁可以由多个线程同时保持，而写锁是独占的，只能由一个线程获取。

举个例子，假设我有一份共享数据——订单金额，大多数情况下，线程只会进行高频的数据访问（读取订单金额），数据修改（修改订单金额）的频率较低。
那么一般情况下，如果采用互斥锁，读/写和读/读都是互斥的，性能显然不如采用读写锁。

另外，由于读写锁本身的实现就远比独占锁复杂，因此，读写锁比较适用于以下情形：

1. 高频次的读操作，相对较低频次的写操作；
2. 读操作所用时间不会太短。（否则读写锁本身的复杂实现所带来的开销会成为主要消耗成本）

# 2 ReentrantLock

ReentrantLock类，实现了Lock接口，是一种**可重入**的**独占锁**，它具有与使用 `synchronized` 相同的一些基本行为和语义，但功能更强大。ReentrantLock内部通过内部类实现了AQS框架(AbstractQueuedSynchronizer)的API来实现**独占锁**的功能。

ReentrantLock类的其中一个构造器提供了指定**公平策略** / **非公平策略**的功能，默认为**非公平策略**。

- **公平策略：**在多个线程争用锁的情况下，公平策略倾向于将访问权授予等待时间最长的线程。也就是说，相当于有一个线程等待队列，先进入等待队列的线程后续会先获得锁，这样按照“先来后到”的原则，对于每一个等待线程都是公平的。
- **非公平策略：**在多个线程争用锁的情况下，能够最终获得锁的线程是随机的（由底层OS调度）。

注意：一般情况下，使用公平策略的程序在多线程访问时，总体吞吐量（即速度很慢，常常极其慢）比较低，因为此时在线程调度上面的开销比较大。

举个例子：
假设采用公平策略，线程A首先获取了锁，线程B和线程C等待获取锁，

当线程A释放锁时，线程B将经历从 挂起->唤醒 的线程调度过程，线程调度非常耗时。

在线程B的 挂起->唤醒 阶段：

1. 如果采用非公平策略，那么线程C可以立即获取锁，线程C使用完并释放锁后，线程B可能才刚唤醒完成；此时线程B又可以去获取锁，这样线程B和线程C的效率都得到提升，系统吞吐量提升；
2. 如果采用公平策略，线程C即使可用，也要等到线程调度完成，整个系统的吞吐量降低。

因此，当线程持有锁的时间相对较长或者线程请求锁的平均时间间隔较长时，可以考虑使用公平策略。此时线程调度产生的耗时间隔影响会较小。

ReentrantLock的源码非常简单，它通过内部类实现了AQS框架，Lock接口的实现仅仅是对AQS的api的简单封装。

# 3 ReentrantReadWriteLock

ReentrantReadWriteLock类，顾名思义，是一种读写锁，它是ReadWriteLock接口的直接实现，该类在内部实现了具体**独占锁**特点的写锁，以及具有**共享锁**特点的读锁，和ReentrantLock一样，ReentrantReadWriteLock类也是通过定义内部类实现AQS框架的API来实现独占/共享的功能。

ReentrantReadWriteLock类具有如下特点：

（1）支持公平/非公平策略

与ReadWriteLock类一样，ReentrantReadWriteLock对象在构造时，可以传入参数指定是公平锁还是非公平锁。

（2）支持锁重入：

- 同一读线程在获取了读锁后还可以获取读锁；
- 同一写线程在获取了写锁之后既可以再次获取写锁又可以获取读锁；

（3）支持锁降级

所谓锁降级，就是：先获取写锁，然后获取读锁，最后释放写锁，这样写锁就降级成了读锁。但是，读锁不能升级到写锁。简言之，就是：写锁可以降级成读锁，读锁不能升级成写锁。

（4）Condition条件支持

ReentrantReadWriteLock的内部读锁类、写锁类实现了Lock接口，所以可以通过`newCondition()`方法获取Condition对象。但是这里要注意，读锁是没法获取Condition对象的，读锁调用`newCondition() `方法会直接抛出`UnsupportedOperationException`。

我们知道，condition的作用其实是对Object类的`wait()`和`notify()`的增强，是为了让线程在指定对象上等待，是一种线程之间进行协调的工具。

当线程调用condition对象的`await`方法时，必须拿到和这个condition对象关联的锁。由于线程对读锁的访问是不受限制的（在写锁未被占用的情况下），那么即使拿到了和读锁关联的condition对象也是没有意义的，因为读线程之前不需要进行协调。

ReentrantReadWriteLock类有两个内部嵌套类`ReadLock`和`WriteLock`，这两个内部类的实例会在ReentrantReadWriteLock类的构造器中创建，并通过ReentrantReadWriteLock类的`readLock()`和`writeLock()`方法访问。

ReentrantReadWriteLock类的核心方法其实就两个：`readLock()`和`writeLock()`，其它都是一些用来监控系统状态的方法，返回的都是某一时刻点的近似值。

# 4 LockSupport

LockSupport类，是JUC包中的一个工具类，是用来创建锁和其他同步类的基本线程阻塞原语。

LockSupport类的核心方法其实就两个：`park()`和`unark()`，其中`park()`方法用来阻塞当前调用线程，`unpark()`方法用于唤醒指定线程。

这其实和Object类的wait()和signial()方法有些类似，但是LockSupport的这两种方法从语意上讲比Object类的方法更清晰，而且可以针对指定线程进行阻塞和唤醒。

LockSupport类使用了一种名为Permit（许可）的概念来做到阻塞和唤醒线程的功能，可以把许可看成是一种(0,1)信号量（Semaphore），但与 Semaphore 不同的是，许可的累加上限是1。

初始时，permit为0，当调用`unpark()`方法时，线程的permit加1，当调用`park()`方法时，如果permit为0，则调用线程进入阻塞状态。

通过LockSupport的这两个方法，可以很方便的阻塞和唤醒线程。但是LockSupport的使用过程中还需要注意以下几点：

1. park方法的调用一般要方法一个循环判断体里面。之所以这样做，是为了防止线程被唤醒后，不进行判断而意外继续向下执行，这其实是一种Guarded Suspension的多线程设计模式。
2. `park`方法是会响应中断的，但是不会抛出异常。(也就是说如果当前调用线程被中断，则会立即返回但不会抛出中断异常)
3. park的重载方法`park(Object blocker)`，会传入一个blocker对象，所谓Blocker对象，其实就是当前线程调用时所在调用对象（如上述示例中的FIFOMutex对象）。该对象一般供监视、诊断工具确定线程受阻塞的原因时使用。

# 5 AQS

## 5.1 AQS简介

AbstractQueuedSynchronizer抽象类（以下简称AQS）是整个`java.util.concurrent`包的核心。在JDK1.5时，引入了J.U.C包，该包中的大多数同步器都是基于AQS来构建的。AQS框架提供了一套通用的机制来管理同步状态（synchronization state）、阻塞/唤醒线程、管理等待队列。

我们所熟知的ReentrantLock、CountDownLatch、CyclicBarrier等同步器，其实都是通过内部类实现了AQS框架暴露的API，以此实现各类同步器功能。这些同步器的主要区别其实就是对同步状态（synchronization state）的定义不同。

AQS框架，分离了构建同步器时的一系列关注点，它的所有操作都围绕着资源——同步状态（synchronization state）来展开，并替用户解决了如下问题：

1. 资源是可以被同时访问？还是在同一时间只能被一个线程访问？（共享/独占功能）
2. 访问资源的线程如何进行并发管理？（等待队列）
3. 如果线程等不及资源了，如何从等待队列退出？（超时/中断）

这其实是一种典型的模板方法设计模式：父类（AQS框架）定义好骨架和内部操作细节，具体规则由子类去实现。
AQS框架将剩下的一个问题留给用户：

**什么是资源？如何定义资源是否可以被访问？**

我们来看下几个常见的同步器对这一问题的定义：

| 同步器                 | 资源的定义                                                   |
| :--------------------- | :----------------------------------------------------------- |
| ReentrantLock          | 资源表示独占锁。State为0表示锁可用；为1表示被占用；为N表示重入的次数 |
| CountDownLatch         | 资源表示倒数计数器。State为0表示计数器归零，所有线程都可以访问资源；为N表示计数器未归零，所有线程都需要阻塞。 |
| Semaphore              | 资源表示信号量或者令牌。State≤0表示没有令牌可用，所有线程都需要阻塞；大于0表示由令牌可用，线程每获取一个令牌，State减1，线程没释放一个令牌，State加1。 |
| ReentrantReadWriteLock | 资源表示共享的读锁和独占的写锁。state逻辑上被分成两个16位的unsigned short，分别记录读锁被多少线程使用和写锁被重入的次数。 |

综上所述，AQS框架提供了以下功能：

**1 提供一套模板框架**

由于并发的存在，需要考虑的情况非常多，因此能否以一种相对简单的方法来完成这两个目标就非常重要，因为对于用户（AQS框架的使用者来说），很多时候并不关心内部复杂的细节。而AQS其实就是利用模板方法模式来实现这一点，AQS中大多数方法都是final或是private的，也就是说Doug Lea并不希望用户直接使用这些方法，而是只覆写部分模板规定的方法。
AQS通过暴露以下API来让让用户自己解决上面提到的“**如何定义资源是否可以被访问**”的问题：

| 钩子方法          | 描述               |
| :---------------- | :----------------- |
| tryAcquire        | 排它获取（资源数） |
| tryRelease        | 排它释放（资源数） |
| tryAcquireShared  | 共享获取（资源数） |
| tryReleaseShared  | 共享获取（资源数） |
| isHeldExclusively | 是否排它状态       |

**2 支持中断、超时**

还记得Lock接口中的那些锁中断、限时等待、锁尝试的方法吗？这些方法的实现其实AQS都内置提供了。
使用了AQS框架的同步器，都支持下面的操作：

- 阻塞和非阻塞（例如tryLock）同步；
- 可选的超时设置，让调用者可以放弃等待；
- 可中断的阻塞操作。

**3 支持独占模式和共享模式**

**4 支持Condition条件等待**

Condition接口，可以看做是Obejct类的wait()、notify()、notifyAll()方法的替代品，与Lock配合使用。
AQS框架内部通过一个内部类`ConditionObject`，实现了Condition接口，以此来为子类提供条件等待的功能。

## 5.2 AQS方法说明

在本章第一部分讲到，AQS利用了模板方法模式，其中大多数方法都是final或是private的，我们把这类方法称为**Skeleton Method**，也就是说这些方法是AQS框架自身定义好的骨架，子类是不能覆写的。
下面会按类别简述一些比较重要的方法，具体实现细节及原理会在本系列后续部分详细阐述。

### 5.2.1 CAS操作

CAS，即CompareAndSet，在Java中CAS操作的实现都委托给一个名为UnSafe类，关于`Unsafe`类，以后会专门详细介绍该类，目前只要知道，通过该类可以实现对字段的原子操作。

| 方法名                  | 修饰符               | 描述                    |
| :---------------------- | :------------------- | :---------------------- |
| compareAndSetState      | protected final      | CAS修改同步状态值       |
| compareAndSetHead       | private final        | CAS修改等待队列的头指针 |
| compareAndSetTail       | private final        | CAS修改等待队列的尾指针 |
| compareAndSetWaitStatus | private static final | CAS修改结点的等待状态   |
| compareAndSetNext       | private static final | CAS修改结点的next指针   |

### 5.2.2 等待队列的核心操作

| 方法名              | 修饰符  | 描述                 |
| :------------------ | :------ | :------------------- |
| enq                 | private | 入队操作             |
| addWaiter           | private | 入队操作             |
| setHead             | private | 设置头结点           |
| unparkSuccessor     | private | 唤醒后继结点         |
| doReleaseShared     | private | 释放共享结点         |
| setHeadAndPropagate | private | 设置头结点并传播唤醒 |

### 5.2.3 资源的获取操作

| 方法名                       | 修饰符         | 描述                              |
| :--------------------------- | :------------- | :-------------------------------- |
| cancelAcquire                | private        | 取消获取资源                      |
| shouldParkAfterFailedAcquire | private static | 判断是否阻塞当前调用线程          |
| acquireQueued                | final          | 尝试获取资源,获取失败尝试阻塞线程 |
| doAcquireInterruptibly       | private        | 独占地获取资源（响应中断）        |
| doAcquireNanos               | private        | 独占地获取资源（限时等待）        |
| doAcquireShared              | private        | 共享地获取资源                    |
| doAcquireSharedInterruptibly | private        | 共享地获取资源（响应中断）        |
| doAcquireSharedNanos         | private        | 共享地获取资源（限时等待）        |

| 方法名                     | 修饰符       | 描述                       |
| :------------------------- | :----------- | :------------------------- |
| acquire                    | public final | 独占地获取资源             |
| acquireInterruptibly       | public final | 独占地获取资源（响应中断） |
| acquireInterruptibly       | public final | 独占地获取资源（限时等待） |
| acquireShared              | public final | 共享地获取资源             |
| acquireSharedInterruptibly | public final | 共享地获取资源（响应中断） |
| tryAcquireSharedNanos      | public final | 共享地获取资源（限时等待） |

### 5.2.4 资源的释放操作

| 方法名        | 修饰符       | 描述         |
| :------------ | :----------- | :----------- |
| release       | public final | 释放独占资源 |
| releaseShared | public final | 释放共享资源 |

## 5.3 AQS原理简述

我们在第一节中讲到，AQS框架分离了构建同步器时的一系列关注点，它的所有操作都围绕着资源——同步状态（synchronization state）来展开因此，围绕着资源，衍生出三个基本问题：

1. 同步状态（synchronization state）的管理
2. 阻塞/唤醒线程的操作
3. 线程等待队列的管理

### 5.3.1 同步状态

**同步状态的定义**：同步状态，其实就是资源。AQS使用单个int（32位）来保存同步状态，并暴露出getState、setState以及compareAndSetState操作来读取和更新这个状态。

### 5.3.2 线程的阻塞/唤醒

在JDK1.5之前，除了内置的监视器机制外，没有其它方法可以安全且便捷得阻塞和唤醒当前线程。

JDK1.5以后，java.util.concurrent.locks包提供了LockSupport类来作为线程阻塞和唤醒的工具。

### 5.3.3 等待队列

等待队列，是AQS框架的核心，整个框架的关键其实就是如何在并发状态下管理被阻塞的线程。

等待队列是严格的FIFO队列，是Craig，Landin和Hagersten锁（CLH锁）的一种变种，采用双向链表实现，因此也叫CLH队列。

**结点定义**

CLH队列中的结点是对线程的包装，结点一共有两种类型：独占（EXCLUSIVE）和共享（SHARED）。
每种类型的结点都有一些状态，其中独占结点使用其中的CANCELLED(1)、SIGNAL(-1)、CONDITION(-2)，共享结点使用其中的CANCELLED(1)、SIGNAL(-1)、PROPAGATE(-3)。

| 结点状态  | 值   | 描述                                                         |
| :-------- | :--- | :----------------------------------------------------------- |
| CANCELLED | 1    | 取消。表示当前结点被中断或超时，需要移出队列                 |
| SIGNAL    | -1   | 发信号。表示后驱结点被阻塞了（当前结点在入队后、阻塞前，应确保将其prev结点类型改为SIGNAL，以便prev结点取消或释放时将当前结点唤醒。） |
| CONDITION | -2   | Condition专用。表示当前结点在Condition队列中，因为等待某个条件而被阻塞了 |
| PROPAGATE | -3   | 传播。适用于共享模式（比如连续的读操作结点可以依次进入临界区，设为PROPAGATE有助于实现这种迭代操作。） |
| INITIAL   | 0    | 默认。新结点会处于这种状态                                   |

AQS使用CLH队列实现线程的结构管理，而CLH结构正是用前一结点某一属性表示当前结点的状态，之所以这种做是因为在双向链表的结构下，这样更容易实现取消和超时功能。

next指针：用于维护队列顺序，当临界区的资源被释放时，头结点通过next指针找到队首结点。
prev指针：用于在结点（线程）被取消时，让当前结点的前驱直接指向当前结点的后驱完成出队动作。  

**队列定义**

对于CLH队列，当线程请求资源时，如果请求不到，会将线程包装成结点，将其挂载在队列尾部。

CLH队列的示意图如下：

①初始状态，队列head和tail都指向空

![clipboard.png](https://segmentfault.com/img/bVbetIi?w=168&h=166)

②首个线程入队，先创建一个空的头结点，然后以自旋的方式不断尝试插入一个包含当前线程的新结点

![clipboard.png](https://segmentfault.com/img/bVbetIk?w=192&h=263)

![clipboard.png](https://segmentfault.com/img/bVbetIm?w=523&h=302)

# 6 AQS的独占功能

以ReentrantLock的调用为例，说明AbstractQueuedSynchronizer提供的独占功能。

## 6.1 ReentrantLock的公平策略原理

本节对ReentrantLock公平策略的分析基于以下示例：

假设现在有3个线程：ThreadA、ThreadB、ThreadC，一个公平的独占锁，3个线程会依次尝试去获取锁：`ReentrantLock lock=new ReentrantLock(true);`

### 6.1.1 ThreadA首先获取到锁

ThreadA首先调用ReentrantLock的**lock**方法

lock方法内部调用了**FairSync**的**lock**方法，其中又调用了AQS的acquire方法并传入参数1

AQS中的**acquire**方法如下：

![clipboard.png](https://segmentfault.com/img/bVbetLr?w=605&h=116)

其中**tryAcquire**方法需要AQS的子类自己去实现，我们来看下ReentrantLock中的实现：

![clipboard.png](https://segmentfault.com/img/bVbetLs?w=810&h=537)

可以看到，在ReentrantLock中，同步状态State的含义如下：

| State | 资源的定义                               |
| :---- | :--------------------------------------- |
| 0     | 表示锁可用                               |
| 1     | 表示锁被占用                             |
| 大于1 | 表示锁被占用，且值表示同一线程的重入次数 |

ThreadA是首个获取锁的线程，所以上述方法会返回true，第一阶段结束。（ThreadA一直保持占有锁的状态）
此时，AQS中的等待队列还是空：

![clipboard.png](https://segmentfault.com/img/bVbetLZ?w=120&h=176)

### 6.1.2 ThreadB开始获取锁

终于，ThreadB要登场了，一样，ThreadB先去调用lock方法，最终调用AQS的acquire方法：

![clipboard.png](https://segmentfault.com/img/bVbetL2?w=693&h=162)

**tryAcquire**方法肯定是返回false（因为此时ThreadA占有着锁）。

接下来看下**addWaiter**方法，这个方法其实就是将当前调用线程包装成一个【独占结点】，添加到等待队列尾部。

![clipboard.png](https://segmentfault.com/img/bVbetL4?w=854&h=387)

![clipboard.png](https://segmentfault.com/img/bVbetL5?w=549&h=331)

这里关键是enq方法，因为并发插入的情况存在，所以该方法设计成了自旋操作，保证结点能成功插入，具体步骤如下：

①当队列为空的时候，先创建一个dummy头结点；

![clipboard.png](https://segmentfault.com/img/bVbetL7?w=352&h=369)

②进入下一次循环，插入队尾结点。

![clipboard.png](https://segmentfault.com/img/bVbetL9?w=680&h=392)

好了，ThreadB已经被包装成结点插入队尾了，接下来会调用**acquireQueued**方法，这也是AQS中最重要的方法之一：

- 从等待队列中获取队首线程，并尝试获取锁。如果获取不到，就要确保在前驱能够唤醒自己的前提下（将前驱状态置为SIGNAL）进入阻塞状态。
- 注意：正常情况下，该方法会一直阻塞当前线程，除非获取到锁才返回；但是如果执行过程中，抛出异常（tryAcquire方法）,那么会将当前节点移除，继续上抛异常。
- 如果线程阻塞过程中被中断，则返回true

![clipboard.png](https://segmentfault.com/img/bVbetMa?w=1313&h=605)

在AQS中，等待队列中的线程都是阻塞的，当某个线程被唤醒时，只有该线程是首结点（线程）时，才有权去尝试获取锁。

上述方法中，将ThreadB包装成结点插入队尾后，先判断ThreadB是否是首结点（注意不是头结点，头结点是个dummy结点），发现确实是首结点（node.predecessor==head），于是调用tryAcquire尝试获取锁，但是获取失败了（此时ThreadA占有着锁），就要判断是否需要阻塞当前线程。

判断是否需要阻塞线程：

注意：CLH队列的一个特点就是，将当前节点的状态保存在它的前驱中，前驱状态是【-1：等待唤醒】时，才会阻塞当前线程。

返回true表示需要阻塞当前调用线程。

![clipboard.png](https://segmentfault.com/img/bVbetMc?w=1131&h=500)

注意，对于独占功能，只使用了3种结点状态：

| 结点状态  | 值   | 描述                                                         |
| :-------- | :--- | :----------------------------------------------------------- |
| CANCELLED | 1    | 取消。表示后驱结点被中断或超时，需要移出队列                 |
| SIGNAL    | -1   | 发信号。表示后驱结点被阻塞了（当前结点在入队后、阻塞前，应确保将其prev结点类型改为SIGNAL，以便prev结点取消或释放时将当前结点唤醒。） |
| CONDITION | -2   | Condition专用。表示当前结点在Condition队列中，因为等待某个条件而被阻塞了 |

对于在等待队列中的线程，如果要阻塞它，需要确保将来有线程可以唤醒它，AQS中通过将前驱结点的状态置为SIGNAL:-1来表示将来会唤醒当前线程，当前线程可以安心的阻塞。

看下图或许比较好理解：

①插入完ThreadB后，队列的初始状态如下：

![clipboard.png](https://segmentfault.com/img/bVbetM7?w=427&h=271)

②虽然ThreadB是队首结点，但是它拿不到锁（被ThreadA占有着），所以ThreadB会阻塞，但在阻塞前需要设置下前驱的状态，以便将来可以唤醒我：

![clipboard.png](https://segmentfault.com/img/bVbetM3?w=427&h=271)

至此，ThreadB的执行也暂告一段落了（安心得在等待队列中睡觉）。

注意：补充一点，如果ThreadB在阻塞过程中被中断，其实是不会抛出异常的，只会在acquireQueued方法返回时，告诉调用者在阻塞器件有没被中断过，具体如果处理，要不要抛出异常，取决于调用者，这其实是一种延时中断机制。

### 6.1.3 ThreadC开始获取锁

终于轮到ThreadC出场了，ThreadC的调用过程和ThreadB完全一样，同样拿不到锁，然后加入到等待队列队尾：

![clipboard.png](https://segmentfault.com/img/bVbetNf?w=686&h=267)

然后，ThreadC在阻塞前需要把前驱结点的状态置为SIGNAL：-1，以确保将来可以被唤醒：

![clipboard.png](https://segmentfault.com/img/bVbetNh?w=686&h=267)

### 6.1.4 ThreadA释放锁

ThreadA终于使用完了临界资源，要释放锁了，调用ReentrantLock的**unlock**方法

unlock内部调用了AQS的release方法，传参1：

![clipboard.png](https://segmentfault.com/img/bVbetNq?w=648&h=197)

尝试释放锁的操作**tryRelease**：

![clipboard.png](https://segmentfault.com/img/bVbetNr?w=1078&h=276)

释放成功后，调用**unparkSuccessor**方法，唤醒队列中的首结点：

![clipboard.png](https://segmentfault.com/img/bVbetNv?w=1169&h=513)

此时，队列状态为：

![clipboard.png](https://segmentfault.com/img/bVbetNz?w=686&h=263)

### 6.1.5 ThreadB唤醒后继续执行

好了，队首结点（ThreadB）被唤醒了。

ThreadB会继续从以下位置开始执行，先返回一个中断标识，用于表示ThreadB在阻塞期间有没被中断过：

![clipboard.png](https://segmentfault.com/img/bVbetNB?w=573&h=203)

然后ThreadB又开始了自旋操作，被唤醒的是队首结点，所以可以尝试tryAcquire获取锁，此时获取成功（ThreadA已经释放了锁）。

获取成功后会调用setHead方法，将头结点置为当前结点，并清除线程信息：

最终的队列状态如下：

![clipboard.png](https://segmentfault.com/img/bVbetNR?w=427&h=263)

### 6.1.6 ThreadB释放锁

ThreadB也终于使用完了临界资源，要释放锁了，过程和ThreadA释放时一样，释放成功后，会调用**unparkSuccessor**方法，唤醒队列中的首结点：

![clipboard.png](https://segmentfault.com/img/bVbetNZ?w=427&h=263)

队首结点（ThreadC）被唤醒后，继续从原来的阻塞处向下执行，并尝试获取锁，获取成功，最终队列状态如下：

![clipboard.png](https://segmentfault.com/img/bVbetN7?w=167&h=255)

### 6.1.7 ThreadC释放锁

ThreadC也终于使用完了临界资源，要释放锁了。释放成功后，调用unparkSuccessor方法，唤醒队列中的首结点：
此时队列中只剩下一个头结点（dummy），所以这个方法其实什么都不做。最终队列的状态就是只有一个dummy头结点。

至此，AQS的独占功能已经差不多分析完了，剩下还有几个内容没分析：

1. 锁中断功能
2. 限时等待功能
3. Conditon等待功能

## 6.2 ReentrantLock的非公平策略原理

ReenrantLock非公平策略的内部实现和公平策略没啥太大区别：

非公平策略和公平策略的最主要区别在于：

公平锁获取锁时，会判断等待队列中是否有线程排在当前线程前面。只有没有情况下，才去获取锁，这是公平的含义。

非公平锁获取锁时，会立即尝试修改同步状态，失败后再调用AQS的acquire方法。 

acquire方法会转调非公平锁自身的tryAcquire方法，其实最终是调了nofairTryAcquire方法，而该方法相对于公平锁，只是少了“队列中是否有其它线程排在当前线程前”这一判断：

## 6.3 AQS对中断的支持

还是以ReentrantLock为例，来看下AQS是如何实现锁中断和超时的。

我们知道ReentrantLock的**lockInterruptibly**方法是会响应中断的。（线程如果在阻塞过程中被中断，会抛出InterruptedException异常）

该方法调用了AQS的**acquireInterruptibly**方法：

![clipboard.png](https://segmentfault.com/img/bVbetOA?w=725&h=232)

上述代码会先去尝试获取锁，如果失败，则调用doAcquireInterruptibly方法，如下：

![clipboard.png](https://segmentfault.com/img/bVbetOB?w=587&h=578)

它和**acquireQueued**方法的对比，唯一的区别就是：

当调用线程获取锁失败，进入阻塞后，如果中途被中断，**acquireQueued**只是用一个标识记录线程被中断过，而**doAcquireInterruptibly**则是直接抛出异常。

## 6.4 AQS对限时等待的支持

Lock接口中有一个方法：**tryLock**，用于在指定的时间内尝试获取锁，获取不到就返回。

ReentrantLock实现了该方法，该方法内部调用了AQS的**tryAcquireNanos**方法：

**tryAcquireNanos**方法是响应中断的，先尝试获取一次锁，失败则调用**doAcquireNanos**方法进行超时等待：

关键是**doAcquireNano**方法，和**acquireQuqued**方法类似，又是一个自旋操作，在超时前不断尝试获取锁，获取不到则阻塞（加上了等待时间的判断）。该方法内部，调用了`LockSupport.parkNanos`来超时阻塞线程：

`LockSupport.parkNanos`内部其实通过Unsafe这个类来操作线程的阻塞，底层是一个native方法：

如果当前线程在指定时间内获取不到锁，除了返回false外，最终还会执行**cancelAcquire**方法：取消一个正在尝试获取锁的线程操作。

假设现在有3个线程：ThreadA、ThreadB、ThreadC，一个公平的独占锁，3个线程会依次尝试去获取锁，不过此时加上了限时等待：ThreadB等待10s，ThreadA等待20s。

**1. ThreadA首先获取到锁，ThreadB和ThreadC依次尝试去获取锁** 

ThreadB和ThreadC经过两轮自旋操作后，等待队列的情况如下：

![clipboard.png](https://segmentfault.com/img/bVbetPn?w=686&h=279)

**2. ThreadB先到超时时间**

调用了**cancelAcquire**方法取消操作，队列状态变成：

![clipboard.png](https://segmentfault.com/img/bVbetPs?w=686&h=279)

**3. ThreadC到达超时时间**

调用了**cancelAcquire**方法取消操作，队列状态变成：

![clipboard.png](https://segmentfault.com/img/bVbetPK?w=686&h=278)

在退出**cancelAcquire**后，原来ThreadB和ThreadC对应的结点会被JVM垃圾回收器回收。

# 7 AQS的Condition等待

以ReentrantLock的调用为例，说明AbstractQueuedSynchronizer提供的Conditon等待功能。

## 7.1 Condition接口的实现

J.U.C包提供了Conditon接口，用以对原生的`Object.wait()`、`Object.notify()`进行增强。

Condition接口的实现类其实是在AQS中——`ConditionObject`，ReentranLock的newConditon方法其实是创建了一个`AbstractQueuedSynchronizer.ConditionObject`对象：

Condition作为AQS的内部类，复用了AQS的结点，维护一个条件队列，队列初始时的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeujR?w=774&h=285)

![clipboard.png](https://segmentfault.com/img/bVbeuj3?w=315&h=96)

假设现在有3个线程：ThreadA、ThreadB、ThreadC，一个Conditon实现对象。

```java
ReentrantLock lock = new ReentrantLock();
Conditon con = lock.newConditon();
```

线程将以以下的时序调用：

```java
// ThreadA先调用lock方法获取到锁，然后调用con.await()
// ThreadB获取锁，调用con.signal()唤醒ThreadA
// ThreadB释放锁
```

### 7.1.1 ThreadA获取到锁后，首先调用**await**方法

![clipboard.png](https://segmentfault.com/img/bVbeumJ?w=820&h=453)

上述方法，先对线程中断做一次预判断，然后将线程包装成结点插入【条件队列】，插入完成后，条件队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeumO?w=314&h=230)

我们知道，`await()`方法会释放当前线程持有的锁，这个过程其实就是**fullyRelease**方法的作用：

然后，判断当前结点是不是在【等待队列】中，不在的话就会阻塞线程。

最终线程A释放了锁，并进入阻塞状态。

### 7.1.2 ThreadB获取到锁后，首先调用**signal**方法

由于Condition的signal方法要求线程必须获得与此Condition对象相关联的锁，所以这里有个中断判断：

然后，会调用**doSignal**方法，删除条件队列中的队首**CONDITION**类型结点：

删除完成后，**transferForSignal**方法会将**CONDITON**结点转换为初始结点，并插入【等待队列】：

此时，【条件队列】已经空了：

而ThreadA被包装成新结点后，插入【等待队列】：

![clipboard.png](https://segmentfault.com/img/bVbeunK?w=427&h=266)

### 7.1.3 ThreadB释放锁

终于ThreadB释放了锁，释放成功后，会调用**unparkSuccessor**方法（参加AQS独占功能的讲解），唤醒队列中的首结点（线程A）：

最终等待队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeun0?w=427&h=266)

### 7.1.4 ThreadA从唤醒处继续执行

ThreadA被唤醒后，从await方法的阻塞处开始继续往下执行：

之后会调用**acquireQueued**方法再次尝试获取锁，获取成功后，最终等待队列状态如下：

![clipboard.png](https://segmentfault.com/img/bVbeun4?w=167&h=231)

本章以ReentrantLock的公平锁为例，分析了AbstractQueuedSynchronizer的Condition功能。

通过分析，可以看到，当线程在指定Condition对象上等待的时候，其实就是将线程包装成结点，加入了条件队列，然后阻塞。当线程被通知唤醒时，则是将条件队列中的结点转换成等待队列中的结点，之后的处理就和独占功能完全一样。

除此之外，Condition还支持限时等待、非中断等待等功能，分析思路是一样的，读者可以自己去阅读AQS的源码，通过使用示例，加入调试断点一步步看内部的调用流程，主干理顺了之后，再看其它分支，其实是异曲同工的。

# 8 AQS的共享功能

以CountDownLatch为例，分析AQS的共享功能。CountDownLatch，是J.U.C中的一个同步器类，可作为倒数计数器使用。

CountDownLatch示例：假设现在有3个线程，ThreadA、ThreadB、mainThread，CountDownLatch初始计数为1：`CountDownLatch switcher = new CountDownLatch(1);`

线程的调用时序如下：

```java
// ThreadA调用await()方法等待
// ThreadB调用await()方法等待
// 主线程main调用countDown()放行
```

## 8.1 AQS共享功能的原理

### 8.1.1 创建CountDownLatch

CountDownLatch的创建没什么特殊，调用唯一的构造器，传入一个初始计数值，内部实例化一个AQS子类：

```java
CountDownLatch switcher = new CountDownLatch(1);
```

可以看到，初始计数值count其实就是同步状态值，在CountDownLatch中，同步状态State表示CountDownLatch的计数器的初始大小。

### 8.1.2 ThreadA调用await()方法等待

CountDownLatch的**await**方法是响应中断的，该方法其实是调用了AQS的**acquireSharedInterruptibly**方法：

注意**tryAcquireShared**方法，该方法尝试获取锁，由AQS子类实现，其返回值的含义如下：

| State | 资源的定义                           |
| :---- | :----------------------------------- |
| 小于0 | 表示获取失败                         |
| 0     | 表示获取成功                         |
| 大于0 | 表示获取成功，且后继争用线程可能成功 |

CountDownLatch中的**tryAcquireShared**实现相当简单，当State值为0时，永远返回成功：

我们之前说了在CountDownLatch中，同步状态State表示CountDownLatch的计数器的初始值，当`State==0`时，表示无锁状态，且一旦State变为0，就永远处于无锁状态了，此时所有线程在await上等待的线程都可以继续执行。

而在ReentrantLock中，`State==0`时，虽然也表示无锁状态，但是只有一个线程可以重置State的值。这就是**共享锁**的含义。

好了，继续向下执行，ThreadA尝试获取锁失败后，会调用**doAcquireSharedInterruptibly**：

![clipboard.png](https://segmentfault.com/img/bVbeupD?w=774&h=646)

首先通过**addWaiter**方法，将ThreadA包装成共享结点，插入等待队列，插入完成后队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeupK?w=427&h=266)

然后会进入自旋操作，先尝试获取一次锁，显然此时是获取失败的（主线程main还未调用countDown，同步状态State还是1）。

然后判断是否要进入阻塞（**shouldParkAfterFailedAcquire**）：

好了，至此，ThreadA进入阻塞态，最终队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeunK?w=427&h=266)

### 8.1.3 ThreadB调用await()方法等待

流程和步骤2完全相同，调用后ThreadB也被加入到等待队列中：

![clipboard.png](https://segmentfault.com/img/bVbeuqp?w=686&h=265)

### 8.1.4 主线程main调用countDown()放行

ThreadA和ThreadB调用了`await()`方法后都在等待了，现在主线程main开始调用`countDown()`方法，该方法调用后，ThreadA和ThreadB都会被唤醒，并继续往下执行，达到类似门栓的作用。

来看下**countDown**方法的内部：将计数值减1，如果计数值变为0（最小为0），则释放所有等待线程。

该方法内部调用了AQS的**releaseShared**方法，先尝试一次释放锁，**tryReleaseShared**方法是一个钩子方法，由**CountDownLatch**实现，当同步State状态值首次变为0时，会返回true：

然后执行**doReleaseShared**方法唤醒阻塞的线程：

先调用**compareAndSetWaitStatus**将头结点的等待状态置为0，表示将唤醒后续结点（ThreadA），成功后的等待队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuqA?w=686&h=265)

然后调用**unparkSuccessor**唤醒后继结点（ThreadA被唤醒后会从原阻塞处继续往下执行，这个在步骤5再讲）：

此时，等待队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuqE?w=686&h=265)

### 8.1.5 ThreadA从原阻塞处继续向下执行

ThreadA被唤醒后，会从原来的阻塞处继续向下执行：

由于是一个自旋操作，ThreadA会再次尝试获取锁，由于此时State同步状态值为0（无锁状态），所以获取成功。然后调用**setHeadAndPropagate**方法：

**setHeadAndPropagate**方法把ThreadA结点变为头结点，并根据传播状态判断是否要唤醒并释放后继结点：

①将ThreadA变成头结点

![clipboard.png](https://segmentfault.com/img/bVbeuqN?w=427&h=266)

②调用**doReleaseShared**方法，释放并唤醒ThreadB结点

![clipboard.png](https://segmentfault.com/img/bVbeuqR?w=427&h=264)

### 8.1.6 ThreadB从原阻塞处继续向下执行

ThreadB被唤醒后，从原阻塞处继续向下执行，这个过程和上面完全一样。

**setHeadAndPropagate**方法把ThreadB结点变为头结点，并根据传播状态判断是否要唤醒并释放后继结点：

①将ThreadB变成头结点

![clipboard.png](https://segmentfault.com/img/bVbeurc?w=167&h=264)

②调用**doReleaseShared**方法，释放并唤醒后继结点（此时没有后继结点了，则直接break）：

最终队列状态如下：

![clipboard.png](https://segmentfault.com/img/bVbeun4?w=167&h=231)

## 8.2 总结

AQS的共享功能，通过钩子方法**tryAcquireShared**暴露，与独占功能最主要的区别就是：

共享功能的结点，一旦被唤醒，会向队列后部传播（Propagate）状态，以实现共享结点的连续唤醒。这也是共享的含义，当锁被释放时，所有持有该锁的共享线程都会被唤醒，并从等待队列移除。

# 9 ReentrantReadWriteLock

本章将会从`ReentrantReadWriteLock`出发，给出其内部利用AQS框架的实现原理。

ReentrantReadWriteLock（以下简称RRW），也就是读写锁，是一个比较特殊的同步器，特殊之处在于其对同步状态State的定义与ReentrantLock、CountDownLatch都很不同。通过RRW的分析，我们可以更深刻的了解AQS框架的设计思想，以及对**“什么是资源？如何定义资源是否可以被访问？”**这一命题有更深刻的理解。

## 9.1 RRW的公平策略原理

假设现在有4个线程，ThreadA、ThreadB、ThreadC、ThreadD。

初始时，构造RRM对象：

```java
private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
private final Lock r = rwl.readLock();
private final Lock w = rwl.writeLock();
```

执行流程：

```java
// ThreadA调用读锁的lock()方法
// ThreadB调用读锁的lock()方法
// ThreadC调用写锁的lock()方法
// ThreadD调用读锁的lock()方法
```

### 9.1.1 RRW对象的创建

和ReentrantLock类似，ReentrantReadWriteLock的构造器可以选择公平/非公平策略（默认为非公平策略），RRW内部的`FairSync`、`NonfairSync`是AQS的两个子类，分别代表了实现公平策略和非公平策略的同步器：

ReentrantReadWriteLock提供了方法，分别获取读锁/写锁：

![clipboard.png](https://segmentfault.com/img/bVbeusU?w=562&h=167)

`ReentrantReadWriteLock.ReadLock`和`ReentrantReadWriteLock.WriteLock`其实就是两个实现了Lock接口的内部类:

### 9.1.2 ThreadA调用读锁的lock()方法

读锁其实是一种共享锁，实现了AQS的共享功能API，可以看到读锁的内部就是调用了AQS的**acquireShared**方法，该方法前面几章我们已经见过太多次了：

关键来看下ReentrantReadWriteLock是如何实现**tryAcquireShared**方法的：

读锁获取成功的条件如下：

1. 写锁没有被其它线程占用（可被当前线程占用，这种情况属于锁降级）
2. 等待队列中的队首没有其它线程（公平策略）
3. 读锁重入次数没有达到最大值
4. CAS操作修改同步状态值State成功

![clipboard.png](https://segmentfault.com/img/bVbeus9?w=1000&h=771)

如果CAS操作失败，会调用**fullTryAcquireShared**方法，自旋修改State值：

ThreadA调用完**lock**方法后，等待队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeutj?w=160&h=188)

此时：写锁数量：0，读锁数量：1

### 9.1.3 ThreadB调用读锁的lock()方法

由于读锁是共享锁，且此时写锁未被占用，所以此时ThreadB也可以拿到读锁：

ThreadB调用完**lock**方法后，等待队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeutj?w=160&h=188)

此时：写锁数量：0，读锁数量：2

### 9.1.4 ThreadC调用写锁的lock()方法

写锁其实是一种独占锁，实现了AQS的独占功能API，可以看到写锁的内部就是调用了AQS的acquire方法，该方法前面几章我们已经见过太多次了：

关键来看下ReentrantReadWriteLock是如何实现**tryAcquire**方法的，并没有什么特别，就是区分了两种情况：

1. 当前线程已经持有写锁
2. 写锁未被占用

![clipboard.png](https://segmentfault.com/img/bVbeutE?w=1145&h=488)

ThreadC调用完lock方法后，由于存在使用中的读锁，所以会调用**acquireQueued**并被加入等待队列，这个过程就是独占锁的请求过程，等待队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeutS?w=490&h=296)

此时：写锁数量：0，读锁数量：2

### 9.1.5 ThreadD调用读锁的lock()方法

这个过程和ThreadA和ThreadB几乎一样，读锁是共享锁，可以重复获取，但是有一点区别：

由于等待队列中已经有其它线程（ThreadC）排在当前线程前，所以**readerShouldblock**方法会返回true，这是公平策略的含义。

虽然获取失败了，但是后续调用**fullTryAcquireShared**方法，自旋修改State值，正常情况下最终修改成功，代表获取到读锁：

最终等待队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeutS?w=490&h=296)

此时：写锁数量：0，读锁数量：3

### 9.1.6 ThreadA释放读锁

内部就是调用了AQS的**releaseShared**方法，该方法前面几章我们已经见过太多次了：

关键来看下ReentrantReadWriteLock是如何实现**tryReleaseShared**方法的，没什么特别的，就是将读锁数量减1：

![clipboard.png](https://segmentfault.com/img/bVbeuvs?w=752&h=774)

此时：写锁数量：0，读锁数量：2

### 9.1.7 ThreadB释放读锁

和ThreadA的释放完全一样，此时：写锁数量：0，读锁数量：1

### 9.1.8 ThreadD释放读锁

和ThreadA的释放几乎一样，不同的是此时读锁数量为0，**tryReleaseShared**方法返回true：

此时：写锁数量：0，读锁数量：0

![clipboard.png](https://segmentfault.com/img/bVbeuv6?w=481&h=294)

因此，会继续调用**doReleaseShared**方法，**doReleaseShared**方法之前已经阐述过了，就是一个自旋操作：

![clipboard.png](https://segmentfault.com/img/bVbeup5?w=1152&h=369)

该操作会将ThreadC唤醒：

![clipboard.png](https://segmentfault.com/img/bVbeuwC?w=491&h=292)

### 9.1.9 ThreadC从原阻塞处继续向下执行

ThreadC从原阻塞处被唤醒后，进入下一次自旋操作，然后调用**tryAcquire**方法获取写锁成功，并从队列中移除:

等待队列最终状态：

![clipboard.png](https://segmentfault.com/img/bVbeuwV?w=228&h=258)

此时：写锁数量：1，读锁数量：0

### 9.1.10 ThreadC释放写锁

其实就是独占锁的释放，不再赘述。

补充一点：如果头结点后面还有等待的共享结点，会以传播的方式依次唤醒，这个过程就是共享结点的唤醒过程，并无区别。

## 9.2 总结

本章通过ReentrantReadWriteLock的公平策略，分析了RRW的源码，非公平策略分析方法也是一样的，非公平和公平的最大区别在于写锁的获取上：

在非公平策略中，写锁的获取永远不需要排队，这其实时性能优化的考虑，因为大多数情况写锁涉及的操作时间耗时要远大于读锁，频次远低于读锁，这样可以防止写线程一直处于饥饿状态。

于ReentrantReadWriteLock，最后有两点规律需要注意：

1. 当RRW的等待队列队首结点是共享结点，说明当前写锁被占用，当写锁释放时，会以传播的方式唤醒头结点之后紧邻的各个共享结点。
2. 当RRW的等待队列队首结点是独占结点，说明当前读锁被使用，当读锁释放归零后，会唤醒队首的独占结点。

ReentrantReadWriteLock的特殊之处其实就是用一个int值表示两种不同的状态（低16位表示写锁的重入次数，高16位表示读锁的使用次数），并通过两个内部类同时实现了AQS的两套API，核心部分与共享/独占锁并无什么区别。

# 10 StampedLock

StampedLock类，在JDK1.8时引入，是对读写锁ReentrantReadWriteLock的增强，该类提供了一些功能，优化了读锁、写锁的访问，同时使读写锁之间可以互相转换，更细粒度控制并发。

首先明确下，该类的设计初衷是作为一个内部工具类，用于辅助开发其它线程安全组件，用得好，该类可以提升系统性能，用不好，容易产生死锁和其它莫名其妙的问题。

## 10.1 StampedLock类简介

先来看下，为什么有了ReentrantReadWriteLock，还要引入StampedLock？

ReentrantReadWriteLock使得多个读线程同时持有读锁（只要写锁未被占用），而写锁是独占的。

但是，读写锁如果使用不当，很容易产生“饥饿”问题：

比如在读线程非常多，写线程很少的情况下，很容易导致写线程“饥饿”，虽然使用“公平”策略可以一定程度上缓解这个问题，但是“公平”策略是以牺牲系统吞吐量为代价的。

StampedLock的特点：

1. 所有获取锁的方法，都返回一个邮戳（Stamp），Stamp为0表示获取失败，其余都表示成功；
2. 所有释放锁的方法，都需要一个邮戳（Stamp），这个Stamp必须是和成功获取锁时得到的Stamp一致；
3. StampedLock是不可重入的；（如果一个线程已经持有了写锁，再去获取写锁的话就会造成死锁）
4. StampedLock有三种访问模式：
   ①Reading（读模式）：功能和ReentrantReadWriteLock的读锁类似
   ②Writing（写模式）：功能和ReentrantReadWriteLock的写锁类似
   ③Optimistic reading（乐观读模式）：这是一种优化的读模式。
5. StampedLock支持读锁和写锁的相互转换
   我们知道RRW中，当线程获取到写锁后，可以降级为读锁，但是读锁是不能直接升级为写锁的。
   StampedLock提供了读锁和写锁相互转换的功能，使得该类支持更多的应用场景。
6. 无论写锁还是读锁，都不支持Conditon等待

我们知道，在ReentrantReadWriteLock中，当读锁被使用时，如果有线程尝试获取写锁，该写线程会阻塞。
但是，在Optimistic reading中，即使读线程获取到了读锁，写线程尝试获取写锁也不会阻塞，这相当于对读模式的优化，但是可能会导致数据不一致的问题。所以，当使用Optimistic reading获取到读锁时，必须对获取结果进行校验。

## 10.2 StampedLock原理

### 10.2.1 StampedLock的内部常量

StampedLock虽然不像其它锁一样定义了内部类来实现AQS框架，但是StampedLock的基本实现思路还是利用CLH队列进行线程的管理，通过同步状态值来表示锁的状态和类型。

StampedLock内部定义了很多常量，定义这些常量的根本目的还是和ReentrantReadWriteLock一样，对同步状态值按位切分，以通过位运算对State进行操作：

对于StampedLock来说，写锁被占用的标志是第8位为1，读锁使用0-7位，正常情况下读锁数目为1-126，超过126时，使用一个名为`readerOverflow`的int整型保存超出数。

另外，StampedLock相比ReentrantReadWriteLock，对多核CPU进行了优化，可以看到，当CPU核数超过1时，会有一些自旋操作:

假设现在有三个线程：ThreadA、ThreadB、ThreadC、ThreadD。操作如下：

```java
// ThreadA调用writeLock, 获取写锁
// ThreadB调用readLock, 获取读锁
// ThreadC调用readLock, 获取读锁
// ThreadD调用writeLock, 获取写锁
// ThreadE调用readLock, 获取读锁
```

### 10.2.2 StampedLock对象的创建

tampedLock的构造器很简单，构造时设置下同步状态值：

另外，StamedLock提供了三类视图：

![clipboard.png](https://segmentfault.com/img/bVbeuAp?w=582&h=105)

这些视图其实是对StamedLock方法的封装，便于习惯了ReentrantReadWriteLock的用户使用：

例如，**ReadLockView**其实相当于`ReentrantReadWriteLock.readLock()`返回的读锁;

### 10.2.3 ThreadA调用writeLock获取写锁

来看下**writeLock**方法：获取写锁，如果获取失败则进入阻塞，注意该方法不响应中断，返回非0表示获取成功。

![clipboard.png](https://segmentfault.com/img/bVbeuAz?w=1202&h=244)

StampedLock中大量运用了位运算，这里`(s = state) & ABITS == 0L` 表示读锁和写锁都未被使用，这里写锁可以立即获取成功，然后CAS操作更新同步状态值State。

操作完成后，等待队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuAI?w=145&h=201)

注意：StampedLock中，等待队列的结点要比AQS中简单些，仅仅三种状态。

```
0：初始状态
-1：等待中
1：取消
```

另外，结点的定义中有个`cowait`字段，该字段指向一个栈，用于保存读线程，这个后续会讲到。

### 10.2.4 ThreadB调用readLock获取读锁

来看下**readLock**方法：

由于ThreadA此时持有写锁，所以ThreadB获取读锁失败，将调用**acquireRead**方法，加入等待队列：

**acquireRead**方法非常复杂，用到了大量自旋操作：

我们来分析下这个方法。

该方法会首先自旋的尝试获取读锁，获取成功后，就直接返回；否则，会将当前线程包装成一个读结点，插入到等待队列。

由于，目前等待队列还是空，所以ThreadB会初始化队列，然后将自身包装成一个读结点，插入队尾，然后跳出第一个自旋，此时，等待队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuIU?w=621&h=332)

跳出自旋后，ThreadB会继续向下执行，进入下一个自旋，在下一个自旋中，依然会再次尝试获取读锁，如果这次再获取不到，就会将前驱的等待状态置为WAITING, 表示我（当前线程）要去睡了（阻塞），到时记得叫醒我：

![clipboard.png](https://segmentfault.com/img/bVbeuIT?w=685&h=352)

最终, ThreadB进入阻塞状态:最终，等待队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuII?w=643&h=350)

### 10.2.5 ThreadC调用readLock获取读锁

这个过程和ThreadB获取读锁一样，区别在于ThreadC被包装成结点加入等待队列后，是链接到ThreadB结点的栈指针中的。调用完下面这段代码后，ThreadC会链接到以Thread B为栈顶指针的栈中：

![clipboard.png](https://segmentfault.com/img/bVbeuIB?w=760&h=554)

注意：读结点的cowait字段其实构成了一个栈，入栈的过程其实是个“头插法”插入单链表的过程。比如，再来个ThreadX读结点，则cowait链表结构为：`ThreadB - > ThreadX -> ThreadC`。最终唤醒读结点时，将从栈顶开始。

然后会在下一次自旋中，阻塞当前读线程：

最终，等待队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuIv?w=696&h=550)

可以看到，此时ThreadC结点并没有把它的前驱的等待状态置为-1，因为ThreadC是链接到栈中的，当写锁释放的时候，会从栈顶元素开始，唤醒栈中所有读结点。

### 10.2.6 ThreadD调用writeLock获取写锁

ThreadD调用**writeLock**方法获取写锁失败后（ThreadA依然占用着写锁），会调用**acquireWrite**方法，该方法整体逻辑和**acquireRead**差不多，首先自旋的尝试获取写锁，获取成功后，就直接返回；否则，会将当前线程包装成一个写结点，插入到等待队列。

插入完成后，队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuIg?w=931&h=549)

然后，进入下一个自旋，并在下一个自旋中阻塞ThreadD，最终队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuI3?w=967&h=545)

### 10.2.7 ThreadE调用readLock获取读锁

同样，由于写锁被ThreadA占用着，所以最终会调用**acquireRead**方法，在该方法的第一个自旋中，会将ThreadE加入等待队列：

![clipboard.png](https://segmentfault.com/img/bVbeuI8?w=946&h=430)

注意，由于队尾结点是写结点，所以当前读结点会直接链接到队尾；如果队尾是读结点，则会链接到队尾读结点的cowait链中。

然后进入第二个自旋，阻塞ThreadE，最终队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuJr?w=946&h=430)

### 10.2.8 ThreadA调用unlockWrite释放写锁

通过CAS操作，修改State成功后，会调用**release**方法唤醒等待队列的队首结点：

**release**方法非常简单，先将头结点的等待状态置为0，表示即将唤醒后继结点，然后立即唤醒队首结点：

此时，等待队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuJA?w=946&h=430)

### 10.2.9 ThreadB被唤醒后继续向下执行

ThreadB被唤醒后，会从原阻塞处继续向下执行，然后开始下一次自旋：

第二次自旋时，ThreadB发现写锁未被占用，则成功获取到读锁，然后从栈顶（ThreadB的cowait指针指向的结点）开始唤醒栈中所有线程，最后返回：

最终，等待队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuJK?w=777&h=459)

### 10.2.10 ThreadC被唤醒后继续向下执行

ThreadC被唤醒后，继续执行，并进入下一次自旋，下一次自旋时，会成功获取到读锁。

注意，此时ThreadB和ThreadC已经拿到了读锁，ThreadD（写线程）和ThreadE（读线程）依然阻塞中，原来ThreadC对应的结点是个孤立结点，会被GC回收。

最终，等待队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuJT?w=798&h=291)

### 10.2.11 ThreadB和ThreadC释放读锁

ThreadB和ThreadC调用**unlockRead**方法释放读锁，CAS操作State将读锁数量减1：

注意，当读锁的数量变为0时才会调用**release**方法，唤醒队首结点：

队首结点（ThreadD写结点被唤醒），最终等待队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuJ2?w=791&h=308)

### 10.2.12 ThreadD被唤醒后继续向下执行

ThreadD会从原阻塞处继续向下执行，并在下一次自旋中获取到写锁，然后返回:

最终，等待队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuKk?w=506&h=291)

### 10.2.13 ThreadD调用unlockWrite释放写锁

ThreadD释放写锁的过程和步骤8完全相同，会调用**unlockWrite**唤醒队首结点（ThreadE）。

![clipboard.png](https://segmentfault.com/img/bVbeuKu?w=487&h=288)

ThreadE被唤醒后会从原阻塞处继续向下执行，但由于ThreadE是个读结点，所以同时会唤醒cowait栈中的所有读结点，过程和步骤9完全一样。最终，等待队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbeuKP?w=215&h=258)

至此，全部执行完成。

## 10.3 StampedLock总结

StampedLock的等待队列与RRW的CLH队列相比，有以下特点：

1. 当入队一个线程时，如果队尾是读结点，不会直接链接到队尾，而是链接到该读结点的cowait链中，cowait链本质是一个栈；
2. 当入队一个线程时，如果队尾是写结点，则直接链接到队尾；
3. 唤醒线程的规则和AQS类似，都是首先唤醒队首结点。区别是StampedLock中，当唤醒的结点是读结点时，会唤醒该读结点的cowait链中的所有读结点（顺序和入栈顺序相反，也就是后进先出）。

另外，StampedLock使用时要特别小心，避免锁重入的操作，在使用乐观读锁时也需要遵循相应的调用模板，防止出现数据不一致的问题。

