集合框架，是指`java.util.concurrent`包下的一些同步集合类，按类型划分可以分为：**符号表**、**队列**、**Set集合**、**列表**四大类，每个类都有自己适合的使用场景，整个juc-collections集合框架的结构如下图：

![clipboard.png](https://segmentfault.com/img/bVbfHAm?w=1449&h=387)

其中阻塞队列的分类及特性如下表：

| 队列特性 | 有界队列           | 近似无界队列                             | 无界队列            | 特殊队列                          |
| :------- | :----------------- | :--------------------------------------- | :------------------ | :-------------------------------- |
| 有锁算法 | ArrayBlockingQueue | LinkedBlockingQueue、LinkedBlockingDeque | /                   | PriorityBlockingQueue、DelayQueue |
| 无锁算法 | /                  | /                                        | LinkedTransferQueue | SynchronousQueue                  |

# 1 ConcurrentHashMap

## 1.1 ConcurrentHashMap类简介

`ConcurrentHashMap`是在JDK1.5时，J.U.C引入的一个同步集合工具类，顾名思义，这是一个线程安全的HashMap。不同版本的ConcurrentHashMap，内部实现机制千差万别，本节所有的讨论基于JDK1.8。

**ConcurrentHashMap**的类继承关系并不复杂：

ConcurrentHashMap继承了**AbstractMap**，这是一个`java.util`包下的抽象类，提供Map接口的骨干实现，以最大限度地减少实现Map这类数据结构时所需的工作量，一般来讲，如果需要重复造轮子——自己来实现一个Map，那一般就是继承AbstractMap。

另外，**ConcurrentHashMap**实现了`ConcurrentMap`这个接口，ConcurrentMap是在JDK1.5时随着J.U.C包引入的，这个接口其实就是提供了一些针对Map的原子操作：

## 1.2 ConcurrentHashMap基本结构

我们先来看下`ConcurrentHashMap`对象的内部结构究竟什么样的：

![clipboard.png](https://segmentfault.com/img/bVbhW1C?w=855&h=486)

### 1.2.1 基本结构

**ConcurrentHashMap**内部维护了一个`Node`类型的数组，也就是**table**：

数组的每一个位置`table[i]`代表了一个桶，当插入键值对时，会根据键的hash值映射到不同的桶位置，table一共可以包含**4种不同类型**的桶：**Node**、**TreeBin**、**ForwardingNode**、**ReservationNode**。上图中，不同的桶用不同颜色表示。可以看到，有的桶链接着**链表**，有的桶链接着**树**，这也是JDK1.8中ConcurrentHashMap的特殊之处，后面会详细讲到。

需要注意的是：**TreeBin**所链接的是一颗红黑树，红黑树的结点用**TreeNode**表示，所以ConcurrentHashMap中实际上一共有**五种不同类型**的Node结点。

之所以用**TreeBin**而不是直接用**TreeNode**，是因为红黑树的操作比较复杂，包括构建、左旋、右旋、删除，平衡等操作，用一个代理结点TreeBin来包含这些复杂操作，其实是一种“职责分离”的思想。另外TreeBin中也包含了一些加/解锁的操作。

在JDK1.8之前，ConcurrentHashMap采用了分段锁的设计思路，以减少热点域的冲突。JDK1.8时不再延续，转而直接对每个桶加锁，并用“红黑树”链接冲突结点。

### 1.2.2 结点定义

上一节提到，**ConcurrentHashMap**一共包含5种结点，我们来看下各个结点的定义和作用。

**1、Node结点**

Node结点的定义非常简单，也是其它四种类型结点的父类。

默认链接到`table[i]`——桶上的结点就是Node结点。

当出现hash冲突时，Node结点会首先以**链表**的形式链接到table上，当结点数量超过一定数目时，链表会转化为红黑树。因为链表查找的平均时间复杂度为`O(n)`，而红黑树是一种平衡二叉树，其平均时间复杂度为`O(logn)`。

**2、TreeNode结点**

TreeNode就是红黑树的结点，TreeNode不会直接链接到`table[i]`——桶上面，而是由TreeBin链接，TreeBin会指向红黑树的根结点。

**3、TreeBin结点**

TreeBin相当于TreeNode的代理结点。TreeBin会直接链接到`table[i]`——桶上面，该结点提供了一系列红黑树相关的操作，以及加锁、解锁操作。hash值固定为-3

**4、ForwardingNode结点**

ForwardingNode结点仅仅在扩容时才会使用

ForwardingNode是一种临时结点，在扩容进行中才会出现，hash值固定为-1，且不存储实际数据。
 * 如果旧table数组的一个hash桶中全部的结点都迁移到了新table中，则在这个桶中放置一个ForwardingNode。
 * 读操作碰到ForwardingNode时，将操作转发到扩容后的新table数组上去执行；写操作碰见它时，则尝试帮助扩容。

**5、ReservationNode结点**

保留结点，ConcurrentHashMap中的一些特殊方法会专门用到该类结点。

hash值固定为-3， 不保存实际数据

 * 只在computeIfAbsent和compute这两个函数式API中充当占位符加锁使用

## 1.3 ConcurrentHashMap的构造

**ConcurrentHashMap**提供了**五个构造器**，这五个构造器内部最多也只是计算了下table的初始容量大小，并没有进行实际的创建table数组的工作：ConcurrentHashMap，采用了一种**“懒加载”**的模式，只有到**首次插入键值对**的时候，才会真正的去初始化table数组。

1. 空构造器
2. 指定table初始容量的构造器
3. 根据已有的Map构造
4. 指定table初始容量和负载因子的构造器
5. 指定table初始容量、负载因子、并发级别的构造器

注意：并发级别只是为了兼容JDK1.8以前的版本，并不是实际的并发级别，负载因子也不是实际的负载因子。这两个都失去了原有的意义，仅仅对初始容量有一定的控制作用

我们再看下ConcurrentHashMap内部定义了哪些常量/字段，先大致熟悉下这些常量/字段，后面结合具体的方法分析就能相对容易地理解这些常量/字段的含义了。

**常量 :**

```java
/**
 * 最大容量.
 */
private static final int MAXIMUM_CAPACITY = 1 << 30;

/**
 * 默认初始容量
 */
private static final int DEFAULT_CAPACITY = 16;

/**
 * The largest possible (non-power of two) array size.
 * Needed by toArray and related methods.
 */
static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

/**
 * 负载因子，为了兼容JDK1.8以前的版本而保留。
 * JDK1.8中的ConcurrentHashMap的负载因子恒定为0.75
 */
private static final float LOAD_FACTOR = 0.75f;

/**
 * 链表转树的阈值，即链接结点数大于8时， 链表转换为树.
 */
static final int TREEIFY_THRESHOLD = 8;

/**
 * 树转链表的阈值，即树结点树小于6时，树转换为链表.
 */
static final int UNTREEIFY_THRESHOLD = 6;

/**
 * 在链表转变成树之前，还会有一次判断：
 * 即只有键值对数量大于MIN_TREEIFY_CAPACITY，才会发生转换。
 * 这是为了避免在Table建立初期，多个键值对恰好被放入了同一个链表中而导致不必要的转化。
 */
static final int MIN_TREEIFY_CAPACITY = 64;

/**
 * 在树转变成链表之前，还会有一次判断：
 * 即只有键值对数量小于MIN_TRANSFER_STRIDE，才会发生转换.
 */
private static final int MIN_TRANSFER_STRIDE = 16;

/**
 * 用于在扩容时生成唯一的随机数.
 */
private static int RESIZE_STAMP_BITS = 16;

/**
 * 可同时进行扩容操作的最大线程数.
 */
private static final int MAX_RESIZERS = (1 << (32 - RESIZE_STAMP_BITS)) - 1;

/**
 * The bit shift for recording size stamp in sizeCtl.
 */
private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;

static final int MOVED = -1;                // 标识ForwardingNode结点（在扩容时才会出现，不存储实际数据）
static final int TREEBIN = -2;              // 标识红黑树的根结点
static final int RESERVED = -3;             // 标识ReservationNode结点（）
static final int HASH_BITS = 0x7fffffff;    // usable bits of normal node hash

/**
 * CPU核心数，扩容时使用
 */
static final int NCPU = Runtime.getRuntime().availableProcessors();
```

**字段 :**

```java
/**
 * Node数组，标识整个Map，首次插入元素时创建，大小总是2的幂次.
 */
transient volatile Node<K, V>[] table;

/**
 * 扩容后的新Node数组，只有在扩容时才非空.
 */
private transient volatile Node<K, V>[] nextTable;

/**
 * 控制table的初始化和扩容.
 * 0  : 初始默认值
 * -1 : 有线程正在进行table的初始化
 * >0 : table初始化时使用的容量，或初始化/扩容完成后的threshold
 * -(1 + nThreads) : 记录正在执行扩容任务的线程数
 */
private transient volatile int sizeCtl;

/**
 * 扩容时需要用到的一个下标变量.
 */
private transient volatile int transferIndex;

/**
 * 计数基值,当没有线程竞争时，计数将加到该变量上。类似于LongAdder的base变量
 */
private transient volatile long baseCount;

/**
 * 计数数组，出现并发冲突时使用。类似于LongAdder的cells数组
 */
private transient volatile CounterCell[] counterCells;

/**
 * 自旋标识位，用于CounterCell[]扩容时使用。类似于LongAdder的cellsBusy变量
 */
private transient volatile int cellsBusy;

// 视图相关字段
private transient KeySetView<K, V> keySet;
private transient ValuesView<K, V> values;
private transient EntrySetView<K, V> entrySet;
```

## 1.4 ConcurrentHashMap的put操作

我们来看下**ConcurrentHashMap**如何插入一个元素：put方法。

put方法内部调用了`putVal`这个私有方法：

`putVal`的逻辑还是很清晰的，首先根据**key**计算**hash**值，然后通过**hash**值与**table**容量进行运算，计算得到key所映射的索引——也就是对应到**table**中桶的位置。

这里需要注意的是计算索引的方式：`i = (n - 1) & hash`

`n - 1 == table.length - 1`，`table.length` 的大小必须为**2的幂次**的原因就在这里。

读者可以自己计算下，当`table.length`为2的幂次时，`(table.length-1)`的二进制形式的特点是**除最高位外全部是1**，配合这种索引计算方式可以**实现key在table中的均匀分布，减少hash冲突**——出现hash冲突时，结点就需要以链表或红黑树的形式链接到table[i]，这样无论是插入还是查找都需要额外的时间。

------

putVal方法一共处理四种情况：

### 1.4.1 首次初始化table —— 懒加载

之前讲构造器的时候说了，**ConcurrentHashMap**在构造的时候并不会初始化table数组，首次初始化就在这里通过**initTable**方法完成：

**initTable**方法就是将**sizeCtl**字段的值（ConcurrentHashMap对象在构造时设置）作为table的大小。
需要注意的是这里的`n - (n >>> 2)`，其实就是`0.75 * n`，sizeCtl 的值最终需要变更为`0.75 * n`，相当于设置了**threshold**。

### 1.4.2 table[i]对应的桶为空

最简单的情况，直接CAS操作占用桶`table[i]`即可。

### 1.4.3 发现**ForwardingNode**结点，说明此时table正在扩容，则尝试协助进行数据迁移

**ForwardingNode**结点是ConcurrentHashMap中的五类结点之一，相当于一个占位结点，表示当前table正在进行扩容，当前线程可以尝试协助数据迁移。

扩容和数据迁移是ConcurrentHashMap中最复杂的部分，我们会在下一章专门讨论。

### 1.4.4 出现hash冲突,也就是table[i]桶中已经有了结点

当两个不同key映射到同一个`table[i]`桶中时，就会出现这种情况：

- 当table[i]的结点类型为Node——链表结点时，就会将新结点以**“尾插法”**的形式插入链表的尾部。
- 当table[i]的结点类型为TreeBin——红黑树代理结点时，就会将新结点通过红黑树的插入方式插入。

------

**putVal**方法的最后，涉及将链表转换为红黑树 —— **treeifyBin** ，**但实际情况并非立即就会转换，当table的容量小于64时，出于性能考虑，只是对table数组扩容1倍**——**tryPresize**：

## 1.5 ConcurrentHashMap的get操作

我们来看下ConcurrentHashMap如何根据key来查找一个元素：

**get**方法的逻辑很简单，首先根据key的hash值计算映射到table的哪个桶——`table[i]`。

1. 如果table[i]的key和待查找key相同，那直接返回；
2. 如果table[i]对应的结点是特殊结点（hash值小于0），则通过find方法查找；
3. 如果table[i]对应的结点是普通链表结点，则按链表方式查找。

关键是第二种情况，不同结点的find查找方式有所不同，我们来具体看下：

### 1.5.1 Node结点的查找

当槽`table[i]`被普通**Node**结点占用，说明是链表链接的形式，直接从链表头开始查找：

### 1.5.2 TreeBin结点的查找

TreeBin的查找比较特殊，我们知道当槽`table[i]`被TreeBin结点占用时，说明链接的是一棵红黑树。由于红黑树的插入、删除会涉及整个结构的调整，所以通常存在读写并发操作的时候，是需要加锁的。

ConcurrentHashMap采用了一种**类似读写锁**的方式：当线程持有写锁（修改红黑树）时，如果读线程需要查找，不会像传统的读写锁那样阻塞等待，而是转而以链表的形式进行查找（TreeBin本身时Node类型的子类，所有拥有Node的所有字段）

从根结点开始遍历查找，找到“相等”的结点就返回它，没找到就返回null，当存在写锁时，以链表方式进行查找

两种特殊情况下以链表的方式进行查找:

1. 有线程正持有写锁，这样做能够不阻塞读线程
2. 有线程等待获取写锁，不再继续加读锁，相当于“写优先”模式

### 1.5.3 ForwardingNode结点的查找

**ForwardingNode**是一种临时结点，在扩容进行中才会出现，所以查找也在扩容的table上进行：

### 1.5.4 ReservationNode结点的查找

ReservationNode是保留结点，不保存实际数据，所以直接返回null：

## 1.6 ConcurrentHashMap的计数

### 1.6.1 计数原理

我们来看下**ConcurrentHashMap**是如何计算键值对的数目的：

size方法内部实际调用了**sumCount**方法：

可以看到，最终键值对的数目其实是通过下面这个公式计算的：
$$
sum=baseCount+\sum_{i=0}^{n}CounterCell[i]
$$
没错，ConcurrentHashMap的计数其实延用了LongAdder分段计数的思路，只不过ConcurrentHashMap并没有在内部直接使用LongAdder，而是差不多copy了一份和LongAdder类似的代码：

```java
/**
 * 计数基值,当没有线程竞争时，计数将加到该变量上。类似于LongAdder的base变量
 */
private transient volatile long baseCount;

/**
 * 计数数组，出现并发冲突时使用。类似于LongAdder的cells数组
 */
private transient volatile CounterCell[] counterCells;

/**
 * 自旋标识位，用于CounterCell[]扩容时使用。类似于LongAdder的cellsBusy变量
 */
private transient volatile int cellsBusy;
```

我们来看下**CounterCell**这个槽对象——出现并发冲突时，每个线程会根据自己的hash值找到对应的槽位置：

### 1.6.2 addCount的实现

回顾之前的**putval**方法的最后，当插入一对键值对后，通过**addCount**方法将计数值为加1：

我们来看下**addCount**的具体实现（后半部分涉及扩容，暂且不看）：

首先，如果counterCells为null，说明之前一直没有出现过冲突，直接将值累加到baseCount上；
否则，尝试更新`counterCells[i]`中的值，更新成功就退出。失败说明槽中也出现了并发冲突，可能涉及槽数组——counterCells的扩容，所以调用**fullAddCount**方法。

fullAddCount的逻辑和LongAdder中的longAccumulate几乎完全一样，

## 1.7 ConcurrentHashMap扩容

### 1.7.1 扩容的基本思路

JDK1.8中，**ConcurrentHashMap**最复杂的部分就是扩容/数据迁移，涉及多线程的合作和rehash。我们先来考虑下一般情况下，如何对一个Hash表进行扩容。

Hash表的扩容，一般都包含两个步骤：

**①table数组的扩容**

table数组的扩容，一般就是新建一个2倍大小的槽数组，这个过程通过由一个单线程完成，且不允许出现并发。

**②数据迁移**

所谓数据迁移，就是把旧table中的各个槽中的结点重新分配到新table中。比如，单线程情况下，可以遍历原来的table，然后put到新table中。

这一过程通常涉及到槽中key的**rehash**，因为key映射到桶的位置与table的大小有关，新table的大小变了，key映射的位置一般也会变化。

**ConcurrentHashMap**在处理rehash的时候，并不会重新计算每个key的hash值，而是利用了一种很巧妙的方法。我们在上一篇说过，ConcurrentHashMap内部的table数组的大小必须为**2的幂次**，原因是让key均匀分布，减少冲突，这只是其中一个原因。另一个原因就是：

当table数组的大小为2的幂次时，通过`key.hash & table.length-1`这种方式计算出的索引`i`，当table扩容后（2倍），新的索引要么在原来的位置`i`，要么是`i+n`。

我们来看个例子：

![clipboard.png](https://segmentfault.com/img/bVbf0jg?w=1607&h=427)

上图中：

扩容前，table数组大小为16，key1和key2映射到同一个索引5；

扩容后，table数组的大小变成 **2\*16=32** ，key1的索引不变，key2的索引变成 **5+16=21**。

而且还有一个特点，**扩容后key对应的索引如果发生了变化，那么其变化后的索引最高位一定是1**（见扩容后key2的最高位）。

这种处理方式非常利于扩容时多个线程同时进行的数据迁移操作，因为旧table的各个桶中的结点迁移不会互相影响，所以就可以用**“分治”**的方式，将整个table数组划分为很多部分，每一部分包含一定区间的桶，每个数据迁移线程处理各自区间中的结点，对多线程同时进行数据迁移非常有利，后面我们会详细介绍。

### 1.7.2 扩容时机

我们再来看下，**ConcurrentHashMap**何时会发生扩容。

在上篇文章中，我们提到过，当往Map中插入结点时，如果链表的结点数目超过一定阈值，就会触发`链表 -> 红黑树`的转换：

现在，我们来分析下**treeifyBin**这个红黑树化的操作：

1. CASE 1: table的容量 < MIN_TREEIFY_CAPACITY(64)时，直接进行table扩容，不进行红黑树转换
2. CASE 2: table的容量 ≥ MIN_TREEIFY_CAPACITY(64)时，进行链表 -> 红黑树的转换

第一个分支中，还会再对**table**数组的长度进行一次判断：如果table长度小于阈值**MIN_TREEIFY_CAPACITY**——默认64，则会调用**tryPresize**方法把数组长度扩大到原来的两倍。

从代码也可以看到，链表 -> 红黑树这一转换并不是一定会进行的，table长度较小时，CurrentHashMap会首先选择扩容，而非立即转换成红黑树。

来看下**tryPresize**方法如何执行扩容：

- CASE 1: table还未初始化，则先进行初始化
- CASE2: c <= sc说明已经被扩容过了；n >= MAXIMUM_CAPACITY说明table数组已达到最大容量
- CASE3: 进行table扩容，`CASE3`其实分为两种情况：
  - 已经有其它线程正在执行扩容了，则当前线程会尝试协助“数据迁移”；（多线程并发）
  - 没有其它线程正在执行扩容，则当前线程自身发起扩容。（单线程）

注意：这两种情况都是调用了transfer方法，通过第二个入参nextTab进行区分（nextTab表示扩容后的新table数组，如果为null，表示首次发起扩容）。第二种情况下，是通过CAS和移位运算来保证仅有一个线程能发起扩容。

## 1.7.3 扩容的原理

我们来看下**transfer**方法，这个方法可以被多个线程同时调用，也是**“数据迁移”**的核心操作方法：

**tranfer**方法的开头，会计算出一个`stride`变量的值，这个stride其实就是每个线程处理的桶区间，也就是步长：

stride可理解成“步长”，即数据迁移时，每个线程要负责旧table中的多少个桶

首次扩容时，会将table数组变成原来的2倍：

整个**transfer**方法几乎都在一个自旋操作中完成，从右往左开始进行数据迁移，transfer的退出点是当某个线程处理完最后的table区段——`table[0,stride-1]`。

------

transfer方法主要包含**4个分支**，即对4种不同情况进行处理，我们按照难易程度来解释下各个分支所做的事情：

### CASE2：桶table[i]为空

当旧table的桶`table[i] == null`，说明原来这个桶就没有数据，那就直接尝试放置一个**ForwardingNode**，表示这个桶已经处理完成。

注：**ForwardingNode**我们在上一篇提到过，主要做占用位，多线程进行数据迁移时，其它线程看到这个桶中是ForwardingNode结点，就知道有线程已经在数据迁移了。

另外，当最后一个线程完成迁移任务后，会遍历所有桶，看看是否都是ForwardingNode，如果是，那么说明整个扩容/数据迁移的过程就完成了。

### CASE3：桶table[i]已迁移完成

没什么好说的，就是桶已经用**ForwardingNode**结点占用了，表示该桶的数据都迁移完了。

### CASE4：桶table[i]未迁移完成

如果旧桶的数据未迁移完成，就要进行迁移，这里根据桶中结点的类型分为：链表迁移、红黑树迁移。

**①链表迁移**

链表迁移的过程如下，首先会遍历一遍原链表，找到最后一个相邻`runBit`不同的结点。
`runbit`是根据`key.hash`和旧table长度`n`进行与运算得到的值，由于table的长度为2的幂次，所以`runbit`只可能为0或最高位为1

然后，会进行第二次链表遍历，按照第一次遍历找到的结点为界，将原链表分成2个子链表，再链接到新table的槽中。可以看到，新table的索引要么是`i`，要么是`i+n`，这里就利用了上一节说的ConcurrentHashMap的rehash特点。

**②红黑树迁移**

红黑树的迁移按照链表遍历的方式进行，当链表结点超过/小于阈值时，涉及`红黑树<->链表`的相互转换：

下面的过程会先以链表方式遍历，复制所有结点，然后根据高低位组装成两个链表；然后看下是否需要进行红黑树转换，最后放到新table对应的桶中

### CASE1：当前是最后一个迁移任务或出现扩容冲突

我们刚才说了，调用**transfer**的线程会自动领用某个区段的桶，进行数据迁移操作，当区段的初始索引i变成负数的时候，说明当前线程处理的其实就是最后剩下的桶，并且处理完了。

所以首先会更新`sizeCtl`变量，将扩容线程数减1，然后会做一些收尾工作：
设置table指向扩容后的新数组，遍历一遍旧数组，确保每个桶的数据都迁移完成——被ForwardingNode占用。

另外，可能在扩容过程中，出现扩容冲突的情况，比如多个线程领用了同一区段的桶，这时任何一个线程都不能进行数据迁移。



# 2 ConcurrentSkipListMap

## 2.1 ConcurrentSkipListMap简介

在正式讲ConcurrentSkipListMap之前，我们先来看下ConcurrentSkipListMap的类继承图：

我们知道，一般的Map都是无序的，也就是只能通过键的hash值进行定位。JDK为了实现有序的Map，提供了一个**SortedMap**接口，SortedMap提供了一些根据键范围进行查找的功能，比如返回整个Map中 key最小/大的键、返回某个范围内的子Map视图等等。

为了进一步对有序Map进行增强，JDK又引入了**NavigableMap**接口，该接口进一步扩展了SortedMap的功能，提供了根据指定Key返回最接近项、按升序/降序返回所有键的视图等功能。

同时，也提供了一个基于NavigableMap的实现类——**TreeMap**，TreeMap底层基于红黑树设计，是一种有序的Map。

JDK1.6时，为了对高并发环境下的有序Map提供更好的支持，J.U.C新增了一个**ConcurrentNavigableMap**接口，ConcurrentNavigableMap很简单，它同时实现了NavigableMap和ConcurrentMap接口：

**ConcurrentNavigableMap**接口提供的功能也和NavigableMap几乎完全一致，很多方法仅仅是返回的类型不同：

J.U.C提供了基于**ConcurrentNavigableMap**接口的一个实现——`ConcurrentSkipListMap`。

ConcurrentSkipListMap可以看成是并发版本的TreeMap，但是和TreeMap不同是，ConcurrentSkipListMap并不是基于红黑树实现的，其底层是一种类似**跳表（Skip List）**的结构。

### 2.1.1 什么是Skip List

**Skip List**（以下简称跳表），是一种类似链表的数据结构，其查询/插入/删除的时间复杂度都是`O(logn)`。

我们知道，通常意义上的链表是不能支持随机访问的（通过索引快速定位），其查找的时间复杂度是`O(n)`，而数组这一可支持随机访问的数据结构，虽然查找很快，但是插入/删除元素却需要移动插入点后的所有元素，时间复杂度为`O(n)`。

为了解决这一问题，引入了树结构，树的增删改查效率比较平均，一棵平衡二叉树（AVL）的增删改查效率一般为`O(logn)`，比如工业上常用红黑树作为AVL的一种实现。

但是，AVL的实现一般都比较复杂，插入/删除元素可能涉及对整个树结构的修改，特别是并发环境下，通常需要全局锁来保证AVL的线程安全，于是又出现了一种类似链表的数据结构——**跳表**。

### 2.1.2 Skip List示例

在讲**Skip List**之前，我们先来看下传统的单链表：
![clipboard.png](https://segmentfault.com/img/bVbf4hy?w=1291&h=103)

上图的单链表中（省去了结点之间的链接），当想查找7、15、46这三个元素时，必须从头指针head开始，遍历整个单链表，其查找复杂度很低，为`O(n)`。

来看下**Skip List**的数据结构是什么样的：
![clipboard.png](https://segmentfault.com/img/bVbf4hM?w=1634&h=203)

上图是Skip List一种可能的结构，它分了2层，假设我们要查找**“15”**这个元素，那么整个步骤如下：

1. 从头指针**head**开始，找到第一个结点的最上层，发现其指向的下个结点值为8，小于15，则直接从1结点跳到8结点。
2. 8结点最上层指向的下一结点值为18，大于15，则从8结点的下一层开始查找。
3. 从8结点的最下层一直向后查找，依次经过10、13，最后找到15结点。

上述整个查找路径如下图标黄部分所示：
![clipboard.png](https://segmentfault.com/img/bVbf4hS?w=2730&h=335)

同理，如果要查找**“46”**这个元素，则整个查找路径如下图标黄部分所示：
![clipboard.png](https://segmentfault.com/img/bVbf4hV?w=2767&h=328)

------

上面就是跳跃表的基本思想了，每个结点不仅仅只包含指向下一个结点的指针，可能还包含很多个其它指向后续结点的指针。并且，一个结点本身可以看成是一个链表（自上向下链接）。这样就可以跳过一些不必要的结点，从而加快查找、删除等操作，这其实是一种**“空间换时间”**的算法设计思想。

**那么一个结点可以包含多少层呢？** 比如，Skip List也可能是下面这种包含3层的结构(在一个3层Skip List中查找元素“46”)：
![clipboard.png](https://segmentfault.com/img/bVbf4hX?w=2777&h=492)

层数是根据一种随机算法得到的，为了不让层数过大，还会有一个最大层数**MAX_LEVEL**限制，随机算法生成的层数不得大于该值。后面讲**ConcurrentSkipListMap**时，我们会具体分析。

以上就是**Skip List**的基本思想了，总结起来，有以下几点：

1. 跳表由很多层组成；
2. 每一层都是一个有序链表；
3. 对于每一层的任意结点，不仅有指向下一个结点的指针，也有指向其下一层的指针。

## 2.2 ConcurrentSkipListMap的内部结构

介绍完了跳表，再来看**ConcurrentSkipListMap**的内部结构就容易得多了：

![clipboard.png](https://segmentfault.com/img/bVbf5Ih?w=1450&h=518)

**ConcurrentSkipListMap**内部一共定义了3种不同类型的结点，元素的增删改查都从最上层的head指针指向的结点开始：我们来看下这3类结点的具体定义。

**普通结点：Node**

普通结点——Node，也就是**ConcurrentSkipListMap**最底层链表中的结点，保存着实际的键值对，如果单独看底层链，其实就是一个按照Key有序排列的单链表：

**索引结点：Index**

**Index**结点是除底层链外，其余各层链表中的非头结点（见示意图中的蓝色结点）。每个Index结点包含3个指针：`down`、`right`、`node`。

down和right指针分别指向下层结点和后继结点，node指针指向其最底部的node结点。

**头索引结点：HeadIndex**

**HeadIndex**结点是各层链表的头结点，它是Index类的子类，唯一的区别是增加了一个`level`字段，用于表示当前链表的级别，越往上层，level值越大。

------

**ConcurrentSkipListMap**一共定义了4种构造器：

- 空构造器
- 指定比较器的构造器
- 从给定Map构建的构造器
- 从给定SortedMap构建的构造器

注：ConcurrentSkipListMap会基于比较器——Comparator ，来进行键Key的比较，如果构造时未指定Comparator ，那么就会按照Key的自然顺序进行比较，所谓Key的自然顺序是指key实现Comparable接口。

上述所有构造器都调用了**initialize**方法：

**initialize**方法将一些字段置初始化null，然后将head指针指向新创建的**HeadIndex**结点。初始化完成后，ConcurrentSkipListMap的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbf5ot?w=201&h=444)

其中，**head**和**BASE_HEADER**都是ConcurrentSkipListMap的字段：head表示最上层链表的头指针，base_header表示最底层链表的头指针。

## 2.3 ConcurrentSkipListMap的核心操作

### 2.3.1 put操作

**put**操作本身很简单，需要注意的是ConcurrentSkipListMap在插入键值对时，Key和Value都不能为null：

put方法内部调用了**doPut**来做实际的插入操作：

我们先不急着看**doPut**方法，而是看下其内部的`findPredecessor`方法，findPredecessor用于查找**“小于且最接近给定key”的Node结点，并且这个Node结点必须有上层结点**：

看代码不太直观，我们还是看下面这个图：

![clipboard.png](https://segmentfault.com/img/bVbf5HF?w=1440&h=596)

上图中，假设要查找的Key为72，则步骤如下：

1. 从最上方head指向的结点开始，比较①号标红的Index结点的key值，发现3小于72，则继续向右；
2. 比较②号标红的Index结点的key值，发现62小于72，则继续向右
3. 由于此时右边是null，则转而向下，一直到⑥号标红结点；
4. 由于⑥号标红结点的down字段为空（不能再往下了，已经是level1最低层了），则直接返回它的node字段指向的结点，即⑧号结点。

**注意：如果我们要查找key为59的Node结点，返回的不是Key为45的结点，而是key为23的结点。读者可以自己在纸上比划下。**

回到**doPut**方法，假设现在待插入的Key为3，则当执行完下面这段代码后，ConcurrentSkipListMap的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbf8ok?w=548&h=343)

**doPut**中的第一个循环，作用就是找到底层链表的插入点，然后插入结点（在查找过程中可能会删除一些已标记的删除结点）。

插入完成后，doPut方法并没结束，我们之前说过**ConcurrentSkipListMap**的分层数是通过一个随机数生成算法来确定，doPut的后半段，就是这个作用：判断是否需要增加层级，如果需要就在各层级中插入对应的Index结点

最终ConcurrentSkipListMap的结构如下所示：

![clipboard.png](https://segmentfault.com/img/bVbf8oW?w=1119&h=389)

### 2.3.2 remove操作

**ConcurrentSkipListMap**在删除键值对时，不会立即执行删除，而是通过引入**“标记结点”**，以**“懒删除”**的方式进行，以提高并发效率。

**remove**方法很简单，内部调用了**doRemove**方法：

还是通过示例来理解上述代码，假设现在要删除Key==23的结点，删除前ConcurrentSkipListMap的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbf8vp?w=1218&h=554)

**doRemove**方法首先会找到待删除的结点，在它和后继结点之间插入一个**value为null的标记结点**（如下图中的绿色结点），然后改变其前驱结点的指向：

![clipboard.png](https://segmentfault.com/img/bVbf8vs?w=1256&h=519)

最后，doRemove会重新调用一遍**findPredecessor**方法，解除被删除结点上的Index结点之间的引用：

![clipboard.png](https://segmentfault.com/img/bVbf8vw?w=1409&h=561)

这样Key==23的结点其实就被孤立，再后续查找或插入过程中，会被完全清除或被GC回收。

### 2.3.3 get操作

最后，我们来看下ConcurrentSkipListMap的查找操作——get方法。

内部调用了**doGet**方法：doGet方法非常简单：

首先找到“小于且最接近给定key”的Node结点，然后用了三个指针：b -> n -> f，
n用于定位最终查找的Key，然后顺着链表一步步向下查，比如查找KEY==45，则最终三个指针的位置如下：

![clipboard.png](https://segmentfault.com/img/bVbf8xX?w=1436&h=584)

# 3 ConcurrentSkipListSet

## 3.1 ConcurrentSkipListSet简介

**ConcurrentSkipListSet**，是JDK1.6时J.U.C新增的一个集合工具类，顾名思义，它是一种**SET**类型。

SET类型，在数学上称为“集合”，具有互异性、无序性的特点，也就是说SET中的任意两个元素均不相同（即不包含重复元素），且元素是无序的。

是不是感觉和HashMap有点类似？HashMap中的Key也是不能重复，且是无序的。

事实上，JDK提供的默认SET实现——`HashSet`，其实就是采用“组合”的方式——内部引用了一个HashMap对象，以此实现SET的功能。

## 3.2 ConcurrentSkipListSet原理

### 3.2.1 内部结构

**ConcurrentSkipListSet**的实现非常简单，其内部引用了一个`ConcurrentSkipListMap`对象，所有API方法均委托`ConcurrentSkipListMap`对象完成：

从上述代码可以看出，**ConcurrentSkipListSet**在构造时创建了一个ConcurrentSkipListMap对象，并由字段m引用，所以其实ConcurrentSkipListSet就是一种**跳表类型**的数据结构，其平均增删改查的时间复杂度均为`O(logn)`。

### 3.2.2 核心方法

所有操作均是委托ConcurrentSkipListMap对象完成的。重点看下`add`方法：

```java
public boolean add(E e) {
    return m.putIfAbsent(e, Boolean.TRUE) == null;
}
```

我们知道**ConcurrentSkipListMap**对键值对的要求是均不能为null，所以ConcurrentSkipListSet在插入元素的时候，用一个`Boolean.TRUE`对象（相当于一个值为true的Boolean型对象）作为value，同时`putIfAbsent`可以保证不会存在相同的Key。

所以，最终跳表中的所有Node结点的Key均不会相同，且值都是`Boolean.True`。

# 4 CopyOnWriteArrayList

## 4.1 CopyOnWriteArrayList简介

`ArrayList`是一种“列表”数据机构，其底层是通过**数组**来实现元素的**随机访问**。JDK1.5之前，如果想要在并发环境下使用“列表”，一般有以下3种方式：

1. 使用**Vector**类
2. 使用`Collections.synchronizedList`返回一个同步代理类；
3. 自己实现**ArrayList**的子类，并进行同步/加锁。

前两种方式都相当于加了一把“全局锁”，访问任何方法都需要首先获取锁。第3种方式，需要自己实现，复杂度较高。

JDK1.5时，随着J.U.C引入了一个新的集合工具类——`CopyOnWriteArrayList`：

大多数业务场景都是一种**“读多写少”**的情形，**CopyOnWriteArrayList**就是为适应这种场景而诞生的。

CopyOnWriteArrayList，运用了一种**“写时复制”**的思想。通俗的理解就是当我们需要修改（增/删/改）列表中的元素时，不直接进行修改，而是先将列表Copy，然后在新的副本上进行修改，修改完成之后，再将引用从原列表指向新列表。

这样做的好处是**读/写是不会冲突**的，可以并发进行，读操作还是在原列表，写操作在新列表。仅仅当有多个线程同时进行写操作时，才会进行同步。

## 4.2 CopyOnWriteArrayList原理

### 4.2.1 内部结构

**CopyOnWriteArrayList**的字段很简单：

```java
public class CopyOnWriteArrayList<E>
    implements List<E>, RandomAccess, Cloneable, java.io.Serializable {
    /**
     * 排它锁, 用于同步修改操作
     */
    final transient ReentrantLock lock = new ReentrantLock();
    /**
     * 内部数组
     */
    private transient volatile Object[] array;
}
```

其中，`lock`用于对修改操作进行同步，`array`就是内部实际保存数据的数组。

------

**构造器定义**

**CopyOnWriteArrayList**提供了三种不同的构造器，这三种构造器最终都是创建一个数组，并通过`setArray`方法赋给`array`字段：

- 空构造器
- 根据已有集合创建
- 根据已有数组创建

### 4.2.2 核心方法

**查询——get方法**

可以看到，**get**方法并没有加锁，直接返回了内部数组对应索引位置的值：`array[index]`

**添加——add方法**

**add**方法首先会进行加锁，保证只有一个线程能进行修改；然后会创建一个新数组（大小为`n+1`），并将原数组的值复制到新数组，新元素插入到新数组的最后；最后，将字段`array`指向新数组。

![clipboard.png](https://segmentfault.com/img/bVbgci5?w=649&h=232)

上图中，ThreadB对Array的修改由于是在新数组上进行的，所以并不会对ThreadA的读操作产生影响。

**删除——remove方法**

删除方法和插入一样，都需要先加锁（所有涉及修改元素的方法都需要先加锁，写-写不能并发），然后构建新数组，复制旧数组元素至新数组，最后将`array`指向新数组。

**其它统计方法**

```java
public int size() {
    return getArray().length;
}
public boolean isEmpty() {
    return size() == 0;
}
```

**迭代**

**CopyOnWriteArrayList**对元素进行迭代时，仅仅返回一个当前内部数组的快照，也就是说，如果此时有其它线程正在修改元素，并不会在迭代中反映出来，因为修改都是在新数组中进行的。

可以看到，上述**iterator**方法返回一个迭代器对象——`COWIterator`，COWIterator的迭代是在旧数组上进行的，当创建迭代器的那一刻就确定了，所以迭代过程中不会抛出并发修改异常——`ConcurrentModificationException`。

另外，迭代器对象也不支持修改方法，全部会抛出`UnsupportedOperationException`异常。

## 4.3 总结

**CopyOnWriteArrayList**的思想和实现整体上还是比较简单，它适用于处理**“读多写少”**的并发场景。通过上述对CopyOnWriteArrayList的分析，读者也应该可以发现该类存在的一些问题：

**1. 内存的使用**
由于CopyOnWriteArrayList使用了“写时复制”，所以在进行写操作的时候，内存里会同时存在两个array数组，如果数组内存占用的太大，那么可能会造成频繁GC,所以CopyOnWriteArrayList并不适合大数据量的场景。

**2. 数据一致性**
CopyOnWriteArrayList只能保证数据的最终一致性，不能保证数据的实时一致性——读操作读到的数据只是一份快照。所以如果希望写入的数据可以立刻被读到，那CopyOnWriteArrayList并不适合。

# 5 CopyOnWriteArraySet

## 5.1 CopyOnWriteArraySet简介

`CopyOnWriteArraySet`，是另一类适合并发环境的SET工具类，也是在JDK1.5时，随着J.U.C包一起引入的。
我们之前已经介绍过了ConcurrentSkipListSet，ConcurrentSkipListSet底层基于Skip List（跳表）实现，其操作平均时间复杂度均为`O(logn)`。

CopyOnWriteArraySet，从名字上可以看出，也是基于“**写时复制**”的思想。事实上，CopyOnWriteArraySet内部引用了一个`CopyOnWriteArrayList`对象，以“组合”方式，委托CopyOnWriteArrayList对象实现了所有API功能。

## 5.2 CopyOnWriteArraySet原理

可以看到，所有的方法都是通过委托实现的，唯一的区别就是CopyOnWriteArraySet不允许含有重复元素，所以添加元素（`add`方法）时，内部调用了CopyOnWriteArrayList的`addAllAbsent`方法。

## 5.3 总结

既然**CopyOnWriteArraySet**也是基于“写时复制”的思想，那么它的特性也和**CopyOnWriteArrayList**是类似的，归结起来，有以下几点：

1. 适合“读多写少”且数据量不大的场景。
2. 线程安全
3. 内存的使用较多
4. 迭代是对快照进行的，不会抛出`ConcurrentModificationException`，且迭代过程中不支持修改操作。

# 6 ConcurrentLinkedQueue

## 6.1 ConcurrentLinkedQueue简介

**ConcurrentLinkedQueue**是JDK1.5时随着J.U.C一起引入的一个支持并发环境的队列。从名字就可以看出来，ConcurrentLinkedQueue底层是基于链表实现的。

Doug Lea在实现ConcurrentLinkedQueue时，并没有利用锁或底层同步原语，而是完全基于**自旋+CAS**的方式实现了该队列。回想一下AQS，AQS内部的CLH等待队列也是利用了这种方式。

由于是完全基于无锁算法实现的，所以当出现多个线程同时进行修改队列的操作（比如同时入队），很可能出现CAS修改失败的情况，那么失败的线程会进入下一次自旋，再尝试入队操作，直到成功。所以，在并发量适中的情况下，ConcurrentLinkedQueue一般具有较好的性能。

## 6.2 ConcurrentLinkedQueue原理

### 6.2.1 队列结构

可以看到，**ConcurrentLinkedQueue**内部就是一个简单的单链表结构，每入队一个元素就是插入一个Node类型的结点。字段`head`指向队列头，`tail`指向队列尾，通过`Unsafe`来CAS操作字段值以及Node对象的字段值。

![clipboard.png](https://segmentfault.com/img/bVbgkZ7?w=799&h=125)

### 6.2.2 构造器定义

ConcurrentLinkedQueue包含两种构造器：

- 构建一个空队列
- 根据已有集合，构造队列

我们重点看下空构造器，通过空构造器建立的ConcurrentLinkedQueue对象，其`head`和`tail`指针并非指向`null`，而是指向一个item值为null的`Node`结点——哨兵结点，如下图：

![clipboard.png](https://segmentfault.com/img/bVbgk0G?w=120&h=130)

### 6.2.3 入队操作

元素的入队是在队尾插入元素。

ConcurrentLinkedQueue的入队代码很简单，却非常精妙：**add方法**,内部调用了offer方法，在队尾入队元素e，直到成功。

我们来分析下上面`offer方法`的实现。单线程的情况下，元素入队比较好理解，直接线性地在队首插入元素即可。现在我们假设有两个线程**ThreadA**和**ThreadB**同时进行入队操作：

**①ThreadA先单独入队两个元素9、2**

此时队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbgk03?w=459&h=125)

**②ThreadA入队元素“10”，ThreadB入队元素“25”**

此时ThreadA和ThreadB若并发执行，我们看下会发生什么：

1、ThreadA和ThreadB同时进入自旋中的以下代码块：

```java
if (q == null) {                            // CASE1: 正常情况下, 新结点直接插入到队尾
    if (p.casNext(null, newNode)) {
        // CAS竞争插入成功
        if (p != t)                         // CAS竞争失败的线程会在下一次自旋中进入该逻辑
            casTail(t, newNode);            // 重新设置队尾指针tail
        return true;
    }
    // CAS竞争插入失败,则进入下一次自旋
}
```

2、ThreadA执行cas操作（p.casNext）成功，插入新结点“10”

ThreadA执行完成后，直接返回true，队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbgk1k?w=629&h=185)

3、ThreadB执行cas操作（p.casNext）失败

由于CAS操作同时修改队尾元素，导致ThreadB操作失败，则ThreadB进入下一次自旋；

在下一次自旋中，进入以下代码块：

上述分支的作用就是让p指针重新定位到队尾结点，此时队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbgk1y?w=629&h=184)

然后ThreadB会继续下一次自旋，并再次进入以下代码块：

此时，CAS操作成功，队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbgk1C?w=799&h=184)

由于此时`p!=t` ，所以会调用`casTail`方法重新设置队尾指针：

```
casTail(t, newNode); // 重新设置队尾指针tail
```

最终队列如下：
![clipboard.png](https://segmentfault.com/img/bVbgk1M?w=799&h=125)

从上面的分析过程可以看到，由于入队元素一定是要链接到队尾的，但并发情况下队尾结点可能随时变化，所以就需要指针定位最新的队尾结点，并在入队时判断队尾结点是否改变了，如果改变了，就需要重新设置定位指针，然后在下一次自旋中继续尝试入队操作。

上面整个执行步骤有一段分支还没有覆盖到：

```java
else if (p == q)                          // CASE2: 发生了出队操作
     p = (t != (t = tail)) ? t : head;
```

这个分支只有在元素入队的同时，针对该元素也发生了“出队”操作才会执行，我们后面会分析元素的“出队”，理解了“出队”操作再回头来看这个分支就容易理解很多了。

### 6.2.4 出队操作

队列中元素的“出队”是从队首移除元素，我们来看下ConcurrentLinkedQueue是如何实现出队的：

还是通过示例来看，假设初始的队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbgk1M?w=799&h=125)

**①ThreadA先单独进行出队操作**

由于head所指的是item==null的结点，所以ThreadA会执行以下分支：

![clipboard.png](https://segmentfault.com/img/bVbgk2k?w=799&h=189)

然后进入下一次自旋，在自旋中执行以下分支，如果CAS操作成功，则移除首个有效元素，并重新设置头指针：

此时队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbgk2l?w=799&h=187)

**如果ThreadA的CAS操作失败呢？**

CAS操作失败则会进入以下分支，并重新开始自旋：

最终前面两个null结点会被GC回收，队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbgk2w?w=459&h=126)

**②ThreadA继续进行出队操作**

ThreadA继续执行“出队”操作，还是执行以下分支：

但是此时`p==h`，所以仅将头结点置`null`，这其实是一种**“懒删除”**的策略。

出队元素“2”：

![clipboard.png](https://segmentfault.com/img/bVbgk2F?w=459&h=126)

出队元素“10”：

![clipboard.png](https://segmentfault.com/img/bVbgk2I?w=459&h=187)

最终队列结果如下：

![clipboard.png](https://segmentfault.com/img/bVbgk2J?w=128&h=128)

**③ThreadA进行出队，其它线程进行入队**

这是最特殊的一种情况，当队列中只剩下一个元素时，如果同时发生出队和入队操作，会导致队列出现下面这种结构：（假设ThreadA进行出队元素“25”，ThreadB进行入队元素“11”）

![clipboard.png](https://segmentfault.com/img/bVbgk2Q?w=289&h=128)

此时tail.next=tail自身，所以ThreadB在执行入队时，会进入到offer方法的以下分支：

```java
else if (p == q)                          // CASE2: 发生了出队操作
    p = (t != (t = tail)) ? t : head;
```

## 6.3 总结

**ConcurrentLinkedQueue**使用了**自旋+CAS**的非阻塞算法来保证线程并发访问时的数据一致性。由于队列本身是一种链表结构，所以虽然算法看起来很简单，但其实需要考虑各种并发的情况，实现复杂度较高，并且ConcurrentLinkedQueue不具备实时的数据一致性，实际运用中，队列一般在生产者-消费者的场景下使用得较多，所以ConcurrentLinkedQueue的使用场景并不如阻塞队列那么多。

另外，关于ConcurrentLinkedQueue还有以下需要注意的几点：

1. ConcurrentLinkedQueue的迭代器是弱一致性的，这在并发容器中是比较普遍的现象，主要是指在一个线程在遍历队列结点而另一个线程尝试对某个队列结点进行修改的话不会抛出`ConcurrentModificationException`，这也就造成在遍历某个尚未被修改的结点时，在next方法返回时可以看到该结点的修改，但在遍历后再对该结点修改时就看不到这种变化。
2. `size`方法需要遍历链表，所以在并发情况下，其结果不一定是准确的，只能供参考。

# 7 ConcurrentLinkedDeque

## 7.1 ConcurrentLinkedDeque简介

在开始讲`ConcurrentLinkedDeque`之前，我们先来了解下**Deque**这种数据结构，我们知道Queue是一种具有**FIFO**特点的数据结构，元素只能在队首进行“入队”操作，在队尾进行“出队”操作。

而**Deque**（double-ended queue）是一种双端队列，也就是说可以在任意一端进行“入队”，也可以在任意一端进行“出队”：

Queue接口的所有方法Deque都具备，只不过队首/队尾都可以进行“出队”和“入队”操作：

| 操作类型 | 抛出异常      | 返回特殊值    |
| :------- | :------------ | :------------ |
| 队首入队 | addFirst(e)   | offerFirst(e) |
| 队首出队 | removeFirst() | pollFirst()   |
| 队首读取 | getFirst()    | peekFirst()   |
| 队尾入队 | addLast(e)    | offerLast(e)  |
| 队尾出队 | removeLast()  | pollLast()    |
| 队尾读取 | getLast()     | peekLast()    |

每种操作类型，都给出了两种方法，区别就是其中一种操作在队列的状态不满足某些要求时，会抛出异常；另一种，则直接返回特殊值（如null）。

除此之外，Deque还可以当作“栈”来使用，我们知道“栈”是一种具有**“LIFO”**特点的数据结构

Deque提供了`push`、`pop`、`peek`这三个栈方法，一般实现这三个方法时，可以利用已有方法，即有如下映射关系：

| 栈方法 | Deque方法     |
| :----- | :------------ |
| push   | addFirst(e)   |
| pop    | removeFirst() |
| peek   | peekFirst()   |

`ConcurrentLinkedDeque`是JDK1.7时，J.U.C包引入的一个集合工具类。在JDK1.7之前，除了Stack类外，并没有其它适合并发环境的“栈”数据结构。ConcurrentLinkedDeque作为双端队列，可以当作“栈”来使用，并且高效地支持并发环境。

ConcurrentLinkedDeque和ConcurrentLinkedQueue一样，采用了无锁算法，底层基于**自旋+CAS**的方式实现

## 7.2 ConcurrentLinkedDeque原理

### 7.2.1 队列结构

ConcurrentLinkedDeque的内部和ConcurrentLinkedQueue类似，不过是一个双链表结构，每入队一个元素就是插入一个Node类型的结点。字段`head`指向队列头，`tail`指向队列尾，通过Unsafe来CAS操作字段值以及Node对象的字段值。

![clipboard.png](https://segmentfault.com/img/bVbguwJ?w=799&h=123)

需要特别注意的是ConcurrentLinkedDeque包含两个特殊字段：PREV_TERMINATOR、NEXT_TERMINATOR。
这两个字段初始时都指向一个值为null的空结点，这两个字段在结点删除时使用，后面会详细介绍：

![clipboard.png](https://segmentfault.com/img/bVbguwQ?w=175&h=123)

![clipboard.png](https://segmentfault.com/img/bVbguwR?w=216&h=122)

### 7.2.2 构造器定义

ConcurrentLinkedDeque包含两种构造器：

1. 空构造器
2. 从已有集合构造队列

我们重点看下空构造器，通过空构造器建立的ConcurrentLinkedDeque对象，其head和tail指针并非指向null，而是指向一个item值为null的Node结点——哨兵结点，如下图：

![clipboard.png](https://segmentfault.com/img/bVbgk0G?w=120&h=130)

### 7.2.3 入队操作

双端队列与普通队列的入队区别是：双端队列既可以在“队尾”插入元素，也可以在“队首”插入元素。

ConcurrentLinkedDeque的入队方法有很多：`addFirst(e)`、`addLast(e)`、`offerFirst(e)`、`offerLast(e)`：

可以看到，队首“入队”其实就是调用了`linkFirst(e)`方法，而队尾“入队”是调用了 linkLast(e)方法。我们先来看下队首“入队”——linkFirst(e)：

为了便于理解，我们以示例来看：假设有两个线程ThreadA和ThreadB同时进行入队操作。

**①ThreadA先单独入队一个元素9**

队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbguxd?w=289&h=123)

**②ThreadA入队一个元素2，同时ThreadB入队一个元素10**

我们假设ThreadA操作成功，ThreadB操作失败：

ThreadA的CAS操作成功后，会进入以下判断：判断的作用就是重置head头指针，可以看到，ConcurrentLinkedDeque其实是以每次跳2个结点的方式移动指针，这主要考虑到并发环境以这种hop跳的方式可以提升效率。

此时队列的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbguxi?w=459&h=123)

注意，此时ThreadB的`p.casPrev(null, newNode)`操作失败了，所以会进入下一次自旋，在下一次自旋中继续进入CASE3。如果ThreadA的casHead操作没有完成，ThreadB就进入了下一次自旋，则会进入分支1，重置指针p指向队首。最终队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbguxj?w=629&h=123)

在队尾插入元素和队首类似，不再赘述，读者可以自己阅读源码。

### 7.2.4 出队操作

ConcurrentLinkedDeque的出队一样分为队首、队尾两种情况：`removeFirst()`、`pollFirst()`、`removeLast()`、`pollLast()`。

可以看到，两个**remove**方法其实内部都调用了对应的poll方法，我们重点看下队尾的“出队”——**pollLast**方法：

**last**方法用于寻找队尾结点，即满足`p.next == null && p.prev != p`的结点：

**pred**方法用于寻找当前结点的前驱结点（如果前驱是自身，则返回队尾结点）：

**unlink**方法断开结点的链接：

ConcurrentLinkedDeque相比ConcurrentLinkedQueue，功能更丰富，但是由于底层结构是双链表，且完全采用CAS+自旋的无锁算法保证线程安全性，所以需要考虑各种并发情况，源码比ConcurrentLinkedQueue更加难懂，留待有精力作进一步分析。

## 7.3 总结

**ConcurrentLinkedDeque**使用了**自旋+CAS**的非阻塞算法来保证线程并发访问时的数据一致性。由于队列本身是一种双链表结构，所以虽然算法看起来很简单，但其实需要考虑各种并发的情况，实现复杂度较高，并且ConcurrentLinkedDeque不具备实时的数据一致性，实际运用中，如果需要一种线程安全的栈结构，可以使用ConcurrentLinkedDeque。

另外，关于ConcurrentLinkedDeque还有以下需要注意的几点：

1. ConcurrentLinkedDeque的迭代器是弱一致性的，这在并发容器中是比较普遍的现象，主要是指在一个线程在遍历队列结点而另一个线程尝试对某个队列结点进行修改的话不会抛出ConcurrentModificationException，这也就造成在遍历某个尚未被修改的结点时，在next方法返回时可以看到该结点的修改，但在遍历后再对该结点修改时就看不到这种变化。
2. size方法需要遍历链表，所以在并发情况下，其结果不一定是准确的，只能供参考。

# 8 BlockingQueue

## 8.1 BlockingQueue简介

阻塞队列在实际应用中非常广泛，许多消息中间件中定义的队列，通常就是一种“阻塞队列”。

`ConcurrentLinkedQueue`和`ConcurrentLinkedDeque`是以非阻塞算法实现的高性能队列，其使用场景一般是在并发环境下，需要“队列”/“栈”这类数据结构时才会使用；而“阻塞队列”通常利用了“锁”来实现，也就是会阻塞调用线程，其使用场景一般是在**“生产者-消费者”**模式中，用于线程之间的数据交换或系统解耦。

“**生产者-消费者**”这种模式。在这种模式中，“生产者”和“消费者”是相互独立的，两者之间的通信需要依靠一个队列。这个队列，其实就是本文中的“阻塞队列”。

引入“阻塞队列”的最大好处就是解耦，在软件工程中，“高内聚，低耦合”是进行模块设计的准则之一，这样“生产者”和“消费者”其实是互不影响的，将来任意一方需要升级时，可以保证系统的平滑过渡。

BlockingQueue继承了Queue接口，提供了一些阻塞方法，主要作用如下：

1. 当线程向队列中插入元素时，如果队列已满，则阻塞线程，直到队列有空闲位置（非满）；
2. 当线程从队列中取元素（删除队列元素）时，如果队列未空，则阻塞线程，直到队列有元素；

既然BlockingQueue是一种队列，所以也具备队列的三种基本方法：插入、删除、读取：

| 操作类型 | 抛出异常  | 返回特殊值 | 阻塞线程 | 超时                 |
| :------- | :-------- | :--------- | :------- | :------------------- |
| 插入     | add(e)    | offer(e)   | put(e)   | offer(e, time, unit) |
| 删除     | remove()  | poll()     | take()   | poll(time, unit)     |
| 读取     | element() | peek()     | /        | /                    |

可以看到，对于每种基本方法，“抛出异常”和“返回特殊值”的方法定义和Queue是完全一样的。BlockingQueue只是增加了两类和阻塞相关的方法：`put(e)`、`take()`；`offer(e, time, unit)`、`poll(time, unit)`。

**put(e)**和**take()**方法会一直阻塞调用线程，直到线程被中断或队列状态可用；
**offer(e, time, unit)**和**poll(time, unit)**方法会限时阻塞调用线程，直到超时或线程被中断或队列状态可用。

除此之外，BlockingQueue还具有以下特点：

- BlockingQueue队列中不能包含null元素；
- BlockingQueue接口的实现类都必须是线程安全的，实现类一般通过“锁”保证线程安全；
- BlockingQueue 可以是限定容量的。remainingCapacity()方法用于返回剩余可用容量，对于没有容量限制的BlockingQueue实现，该方法总是返回Integer.MAX_VALUE 。

# 9 ArrayBlockingQueue

## 9.1 ArrayBlockingQueue简介

它实现了**BlockingQueue**接口，底层基于**数组**实现：

ArrayBlockingQueue是一种**有界阻塞队列**，在初始构造的时候需要指定队列的容量。具有如下特点：

1. 队列的容量一旦在构造时指定，后续不能改变；
2. 插入元素时，在队尾进行；删除元素时，在队首进行；
3. 队列满时，调用特定方法插入元素会阻塞线程；队列空时，删除元素也会阻塞线程；
4. 支持公平/非公平策略，默认为非公平策略。

这里的公平策略，是指当线程从阻塞到唤醒后，以最初请求的顺序（FIFO）来添加或删除元素；非公平策略指线程被唤醒后，谁先抢占到锁，谁就能往队列中添加/删除顺序，是随机的。

## 9.2 ArrayBlockingQueue原理

### 9.2.1 构造

**ArrayBlockingQueue**提供了三种构造器：

- 定队列初始容量的构造器
- 指定队列初始容量和公平/非公平策略的构造器.
- 根据已有集合构造队列

核心就是第二种构造器，从构造器也可以看出，ArrayBlockingQueue在构造时就指定了内部数组的大小，并通过ReentrantLock来保证并发环境下的线程安全。

ArrayBlockingQueue的公平/非公平策略其实就是内部ReentrantLock对象的策略，此外构造时还创建了两个Condition对象。在队列满时，插入线程需要在notFull上等待；当队列空时，删除线程会在notEmpty上等待：

### 9.2.2 核心方法

ArrayBlockingQueue会阻塞线程的方法一共4个：`put(E e)`、`offer(e, time, unit)`和`take()`、`poll(time, unit)`，我们先来看插入元素的方法。

**插入元素——put(E e)**

插入元素的逻辑很简单，用ReentrantLock来保证线程安全，当队列满时，则调用线程会在**notFull**条件队列上等待，否则就调用**enqueue**方法入队。

这里需要注意一点，队列已满的时候，是通过while循环判断的,这其实是多线程设计模式中的Guarded Suspension模式

之所以这样做，是防止线程被意外唤醒，不经再次判断就直接调用**enqueue**方法。

------

**删除元素——take()**

删除元素的逻辑和插入元素类似，区别就是：删除元素时，如果队列空了，则线程需要在notEmpty条件队列上等待。

队列非空时，调用dequeue方法出队一个元素：

### 9.2.3 环形队列

从上面的入队/出队操作，可以看出，ArrayBlockingQueue的内部数组其实是一种环形结构。

假设ArrayBlockingQueue的容量大小为6，我们来看下整个入队过程：

**①初始时**

![clipboard.png](https://segmentfault.com/img/bVbgBCy?w=290&h=359)

**②插入元素“9”**

![clipboard.png](https://segmentfault.com/img/bVbgBCS?w=362&h=358)

**③插入元素“2”、“10”、“25”、“93”**

![clipboard.png](https://segmentfault.com/img/bVbgBCZ?w=353&h=358)

**④插入元素“90”**

注意，此时再插入一个元素“90”，则putIndex变成6，等于队列容量6，由于是循环队列，所以会将putIndex重置为0：

![clipboard.png](https://segmentfault.com/img/bVbgBC9?w=290&h=358)

这是队列已经满了（count==6），如果再有线程尝试插入元素，并不会覆盖原有值，而是被阻塞。

------

我们再来看下出队过程：

**①出队元素“9”**

![clipboard.png](https://segmentfault.com/img/bVbgBDo?w=362&h=359)

**②出队元素“2”、“10”、“25”、“93”**

![clipboard.png](https://segmentfault.com/img/bVbgBDr?w=356&h=359)

**③出队元素“90”**

注意，此时再出队一个元素“90”，则tabeIndex变成6，等于队列容量6，由于是循环队列，所以会将tableIndex重置为0：

![clipboard.png](https://segmentfault.com/img/bVbgBCy?w=290&h=359)

这是队列已经空了（count==0），如果再有线程尝试出队元素，则会被阻塞。

## 9.3 总结

ArrayBlockingQueue利用了ReentrantLock来保证线程的安全性，针对队列的修改都需要加全局锁。在一般的应用场景下已经足够。对于超高并发的环境，由于生产者-消息者共用一把锁，可能出现性能瓶颈。

另外，由于ArrayBlockingQueue是有界的，且在初始时指定队列大小，所以如果初始时需要限定消息队列的大小，则ArrayBlockingQueue 比较合适。后续，我们会介绍另一种基于单链表实现的阻塞队列——**LinkedBlockingQueue**，该队列的最大特点是使用了“两把锁”，以提升吞吐量。

# 10 LinkedBlockingQueue

## 10.1 LinkedBlockingQueue简介

它实现了BlockingQueue接口，底层基于**单链表**实现：

LinkedBlockingQueue是一种**近似有界阻塞队列**，为什么说近似？因为LinkedBlockingQueue既可以在初始构造时就指定队列的容量，也可以不指定，如果不指定，那么它的容量大小默认为`Integer.MAX_VALUE`。

LinkedBlockingQueue除了底层数据结构（单链表）与ArrayBlockingQueue不同外，另外一个特点就是：
它维护了两把锁——`takeLock`和`putLock`。

takeLock用于控制出队的并发，putLock用于入队的并发。这也就意味着，同一时刻，只能只有一个线程能执行入队/出队操作，其余入队/出队线程会被阻塞；但是，入队和出队之间可以并发执行，即同一时刻，可以同时有一个线程进行入队，另一个线程进行出队，这样就可以提升吞吐量。

在ArrayBlockingQueue章节中，我们说过，ArrayBlockingQueue维护了一把全局锁，无论是出队还是入队，都共用这把锁，这就导致任一时间点只有一个线程能够执行。那么对于“生产者-消费者”模式来说，意味着生产者和消费者不能并发执行。

## 10.2 LinkedBlockingQueue原理

### 10.2.1 构造

**LinkedBlockingQueue**提供了三种构造器：

- 默认构造器：队列容量为Integer.MAX_VALUE.
- 显示指定队列容量的构造器
- 从已有集合构造队列：队列容量为Integer.MAX_VALUE

可以看到，如果不指定容量，那么它的容量大小默认为`Integer.MAX_VALUE`。另外，**LinkedBlockingQueue**使用了一个原子变量`AtomicInteger`记录队列中元素的个数，以保证入队/出队并发修改元素时的数据一致性。

构造完成后，LinkedBlockingQueue的初始结构如下：

![clipboard.png](https://segmentfault.com/img/bVbgCyA?w=119&h=127)

插入部分元素后的LinkedBlockingQueue结构：

![clipboard.png](https://segmentfault.com/img/bVbgCyB?w=799&h=123)

### 10.2.2 核心方法

由于接口和ArrayBlockingQueue完全一样，所以LinkedBlockingQueue会阻塞线程的方法也一共有4个：`put(E e)`、`offer(e, time, unit)`和`take()`、`poll(time, unit)`，我们先来看插入元素的方法。

**插入元素——put(E e)**

插入元素时，首先需要获得**“入队锁”**，如果队列满了，则当前线程需要在**notFull**条件队列等待；否则，将新元素链接到队列尾部。

这里需要注意的是两个地方：

**①每入队一个元素后，如果队列还没满，则需要唤醒其它可能正在等待的“入队线程”：**

**② 每入队一个元素，都要判断下队列是否空了，如果空了，说明可能存在正在等待的“出队线程”，需要唤醒它：**

这里为什么不像ArrayBlockingQueue那样，入队完成后，直接唤醒一个在notEmpty上等待的出队线程？

因为ArrayBlockingQueue中，入队/出队用的是同一把锁，两者不会并发执行，所以每入队一个元素（拿到锁），就可以通知可能正在等待的“出队线程”。（同一个锁的两个条件队列：**notEmpty**、**notFull**）

而LinkedBlockingQueue中，入队/出队用的是两把锁，入队/出队是会并发执行的。入队锁对应的是**notFull**条件队列，出队锁对应的是**notEmpty**条件队列，所以每入队一个元素，应当立即去唤醒可能阻塞的其它入队线程。当队列为空时，说明后面再来“出队线程”，一定都会阻塞，所以此时可以去唤醒一个出队线程，以提升性能。

试想以下，如果去掉上面的①和②，当入队线程拿到“入队锁”，入队元素后，直接尝试唤醒出队线程，会要求去拿出队锁，这样持有锁A的同时，再去尝试获取锁B，很可能引起死锁，就算通过打破死锁的条件避免死锁，每次操作同时获取两把锁也会降低性能。

------

**删除元素——table()**

删除元素的逻辑和插入元素类似。删除元素时，首先需要获得**“出队锁”**，如果队列为空，则当前线程需要在**notEmpty**条件队列等待；否则，从队首出队一个元素：

上面需要的注意点和插入元素一样：

**① 每出队一个元素前，如果队列非空，则需要唤醒其它可能正在等待的“出队线程”：**

**② 每出队一个元素，都要判断下队列是否满，如果是满的，说明可能存在正在等待的“入队线程”，需要唤醒它：**

## 10.3 总结

归纳一下，**LinkedBlockingQueue**和**ArrayBlockingQueue**比较主要有以下区别：

1. 队列大小不同。ArrayBlockingQueue初始构造时必须指定大小，而LinkedBlockingQueue构造时既可以指定大小，也可以不指定（默认为`Integer.MAX_VALUE`，近似于无界）；
2. 底层数据结构不同。ArrayBlockingQueue底层采用**数组**作为数据存储容器，而LinkedBlockingQueue底层采用**单链表**作为数据存储容器；
3. 两者的加锁机制不同。ArrayBlockingQueue使用一把**全局锁**，即入队和出队使用同一个ReentrantLock锁；而LinkedBlockingQueue进行了**锁分离**，入队使用一个ReentrantLock锁（putLock），出队使用另一个ReentrantLock锁（takeLock）；
4. LinkedBlockingQueue不能指定公平/非公平策略（默认都是非公平），而ArrayBlockingQueue可以指定策略。

# 11 PriorityBlockingQueue

## 11.1 PriorityBlockingQueue简介

它实现了**BlockingQueue**接口，底层基于**堆**实现：

PriorityBlockingQueue是一种**无界阻塞队列**，在构造的时候可以指定队列的初始容量。具有如下特点：

1. PriorityBlockingQueue与之前介绍的阻塞队列最大的不同之处就是：它是一种**优先级队列**，也就是说元素并不是以FIFO的方式出/入队，而是以按照权重大小的顺序出队；
2. PriorityBlockingQueue是真正的无界队列（仅受内存大小限制），它不像ArrayBlockingQueue那样构造时必须指定最大容量，也不像LinkedBlockingQueue默认最大容量为`Integer.MAX_VALUE`；
3. 由于PriorityBlockingQueue是按照元素的权重进入排序，所以队列中的元素必须是可以比较的，也就是说元素必须实现`Comparable`接口；
4. 由于PriorityBlockingQueue无界队列，所以插入元素永远不会阻塞线程；
5. PriorityBlockingQueue底层是一种**基于数组实现的堆结构**。

**注意**：堆分为“大顶堆”和“小顶堆”，PriorityBlockingQueue会依据元素的比较方式选择构建大顶堆或小顶堆。比如：如果元素是Integer这种引用类型，那么默认就是“小顶堆”，也就是每次出队都会是当前队列最小的元素。

## 11.2 PriorityBlockingQueue原理

### 11.2.1 构造

PriorityBlockingQueue提供了四种构造器：

- 默认构造器：默认初始容量11, 以元素自然顺序比较(元素必须实现Comparable接口)
- 指定初始容量的构造器：以元素自然顺序比较(元素必须实现Comparable接口)
- 指定初始容量和比较器的构造器.
- 从已有集合构造队列：如果已经集合是SortedSet或者PriorityBlockingQueue, 则保持原来的元素顺序

重点是第三种构造器，可以看到，PriorityBlockingQueue内部也是利用了**ReentrantLock**来保证并发访问时的线程安全。

PriorityBlockingQueue如果不指定容量，默认容量为11，内部数组queue其实是一种二叉树，后续我们会详细介绍。

需要注意的是，PriorityBlockingQueue只有一个条件等待队列——`notEmpty`，因为构造时不会限制最大容量且会自动扩容，所以插入元素并不会阻塞，仅当队列为空时，才可能阻塞“出队”线程。

### 11.2.2 插入元素——put(E e)

**PriorityBlockingQueue**插入元素不会阻塞线程，`put(E e)`方法内部其实是调用了`offer(E e)`方法：

首先获取全局锁（对于队列的修改都要获取这把锁），然后判断下队列是否已经满了，如果满了就先进行一次内部数组的扩容；

上面最关键的是**siftUpComparable**和**siftUpUsingComparator**方法，这两个方法内部几乎一样，只不过前者是一个根据元素的自然顺序比较，后者则根据外部比较器比较，我们重点看下siftUpComparable方法：

**siftUpComparable**方法的作用其实就是**堆的“上浮调整”**，可以把堆可以想象成一棵完全二叉树，每次插入元素都链接到二叉树的**最右下方**，然后将插入的元素与其父结点比较，如果父结点大，则交换元素，直到没有父结点比插入的结点大为止。这样就保证了堆顶（二叉树的根结点）一定是最小的元素。（注：以上仅针对“小顶堆”）

### 11.2.3 堆的“上浮”调整

我们通过示例来理解下入队的整个过程：**假设初始构造的队列大小为6，依次插入9、2、93、10、25、90**。

**①初始队列情况**

![clipboard.png](https://segmentfault.com/img/bVbgMtz?w=452&h=97)

**②插入元素9（索引0处）**

![clipboard.png](https://segmentfault.com/img/bVbgMtF?w=452&h=97)

将上述数组想象成一棵**完全二叉树**，其实就是下面的结构：
![clipboard.png](https://segmentfault.com/img/bVbgMtN?w=62&h=68)

------

**③插入元素2（索引1处）**

![clipboard.png](https://segmentfault.com/img/bVbgMtR?w=452&h=97)

对应的二叉树：
![clipboard.png](https://segmentfault.com/img/bVbgMtW?w=129&h=144)

由于结点2的父结点为9，所以要进行“上浮调整”，最终队列结构如下：
![clipboard.png](https://segmentfault.com/img/bVbgMt7?w=452&h=97)

![clipboard.png](https://segmentfault.com/img/bVbgMua?w=129&h=144)

------

**④插入元素93（索引2处）**

![clipboard.png](https://segmentfault.com/img/bVbgMuO?w=452&h=97)

![clipboard.png](https://segmentfault.com/img/bVbgMuQ?w=189&h=144)

------

**⑤插入元素10（索引3处）**

![clipboard.png](https://segmentfault.com/img/bVbgMu4?w=452&h=97)

![clipboard.png](https://segmentfault.com/img/bVbgMu5?w=232&h=222)

------

**⑥插入元素25（索引4处）**

![clipboard.png](https://segmentfault.com/img/bVbgMve?w=452&h=97)

![clipboard.png](https://segmentfault.com/img/bVbgMvg?w=252&h=222)

------

**⑦插入元素90（索引5处）**

![clipboard.png](https://segmentfault.com/img/bVbgMvp?w=452&h=97)

![clipboard.png](https://segmentfault.com/img/bVbgMvq?w=252&h=222)

此时，堆不满足有序条件，因为“90”的父结点“93”大于它，所以需要“上浮调整”：

![clipboard.png](https://segmentfault.com/img/bVbgMvs?w=452&h=97)

![clipboard.png](https://segmentfault.com/img/bVbgMvv?w=252&h=222)

最终，堆的结构如上，可以看到，经过调整后，堆顶元素一定是最小的。

### 11.2.4 扩容

在入队过程中，如果队列内部的`queue`数组已经满了，就需要进行扩容：

上述整个过程还是比较清晰的，由于调用**tryGrow**的方法一定会先获取全局锁，所以先释放锁，因为可能有线程正在出队，扩容/出队是可以并发执行的（扩容的前半部分只是新建一个内部数组，不会对出队产生影响）。扩容后的内部数组大小一般为原来的2倍。

上述需要注意的是`allocationSpinLock`字段，该字段通过CAS操作，置1表示有线程正在进行扩容。

### 11.2.5 删除元素——take()

删除元素（出队）的整个过程比较简单，也是先获取全局锁，然后判断队列状态，如果是空，则阻塞线程，否则调用`dequeue`方法出队：

从**dequeue**方法可以看出，每次出队的元素都是“堆顶结点”，对于“小顶堆”就是队列中的最小值，对于“大顶堆”就是队列中的最大值。

我们看下**siftDownComparable**方法如何实现堆顶点的删除：

上述代码其实是经典的**堆“下沉”**操作，对堆中某个顶点下沉，步骤如下：

1. 找到该顶点的左右子结点中较小的那个；
2. 与当前结点交换；
3. 重复前2步直到当前结点没有左右子结点或比左右子结点都小。

### 11.2.6 堆的“下沉”调整

来看个示例，假设堆的初始结构如下，现在出队一个元素（索引0位置的元素2）。

**①初始状态**

![clipboard.png](https://segmentfault.com/img/bVbgMwE?w=452&h=96)

对应二叉树结构：

![clipboard.png](https://segmentfault.com/img/bVbgMwI?w=252&h=222)

------

**②将顶点与最后一个结点调换**

即将顶点“2”与最后一个结点“93”交换，然后将索引5为止置null。

![clipboard.png](https://segmentfault.com/img/bVbgMwQ?w=252&h=222)

> **注意：**为了提升效率（比如siftDownComparable的源码所示）并不一定要真正交换，可以用一个变量保存索引5处的结点值，在整个下沉操作完成后再替换。但是为了理解这一过程，示例图中全是以交换进行的。

------

**③下沉索引0处结点**

比较元素“93”和左右子结点中的最小者，发现“93”大于“9”，违反了“小顶堆”的规则，所以交换“93”和“9”，这一过程称为**siftdown（下沉）**：

![clipboard.png](https://segmentfault.com/img/bVbgMxd?w=252&h=222)

------

**④继续下沉索引1处结点**

比较元素“93”和左右子结点中的最小者，发现“93”大于“10”，违反了“小顶堆”的规则，所以交换“93”和“10”：

![clipboard.png](https://segmentfault.com/img/bVbgMxl?w=252&h=222)

------

**⑤比较结束**

由于“93”已经没有左右子结点了，所以下沉结束，可以看到，此时堆恢复了有序状态，最终队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbgMxF?w=452&h=97)

## 11.3 总结

**PriorityBlockingQueue**属于比较特殊的阻塞队列，适用于有元素优先级要求的场景。它的内部和ArrayBlockingQueue一样，使用一个了全局独占锁来控制同时只有一个线程可以进行入队和出队，另外由于该队列是无界队列，所以入队线程并不会阻塞。

PriorityBlockingQueue始终保证出队的元素是优先级最高的元素，并且可以定制优先级的规则，内部通过使用**堆（数组形式）**来维护元素顺序，它的内部数组是可扩容的，扩容和出/入队可以并发进行。

# 12 SynchronousQueue

## 12.1 SynchronousQueue简介

它实现了BlockingQueue接口，底层基于**栈**和**队列**实现：

没有看错，SynchronousQueue的底层实现包含两种数据结构——**栈**和**队列**。这是一种非常特殊的阻塞队列，它的特点简要概括如下：

1. 入队线程和出队线程必须一一匹配，否则任意先到达的线程会阻塞。比如ThreadA进行入队操作，在有其它线程执行出队操作之前，ThreadA会一直等待，反之亦然；
2. SynchronousQueue内部不保存任何元素，也就是说它的容量为0，数据直接在配对的生产者和消费者线程之间传递，不会将数据缓冲到队列中。
3. SynchronousQueue支持公平/非公平策略。其中非公平模式，基于内部数据结构——“栈”来实现，公平模式，基于内部数据结构——“队列”来实现；
4. SynchronousQueue基于一种名为“Dual stack and Dual queue”的无锁算法实现。

注意：上述的特点1，和我们之前介绍的Exchanger其实非常相似，可以类比Exchanger的功能来理解。

## 12.2 SynchronousQueue原理

### 12.2.1 构造

之前提到，SynchronousQueue根据公平/非公平访问策略的不同，内部使用了两种不同的数据结构：栈和队列。我们先来看下对象的构造，SynchronousQueue只有2种构造器：

- 默认构造器：默认使用非公平策略.
- 指定策略的构造器

可以看到，对于公平策略，内部构造了一个**TransferQueue**对象，而非公平策略则是构造了**TransferStack**对象。这两个类都继承了内部类**Transferer**，SynchronousQueue中的所有方法，其实都是委托调用了TransferQueue/TransferStack的方法：

### 12.2.2 栈结构

非公平策略由TransferStack类实现，既然TransferStack是栈，那就有结点。TransferStack内部定义了名为**SNode**的结点：

上述SNode结点的定义中有个`mode`字段，表示结点的类型。TransferStack一共定义了**三种结点类型**，任何线程对TransferStack的操作都会创建下述三种类型的某种结点：

- **REQUEST**：表示未配对的消费者（当线程进行出队操作时，会创建一个mode值为REQUEST的SNode结点 ）
- **DATA**：表示未配对的生产者（当线程进行入队操作时，会创建一个mode值为DATA的SNode结点 ）
- **FULFILLING**：表示配对成功的消费者/生产者

### 12.2.3 核心操作——put/take

SynchronousQueue的入队操作调用了**put**方法：入队指定元素e，如果没有另一个线程进行出队操作, 则阻塞该入队线程.

SynchronousQueue的出队操作调用了**take**方法：出队一个元素，如果没有另一个线程进行出队操作, 则阻塞该入队线程.

可以看到，SynchronousQueue一样不支持null元素，实际的入队/出队操作都是委托给了**transfer**方法，该方法返回null表示出/入队失败（通常是线程被中断或超时）：

整个**transfer**方法考虑了限时等待的情况，且入队/出队其实都是调用了同一个方法，其主干逻辑就是在一个自旋中完成以下三种情况之一的操作，直到成功，或者被中断或超时取消：

1. 栈为空，或栈顶结点类型与当前入队结点相同。这种情况，调用线程会阻塞；
2. 栈顶结点还未配对成功，且与当前入队结点可以配对。这种情况，直接进行配对操作；
3. 栈顶结点正在配对中。这种情况，直接进行下一个结点的配对。

### 12.2.4 出/入队示例讲解

为了便于理解，我们来看下面这个调用示例（假设不考虑限时等待的情况），假设一共有三个线程ThreadA、ThreadB、ThreadC：

**①初始栈结构**

初始栈为空，`head`为栈顶指针，始终指向栈顶结点：

![clipboard.png](https://segmentfault.com/img/bVbgN0j?w=52&h=89)

**②ThreadA（生产者）执行入队操作**

由于此时栈为空，所以ThreadA会进入**CASE1**，创建一个类型为`DATA`的结点：

将结点压入栈后，会调用`awaitFulfill`方法，该方法会阻塞调用线程：

此时栈结构如下，结点的`waiter`字段保存着创建该结点的线程ThreadA，ThreadA等待着被配对消费者线程唤醒：

![clipboard.png](https://segmentfault.com/img/bVbgN0A?w=225&h=181)

**③ThreadB（生产者）执行入队操作**

此时栈顶结点的类型和ThreadB创建的结点相同（都是`DATA`类型的结点），所以依然走**CASE1**分支，直接将结点压入栈：

![clipboard.png](https://segmentfault.com/img/bVbgN0H?w=225&h=279)

**④ThreadC（消费者）执行出队操作**

此时栈顶结点的类型和ThreadC创建的结点匹配（栈顶`DATA`类型，ThreadC创建的是`REQUEST`类型），所以走**CASE2**分支，该分支会将匹配的两个结点弹出栈：

ThreadC创建结点并压入栈后，栈的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbgN0V?w=255&h=379)

此时，ThreadC会调用**tryMatch**方法进行匹配，该方法的主要作用有两点：

1. 将待配对结点的`match`字段置为与当前配对的结点（如上图中，结点m是待配对结点，最终`m.math == s`）
2. 唤醒待配对结点中的线程（如上图中，唤醒结点m中ThreadB线程）

匹配完成后，会将匹配的两个结点弹出栈，并返回匹配值：

最终，ThreadC拿到了等待配对结点中的数据并返回，此时栈的结构如下：

![clipboard.png](https://segmentfault.com/img/bVbgN08?w=225&h=181)

**注意:** **CASE2**分支中ThreadC创建的结点的mode值并不是REQUEST，其mode值为`FULFILLING | mode`，`FULFILLING | mode`的主要作用就是给栈顶结点置一个标识（二进制为11或10），**表示当前有线程正在对栈顶匹配**，这时如果有其它线程进入自旋（并发情况），则CASE2一定失败，因为`isFulfilling`的结果必然为true，所以会进入**CASE3**分支——跳过栈顶结点进行匹配。

**⑤ThreadB（生产者）唤醒后继续执行**

ThreadB被唤醒后，会从原阻塞处继续执行，并进入下一次自旋，在下一次自旋中，由于结点的`match`字段已经有了匹配结点，所以直接返回配对结点：

**注意：**对于**入队**线程（生产者），返回的是它入队时携带的**原有元素值。**

### 12.2.5 队列结构

SynchronousQueue的公平策略由**TransferQueue**类实现，TransferQueue内部定义了名为`QNode`的结点,一个`head`队首指针，一个`tail`队尾指针：

关于TransferQueue的transfer方法就不再赘述了，其思路和TransferStack大致相同，总之就是入队/出队必须一一匹配，否则任意一方就会加入队列并等待匹配线程唤醒。读者可以自行阅读TransferQueued的源码。

## 12.3 总结

TransferQueue主要用于线程之间的数据交换，由于采用无锁算法，其性能一般比单纯的其它阻塞队列要高。它的最大特点时不存储实际元素，而是在内部通过栈或队列结构保存阻塞线程。后面我们讲**JUC线程池框架**的时候，还会再次看到它的身影。

# 13 DelayQueue

## 13.1 DelayQueue简介

它实现了BlockingQueue接口，底层基于已有的**PriorityBlockingQueue**实现：

DelayQueue也是一种比较特殊的阻塞队列，从类声明也可以看出，DelayQueue中的所有元素必须实现`Delayed`接口：

Delayed接口除了自身的`getDelay`方法外，还实现了**Comparable**接口。getDelay方法用于返回对象的剩余有效时间，实现Comparable接口则是为了能够比较两个对象，以便排序。

也就是说，如果一个类实现了Delayed接口，当创建该类的对象并添加到DelayQueue中后，**只有当该对象的getDalay方法返回的剩余时间≤0时才会出队**。

另外，由于DelayQueue内部委托了PriorityBlockingQueue对象来实现所有方法，所以能以堆的结构维护元素顺序，这样剩余时间最小的元素就在堆顶，**每次出队其实就是删除剩余时间≤0的最小元素**。

DelayQueue的特点简要概括如下：

1. DelayQueue是无界阻塞队列；
2. 队列中的元素必须实现Delayed接口，元素过期后才会从队列中取走；

## 13.2 DelayQueue原理

### 13.2.1 构造

DelayQueued提供了两种构造器

- 默认构造器
- 从已有集合构造队列

可以看到，内部的**PriorityQueue**并非在构造时创建，而是对象创建时生成：

上述比较特殊的是`leader`字段，我们之前已经说过，DelayQueue每次只会出队一个过期的元素，如果队首元素没有过期，就会阻塞出队线程，让线程在`available`这个条件队列上无限等待。

leader线程是首个尝试出队元素（队列不为空）但被阻塞的线程.

该线程会限时等待（队首元素的剩余有效时间），用于唤醒其它等待线程

为了提升性能，DelayQueue并不会让所有出队线程都无限等待，而是用`leader`保存了第一个尝试出队的线程，该线程的等待时间是队首元素的剩余有效期。这样，一旦leader线程被唤醒（此时队首元素也失效了），就可以出队成功，然后唤醒一个其它在`available`条件队列上等待的线程。之后，会重复上一步，新唤醒的线程可能取代成为新的leader线程。这样，就避免了无效的等待，提升了性能。

### 13.2.2 入队——put

**put**方法没有什么特别，由于是无界队列，所以也不会阻塞线程。

需要注意的是当首次入队元素时，需要唤醒一个出队线程，因为此时可能已有出队线程在空队列上等待了，如果不唤醒，会导致出队线程永远无法执行。

### 13.2.3 出队——take

整个**take**方法在一个自旋中完成，其实就分为两种情况：

**1.队列为空**

这种情况直接阻塞出队线程。（在available条件队列等待）

**2.队列非空**

队列非空时，还要看队首元素的状态（有效期），如果队首元素过期了，那直接出队就行了；如果队首元素未过期，就要看当前线程是否是第一个到达的出队线程（即判断`leader`是否为空），如果不是，就无限等待，如果是，则限时等待。

## 13.3 总结

**DelayQueue**是阻塞队列中非常有用的一种队列，经常被用于缓存或定时任务等的设计。

考虑一种使用场景：

异步通知的重试，在很多系统中，当用户完成服务调用后，系统有时需要将结果异步通知到用户的某个URI。由于网络等原因，很多时候会通知失败，这个时候就需要一种重试机制。

这时可以用DelayQueue保存通知失败的请求，失效时间可以根据已通知的次数来设定（比如：2s、5s、10s、20s），这样每次从队列中take获取的就是剩余时间最短的请求，如果已重复通知次数超过一定阈值，则可以把消息抛弃。

# 14 LinkedBlockingDeque

## 14.1 LinkedBlockingDeque简介

LinkedBlockingDeque和ConcurrentLinkedDeque类似，都是一种**双端队列**的结构，只不过LinkedBlockingDeque同时也是一种阻塞队列，它是在JDK1.5时随着J.U.C包引入的，实现了`BlockingDueue`接口，底层基于**双链表**实现：

**注意：**LinkedBlockingDeque底层利用ReentrantLock实现同步，并不像ConcurrentLinkedDeque那样采用无锁算法。

另外，LinkedBlockingDeque是一种**近似有界阻塞队列**，为什么说近似？因为LinkedBlockingDeque既可以在初始构造时就指定队列的容量，也可以不指定，如果不指定，那么它的容量大小默认为`Integer.MAX_VALUE`。

截止目前为止，我们介绍的阻塞队列都是实现了BlockingQueue接口。和普通双端队列接口——Deque一样，J.U.C中也有一种阻塞的双端队列接口——`BlockingDeque`。

我们知道，BlockingQueue中阻塞方法一共有4个：`put(e)`、`take()`；`offer(e, time, unit)`、`poll(time, unit)`，忽略限时等待的阻塞方法，一共就两个：

队尾入队：put(e)
队首出队：take()

BlockingDeque相对于BlockingQueue，最大的特点就是增加了在**队首入队**/**队尾出队**的阻塞方法。下面是两个接口的比较：

| 阻塞方法 | BlockingQueue | BlockingDeque |
| :------- | :------------ | :------------ |
| 队首入队 | /             | putFirst(e)   |
| 队首出队 | take()        | takeFirst()   |
| 队尾入队 | put(e)        | putLast(e)    |
| 队尾出队 | /             | takeLast()    |

## 14.2 LinkedBlockingDeque原理

### 14.2.1 构造

**LinkedBlockingDeque**一共三种构造器，不指定容量时，默认为`Integer.MAX_VALUE`：

- 默认构造器
- 指定容量的构造器
- 从已有集合构造队列

### 14.2.2 内部结构

LinkedBlockingDeque内部是**双链表**的结构，结点`Node`类型

字段`first`指向队首结点，字段last指向队尾结点。另外LinkedBlockingDeque利用**ReentrantLock**来保证线程安全，所有对队列的修改操作都需要先获取这把全局锁：

### 14.2.3 队尾入队——put

在队尾入队元素e，如果队列已满, 则阻塞线程.

put方法内部调用了putLast方法，这是Deque接口独有的方法。上述入队操作的关键是**linkLast**方法：将结点node链接到队尾, 如果失败, 则返回false.

**linkLast**方法在队尾插入一个结点，插入失败（队列已满的情况）则返回false。插入成功，则唤醒一个正在等待的出队线程：

**初始：**

![clipboard.png](https://segmentfault.com/img/bVbgX9y?w=459&h=123)

**队尾插入结点node：**

![clipboard.png](https://segmentfault.com/img/bVbgX9J?w=629&h=131)

### 14.2.4 队首入队——putFirst

队首入队就是双链表的**“头插法”**插入一个结点，如果队列已满，则阻塞调用线程：

**初始：**

![clipboard.png](https://segmentfault.com/img/bVbgX9y?w=459&h=123)

**队首插入结点node：**

![clipboard.png](https://segmentfault.com/img/bVbgX9U?w=629&h=132)

### 14.2.5 队首出队——take

队首出队的逻辑很简单，如果队列为空，则阻塞调用线程：

实际的出队由**unlinkFirst**方法执行：

**初始：**

![clipboard.png](https://segmentfault.com/img/bVbgX9y?w=459&h=123)

**删除队首结点：**

![clipboard.png](https://segmentfault.com/img/bVbgX94?w=572&h=124)

### 14.2.6 队尾出队——takeLast

队尾出队的逻辑很简单，如果队列为空，则阻塞调用线程：

实际的出队由**unlinkLast**方法执行：

**初始：

![clipboard.png](https://segmentfault.com/img/bVbgX9y?w=459&h=123)

**删除队尾结点：

![clipboard.png](https://segmentfault.com/img/bVbgYaa?w=532&h=142)

## 14.3 总结

LinkedBlockingDeque作为一种阻塞双端队列，提供了队尾删除元素和队首插入元素的阻塞方法。该类在构造时一般需要指定容量，如果不指定，则最大容量为`Integer.MAX_VALUE`。另外，由于内部通过ReentrantLock来保证线程安全，所以LinkedBlockingDeque的整体实现时比较简单的。

另外，双端队列相比普通队列，主要是多了【队尾出队元素】/【队首入队元素】的功能。
阻塞队列我们知道一般用于“生产者-消费者”模式，而双端阻塞队列在“生产者-消费者”就可以利用“双端”的特性，从队尾出队元素。

考虑下面这样一种场景：有多个消费者，每个消费者有自己的一个消息队列，生产者不断的生产数据扔到队列中，消费者消费数据有快又慢。为了提升效率，速度快的消费者可以从其它消费者队列的**队尾**出队元素放到自己的消息队列中，由于是从其它队列的队尾出队，这样可以减少并发冲突（其它消费者从队首出队元素），又能提升整个系统的吞吐量。这其实是一种“**工作窃取算法**”的思路。

# 15 LinkedTransferQueue

## 15.1 LinkedTransferQueue简介

`LinkedTransferQueue`是在JDK1.7时，J.U.C包新增的一种比较特殊的阻塞队列，它除了具备阻塞队列的常用功能外，还有一个比较特殊的`transfer`方法。

我们知道，在普通阻塞队列中，当队列为空时，消费者线程（调用**take**或**poll**方法的线程）一般会阻塞等待生产者线程往队列中存入元素。而**LinkedTransferQueue**的**transfer**方法则比较特殊：

1. 当有消费者线程阻塞等待时，调用transfer方法的生产者线程不会将元素存入队列，而是直接将元素传递给消费者；
2. 如果调用transfer方法的生产者线程发现没有正在等待的消费者线程，则会将元素入队，然后会阻塞等待，直到有一个消费者线程来获取该元素。

LinkedTransferQueue实现了一个名为`TransferQueue`的接口，TransferQueue也是JDK1.7时J.U.C包新增的接口，正是该接口提供了上述的transfer方法：

除了transfer方法外，TransferQueue还提供了两个变种方法：`tryTransfer(E e)`、`tryTransfer(E e, long timeout, TimeUnit unit)`。

**tryTransfer(E e)**
当生产者线程调用tryTransfer方法时，如果没有消费者等待接收元素，则会立即返回false。该方法和transfer方法的区别就是tryTransfer方法无论消费者是否接收，方法立即返回，而transfer方法必须等到消费者消费后才返回。

**tryTransfer(E e, long timeout, TimeUnit unit)**
tryTransfer（E e，long timeout，TimeUnit unit）方法则是加上了限时等待功能，如果没有消费者消费该元素，则等待指定的时间再返回；如果超时还没消费元素，则返回false，如果在超时时间内消费了元素，则返回true。

LinkedTransferQueue的特点简要概括如下：

1. LinkedTransferQueue是一种无界阻塞队列，底层基于单链表实现；
2. LinkedTransferQueue中的结点有两种类型：数据结点、请求结点；
3. LinkedTransferQueue基于无锁算法实现。

## 15.2 LinkedTransferQueue原理

### 15.2.1 内部结构

LinkedTransferQueue提供了两种构造器，也没有参数设置队列初始容量，所以是一种**无界队列**：

关于Node结点，有以下几点需要特别注意：

1. Node结点有两种类型：数据结点、请求结点，通过字段`isData`区分，只有不同类型的结点才能相互匹配；
2. Node结点的值保存在`item`字段，匹配前后值会发生变化；

Node结点的状态变化如下表：

| 结点/状态 | 数据结点                         | 请求结点                    |
| :-------- | :------------------------------- | :-------------------------- |
| 匹配前    | isData = true; item = 数据结点值 | isData = false; item = null |
| 匹配后    | isData = true; item = null       | isData = false; item = this |

从上表也可以看出，对于一个数据结点，当`item == null`表示匹配成功；对于一个请求结点，当`item == this`表示匹配成功。

LinkedTransferQueue内部的其余字段定义如下，主要就是通过Unsafe类操作字段值，内部定义了很多常量字段，比如自旋，这些都是为了非阻塞算法的锁优化而定义的：

比较重要的就是4个常量值的定义：

```java
/*
 * xfer方法的入参, 不同类型的方法内部调用xfer方法时入参不同.
 */
private static final int NOW = 0;   // for untimed poll, tryTransfer
private static final int ASYNC = 1; // for offer, put, add
private static final int SYNC = 2; // for transfer, take
private static final int TIMED = 3; // for timed poll, tryTransfer
```

这四个常量值，作为`xfer`方法的入参，用于标识不同操作类型。其实从常量的命名也可以看出它们对应的操作含义：

- **NOW表示即时操作（可能失败），即不会阻塞调用线程：**
  poll（获取并移除队首元素，如果队列为空，直接返回null）；tryTransfer（尝试将元素传递给消费者，如果没有等待的消费者，则立即返回false，也不会将元素入队）
- **ASYNC表示异步操作（必然成功）：**
  offer（插入指定元素至队尾，由于是无界队列，所以会立即返回true）；put（插入指定元素至队尾，由于是无界队列，所以会立即返回）；add（插入指定元素至队尾，由于是无界队列，所以会立即返回true）
- **SYNC表示同步操作（阻塞调用线程）：**
  transfer（阻塞直到出现一个消费者线程）；take（从队首移除一个元素，如果队列为空，则阻塞线程）
- **TIMED表示限时同步操作（限时阻塞调用线程）：**
  poll(long timeout, TimeUnit unit)；tryTransfer(E e, long timeout, TimeUnit unit)

### 15.2.2 transfer方法

`transfer`方法，用于将指定元素e传递给消费者线程(调用take/poll方法)。如果有消费者线程正在阻塞等待，则调用transfer方法的线程会直接将元素传递给它；如果没有消费者线程等待获取元素，则调用transfer方法的线程会将元素插入到队尾，然后阻塞等待，直到出现一个消费者线程获取元素：

**transfer**方法的内部实际是调用了xfer方法，入参为`SYNC=2`：

我们通过示例看下**xfer**方法到底做了哪些事：

**①队列初始状态**

![clipboard.png](https://segmentfault.com/img/bVbheeX?w=64&h=97)

------

**②ThreadA线程调用transfer入队元素“9”**

注意，此时入队一个数据结点，且队列为空，会插入一个结点至队尾，然后线程进入阻塞，等待一个出队线程（消费者）的到来。

队尾插入结点的方法是`tryAppend`，由于此时队列为空，会设置队首指针head指向新结点，tryAppend方法的返回值有三种情况：

1. 入队失败，返回null；
2. 入队成功且队列只有一个结点，返回该结点自身；
3. 入队成功且队列不止一个结点，返回该入队结点的前驱结点。

等待出队线程方法`awaitMatch`，该方法核心作用就是进行结点匹配：

1. 匹配成功，返回匹配值；
2. 匹配失败（中断或限时等待的超时情况），返回原匹配结点的值；
3. 阻塞线程，等待与之匹配的结点的到来。

从awaitMatch方法其实可以看到一种经典的“锁优化”思路，就是 **自旋 -> yield -> 阻塞**，线程不会立即进入阻塞，因为线程上下文切换的开销往往比较大，所以会先自旋一定次数，中途可能伴随随机的yield操作，让出cpu时间片，如果自旋次数用完后，还是没有匹配线程出现，再真正阻塞线程。

经过上述步骤，ThreadA最终会进入CASE4分支中等待，此时的队列结构如下

![clipboard.png](https://segmentfault.com/img/bVbhee9?w=281&h=189)

注意，此时的队列中tail队尾指针并不指向结点“9”，这是一种“松弛”策略，后面会讲到。

**③ThreadB线程调用transfer入队元素“2”**

首先会读取队首结点，判断该结点有没被匹配过

1. 如果已经被其它线程匹配过了，则继续判断下一个结点
2. 如果还没有被匹配，则判断下当前的入队结点类型是否和队首中的一致；如果一致就匹配失败，跳出循环，否则进行匹配操作。

显然，目前队首结点是“数据结点”，ThreadB线程的入队结点也是“数据结点”，结点类型一致，所以匹配失败，直接跳过循环

此时队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbheff?w=349&h=189)

最终，ThreadB也会在**awaitMatch**方法中进入阻塞，最终队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbhefn?w=349&h=189)

**④ThreadC线程调用transfer入队元素“93”**

过程和前几步几乎相同，不再赘述，最终队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbhefr?w=517&h=189)

可以看到，队尾指针`tail`的设置实际是滞后的，这是一种“松弛”策略，用以提升无锁算法并发修改过程中的性能。

### 15.2.3 take方法

再来看下消费者线程调用的`take`方法，该方法会从队首取出一个元素，如果队列为空，则线程会阻塞：

内部依然调用了**xfer**方法，不过此时入参有所不同，由于是消费线程调用，所以入参`e == null && hasData == false`，表示一个“请求结点”：

**①队列初始状态**

![clipboard.png](https://segmentfault.com/img/bVbhefr?w=517&h=189)

**②ThreadD调用take方法，消费元素**

此时，在**xfer**方法中，会从队首开始，向后找到第一个匹配结点，并交换元素值，然后唤醒队列中匹配结点上的等待线程：

最终队列结构如下，匹配结点的值被置换为null，ThreadA被唤醒，ThreadD拿到匹配结点上的元素值“9”并返回：

![clipboard.png](https://segmentfault.com/img/bVbhefI?w=517&h=189)

**③ThreadA被唤醒后继续执行**

ThreadA被唤醒后，从原阻塞处——继续向下执行

由于结点的item项已经被替换成了null，所以调用`s.forgetContents()`，并返回null

最终队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbhefZ?w=455&h=189)

**④ThreadE调用take方法出队元素**

ThreadE调用**take**方法出队元素，过程和步骤②相同，进入xfer方法（`e == null，hasData == false`），由于head指针指向的元素已经匹配过了，所以向后继续查找，找到第一个未匹配过的结点“2”，然后置换结点“2”中的元素值为null，唤醒线程ThreadB，返回匹配结点的元素值“2”：

此时队列状态如下，可以看到，队首指针head一次性向后跳了2个位置，原来已经匹配过的元素的next指针指向自身，等待被GC回收，这其实就是LinkedTransferQueue的“松弛”策略：

![clipboard.png](https://segmentfault.com/img/bVbhef3?w=505&h=189)

**⑤ThreadB被唤醒后继续执行**

过程和步骤③完全相同，在**awaitMatch**方法中，将结点的item置为this，然后返回匹配结点值——null，最终队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbhegd?w=286&h=189)

------

**⑥ThreadF调用take方法出队元素**

ThreadF调用take方法出队元素，过程和步骤②相同，进入xfer方法（`e == null，hasData == false`），由于head指针指向的元素此时没有匹配，所以不用像步骤②那样向后查找，而是直接置换匹配结点的元素值“93”，然后唤醒ThreadC，返回匹配值“93”。最终队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbhegk?w=286&h=189)

------

**⑦ThreadC被唤醒后继续执行**

过程和步骤③完全相同，在**awaitMatch**方法中，将结点的item置为this，然后返回匹配结点值——null，最终队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbhegq?w=286&h=123)



此时的队列结构，读者移一定感到非常奇怪，并不严格遵守队列的定义，这其实就是**“Dual Queue”**算法的实现，为了对自旋优化，做了很多看似别扭的操作，不必奇怪。

假设此时再有一个线程ThreadH调用take方法出队元素会怎么样？其实这是队列已经空了，ThreadH会被阻塞，但是会创建一个“请求结点”入队

调用完**tryAppend**方法后，队列结构如下，橙色的为“请求结点”—— `item==null && isData==false`：

![clipboard.png](https://segmentfault.com/img/bVbhegz?w=453&h=123)

然后ThreadH也会进入在**awaitMatch**方法后进入阻塞，并等待一个入队线程的到来。最终队列结构如下：

![clipboard.png](https://segmentfault.com/img/bVbhegA?w=453&h=189)

## 15.3 总结

截止本篇为止，我们已经学习完了juc-collection框架中的所有阻塞队列，如下表所示：

| 队列特性 | 有界队列           | 近似无界队列                             | 无界队列            | 特殊队列                          |
| :------- | :----------------- | :--------------------------------------- | :------------------ | :-------------------------------- |
| 有锁算法 | ArrayBlockingQueue | LinkedBlockingQueue、LinkedBlockingDeque | /                   | PriorityBlockingQueue、DelayQueue |
| 无锁算法 | /                  | /                                        | LinkedTransferQueue | SynchronousQueue                  |

可以看到，LinkedTransferQueue其实兼具了SynchronousQueue的特性以及无锁算法的性能，并且是一种无界队列：

1. 和SynchronousQueue相比，LinkedTransferQueue可以存储实际的数据；
2. 和其它阻塞队列相比，LinkedTransferQueue直接用无锁算法实现，性能有所提升。

另外，由于LinkedTransferQueue可以存放两种不同类型的结点，所以称之为“**Dual Queue**”：
内部Node结点定义了一个 boolean 型字段——`isData`，表示该结点是“**数据结点**”还是“**请求结点**”。

为了节省 CAS 操作的开销，LinkedTransferQueue使用了**松弛（slack）**操作：
在结点被匹配（被删除）之后，不会立即更新队列的head、tail，而是当 head、tail结点与最近一个未匹配的结点之间的距离超过“松弛阀值”后才会更新（默认为 2）。这个“松弛阀值”一般为1到3，如果太大会增加沿链表查找未匹配结点的时间，太小会增加 CAS 的开销。

