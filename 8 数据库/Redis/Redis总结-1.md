# 1 Redis简介

Redis是一个开源的，**基于内存的数据结构存储**，可用作于数据库、**缓存**、消息中间件。

- 从官方的解释上，我们可以知道：Redis是基于内存，支持多种数据结构。
- 从经验的角度上，我们可以知道：Redis常用作于缓存。

## 1.1 为什么要用Redis？

从上面可知：Redis是**基于内存**，常用作于**缓存**的一种技术，并且Redis存储的方式是以`key-value`的形式。

我们可以发现这不就是Java的Map容器所拥有的特性吗，那为什么还需要Redis呢？

- Java实现的Map是**本地缓存**，如果有多台实例(机器)的话，每个实例都需要**各自**保存一份缓存，缓存**不具有一致性**
- Redis实现的是**分布式缓存**，如果有多台实例(机器)的话，每个实例都**共享**一份缓存，缓存**具有一致性**。
- Java实现的Map**不是专业**做缓存的，JVM内存太大容易挂掉的。一般用做于容器来存储临时数据，缓存的数据随着JVM销毁而结束。Map所存储的数据结构，缓存过期机制等等是需要程序员自己手写的。
- Redis是**专业**做缓存的，可以用几十个G内存来做缓存。Redis一般用作于缓存，可以将缓存数据保存在硬盘中，Redis重启了后可以将其恢复。原生提供丰富的数据结构、缓存过期机制等等简单好用的功能。

## 1.2 为什么要用缓存？

如果我们的网站出现了性能问题(访问时间慢)，按经验来说，一般是由于**数据库撑不住了**。因为一般数据库的读写都是要经过**磁盘**的，而磁盘的速度可以说是相当慢的(相对内存来说)

![æ°æ®åºæä¸ä½äº](https://segmentfault.com/img/remote/1460000016837795)

如果学过Mybaits、Hibernate的同学就可以知道，它们有一级缓存、二级缓存这样的功能(终究来说还是本地缓存)。目的就是为了：**不用每次读取的时候，都要查一次数据库**。

有了缓存之后，我们的访问就变成这样了：

![æäºç¼å­æé«äºå¹¶ååæ§è½](https://segmentfault.com/img/remote/1460000016837796)

# 2 Redis的数据结构

Redis支持丰富的数据结构，常用的有string、list、hash、set、sortset这几种。学习这些数据结构是使用Redis的基础！

首先还是得声明一下，Redis的存储是以`key-value`的形式的。Redis中的key一定是字符串，value可以是string、list、hash、set、sortset这几种常用的。

但要值得注意的是：Redis并**没有直接使用**这些数据结构来实现`key-value`数据库，而是**基于**这些数据结构创建了一个**对象系统**。

简单来说：Redis使用对象来表示数据库中的键和值。每次我们在Redis数据库中新创建一个键值对时，**至少会创建出两个对象**。一个是键对象，一个是值对象。

Redis中的每个对象都由一个redisObject结构来表示：

```c
typedef struct redisObject{ 
    // 对象的类型
    unsigned type 4:;
    // 对象的编码格式
    unsigned encoding:4;
    // 指向底层实现数据结构的指针
    void * ptr;
    //.....
}robj;
```

简单来说就是Redis对`key-value`封装成对象，key是一个对象，value也是一个对象。每个对象都有type(类型)、encoding(编码)、ptr(指向底层数据结构的指针)来表示。

![ä»¥å¼ä¸º1006çå­ç¬¦ä¸²å¯¹è±¡ä¸ºä¾](https://segmentfault.com/img/remote/1460000016837799)

## 2.1 字符串

Redis中的字符串跟C语言中的字符串，是**有点差距的**。

Redis使用sdshdr结构来表示一个SDS值：

```c
struct sdshdr{
    // 字节数组，用于保存字符串
    char buf[];
    // 记录buf数组中已使用的字节数量，也是字符串的长度
    int len;
    // 记录buf数组未使用的字节数量
    int free;
}
```

![SDSä¾å­](https://segmentfault.com/img/remote/1460000016837800?w=763&h=222)

**使用SDS的好处**

1. sdshdr数据结构中用len属性记录了字符串的长度。那么**获取字符串的长度时，时间复杂度只需要O(1)**。
2. SDS不会发生溢出的问题，如果修改SDS时，空间不足。先会扩展空间，再进行修改！(**内部实现了动态扩展机制**)。
3. SDS可以**减少内存分配的次数**(空间预分配机制)。在扩展空间时，除了分配修改时所必要的空间，还会分配额外的空闲空间(free 属性)。
4. SDS是**二进制安全的**，所有SDS API都会以处理二进制的方式来处理SDS存放在buf数组里的数据。

## 2.2 链表

Redis中的链表使用listNode结构来表示每个节点：

```c
typedef strcut listNode{
    //前置节点
    strcut listNode  *pre;
    //后置节点
    strcut listNode  *pre;
    //节点的值
    void  *value;
}listNode
```

使用listNode是可以组成链表了，Redis中**使用list结构来持有链表**：

```c
typedef struct list{
    //表头结点
    listNode  *head;
    //表尾节点
    listNode  *tail;
    //链表长度
    unsigned long len;
    //节点值复制函数
    void *(*dup) (viod *ptr);
    //节点值释放函数
    void  (*free) (viod *ptr);
    //节点值对比函数
    int (*match) (void *ptr,void *key);
}list
```

具体的结构如图：

![img](https://segmentfault.com/img/remote/1460000016837801)

Redis的链表有以下特性：

- 无环双向链表
- 获取表头指针，表尾指针，链表节点长度的时间复杂度均为O(1)
- 链表使用`void *`指针来保存节点值，可以保存各种不同类型的值

## 2.3 哈希表

在Redis中，`key-value`的数据结构底层就是哈希表来实现的。对于哈希表来说，我们也并不陌生。在Java中，哈希表实际上就是数组+链表的形式来构建的。下面我们来看看Redis的哈希表是怎么构建的吧。

在Redis里边，哈希表使用dictht结构来定义：

```c
typedef struct dictht{
    //哈希表数组
    dictEntry **table;  
    //哈希表大小
    unsigned long size;    
    //哈希表大小掩码，用于计算索引值
    //总是等于size-1
    unsigned long sizemark;     
    //哈希表已有节点数量
    unsigned long used;
}dictht
```

![åå¸è¡¨çæ°æ®ç»æ](https://segmentfault.com/img/remote/1460000016837802?w=481&h=236)

我们下面继续写看看哈希表的节点是怎么实现的吧：

```c
typedef struct dictEntry {
    //键
    void *key;
    //值
    union {
        void *value;
        uint64_tu64;
        int64_ts64;
    }v;    
    //指向下个哈希节点，组成链表
    struct dictEntry *next;

}dictEntry;
```

从结构上看，我们可以发现：Redis实现的哈希表和Java中实现的是**类似**的。只不过Redis多了几个属性来记录常用的值：sizemark(掩码)、used(已有的节点数量)、size(大小)。

同样地，Redis为了更好的操作，对哈希表往上再封装了一层(参考上面的Redis实现链表)，使用dict结构来表示：

```c
typedef struct dict {
    //类型特定函数
    dictType *type;
    //私有数据
    void *privdata;
    //哈希表
    dictht ht[2];
    //rehash索引
    //当rehash不进行时，值为-1
    int rehashidx;  
}dict;
//-----------------------------------
typedef struct dictType{
    //计算哈希值的函数
    unsigned int (*hashFunction)(const void * key);
    //复制键的函数
    void *(*keyDup)(void *private, const void *key);
    //复制值得函数
    void *(*valDup)(void *private, const void *obj);  
    //对比键的函数
    int (*keyCompare)(void *privdata , const void *key1, const void *key2);
    //销毁键的函数
    void (*keyDestructor)(void *private, void *key);
    //销毁值的函数
    void (*valDestructor)(void *private, void *obj);  

}dictType;
```

所以，最后我们可以发现，Redis所实现的哈希表最后的数据结构是这样子的：

![img](https://segmentfault.com/img/remote/1460000016837803)

从代码实现和示例图上我们可以发现，**Redis中有两个哈希表**：

- ht[0]：用于存放**真实**的`key-vlaue`数据
- ht[1]：用于**扩容(rehash)**

Redis中哈希算法和哈希冲突跟Java实现的差不多，它俩**差异**就是：

- Redis哈希冲突时：是将新节点添加在链表的**表头**。
- JDK1.8后，Java在哈希冲突时：是将新的节点添加到链表的**表尾**。

**rehash的过程**

**Redis是专门使用一个哈希表来做rehash的**。这跟Java一次性直接rehash是有区别的。

在对哈希表进行扩展或者收缩操作时，reash过程并不是一次性地完成的，而是**渐进式**地完成的。

Redis在rehash时采取渐进式的原因：**数据量如果过大的话，一次性rehash会有庞大的计算量，这很可能导致服务器一段时间内停止服务**。

Redis具体是rehash时这么干的：

1. 在字典中维持一个索引计数器变量rehashidx，并将设置为0，表示rehash开始。
2. 在rehash期间每次对字典进行增加、查询、删除和更新操作时，**除了执行指定命令外**；还会将ht[0]中rehashidx索引上的值**rehash到ht[1]**，操作完成后rehashidx+1。
3. 字典操作不断执行，最终在某个时间点，所有的键值对完成rehash，这时**将rehashidx设置为-1，表示rehash完成**
4. 在渐进式rehash过程中，字典会同时使用两个哈希表ht[0]和ht[1]，所有的更新、删除、查找操作也会在两个哈希表进行。例如要查找一个键的话，**服务器会优先查找ht[0]，如果不存在，再查找ht[1]**，诸如此类。此外当执行**新增操作**时，新的键值对**一律保存到ht[1]**，不再对ht[0]进行任何操作，以保证ht[0]的键值对数量只减不增，直至变为空表。

## 2.4 跳跃表

跳跃表(shiplist)是实现sortset(**有序**集合)的底层数据结构之一！

Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成。其中**zskiplist保存跳跃表的信息**(表头，表尾节点，长度)，**zskiplistNode则表示跳跃表的节点**。

```c
typeof struct zskiplistNode {
    // 后退指针
    struct zskiplistNode *backward;
    // 分值
    double score;
    // 成员对象
    robj *obj;
    // 层
    struct zskiplistLevel {
        // 前进指针
        struct zskiplistNode *forward;
        // 跨度
        unsigned int span;
    } level[];
} zskiplistNode;
```

zskiplistNode的对象示例图(带有不同层高的节点)：

![å¸¦æä¸åå±é«çèç¹](https://segmentfault.com/img/remote/1460000016837804?w=676&h=334)

示例图如下：

![è·³è·è¡¨èç¹çç¤ºä¾å¾](https://segmentfault.com/img/remote/1460000016837805?w=1016&h=505)

zskiplist的结构如下：

```c
typeof struct zskiplist {
        // 表头节点，表尾节点
        struct skiplistNode *header,*tail;
        // 表中节点数量
        unsigned long length;
        // 表中最大层数
        int level;
} zskiplist;
```

最后我们整个跳跃表的示例图如下：

![è·³è·è¡¨ç¤ºä¾å¾](https://segmentfault.com/img/remote/1460000016837806)

## 2.5 整数集合

整数集合是set(集合)的底层数据结构之一。当一个set(集合)**只包含整数值元素**，并且**元素的数量不多**时，Redis就会采用整数集合(intset)作为set(集合)的底层实现。

整数集合(intset)保证了元素是**不会出现重复**的，并且是**有序**的(从小到大排序)，intset的结构是这样子的：0

```c
typeof struct intset {
    // 编码方式
    unit32_t encoding;
    // 集合包含的元素数量
    unit32_t lenght;
    // 保存元素的数组
    int8_t contents[];
} intset;
```

intset示例图：

![intsetç¤ºä¾å¾](https://segmentfault.com/img/remote/1460000016837807)

说明：虽然intset结构将contents属性声明为int8_t类型的数组，但实际上contents数组并不保存任何int8_t类型的值，**contents数组的真正类型取决于encoding属性的值**：

- INTSET_ENC_INT16
- INTSET_ENC_INT32
- INTSET_ENC_INT64

从编码格式的名字我们就可以知道，16,32,64编码对应能存放的数字范围是不一样的。16明显最少，64明显最大。

如果本来是INTSET_ENC_INT16的编码，想要存放大于INTSET_ENC_INT16编码能存放的整数值，此时就得编码**升级**(从16升级成32或者64)。步骤如下：

1. 根据新元素类型拓展整数集合底层数组的空间并为新元素分配空间。
2. 将底层数组现有的所以元素都转换成与新元素相同的类型，并将类型转换后的元素放到正确的位上，需要维持底层数组的有序性质不变。
3. 将新元素添加到底层数组。

另外一提：**只支持升级操作，并不支持降级操作**。

## 2.6 压缩列表

压缩列表(ziplist)是list和hash的底层实现之一。如果list的每个都是小整数值，或者是比较短的字符串，压缩列表(ziplist)作为list的底层实现。

压缩列表(ziplist)是Redis为了节约内存而开发的，是由一系列的**特殊编码的连续内存块**组成的**顺序性**数据结构。

压缩列表结构图例如下：

![åç¼©åè¡¨çç»æé¨å](https://segmentfault.com/img/remote/1460000016837808)

下面我们看看节点的结构图：

![img](https://segmentfault.com/img/remote/1460000016837809)

压缩列表从表尾节点**倒序遍历**，首先指针通过zltail偏移量指向表尾节点，然后通过指向**节点记录的前一个节点的长度依次向前遍历访问整个压缩列表**。

# 3 Redis中数据结构的对象

![æ°æ®ç»æå¯¹åºçç±»åä¸ç¼ç ](https://segmentfault.com/img/remote/1460000016837798?w=1627&h=730)

## 3.1 字符串(stirng)

在上面的图我们知道string类型有三种**编码格式**：

- int：整数值，这个整数值可以使用long类型来表示（如果是浮点数，那就用embstr或者raw编码。具体用哪个就看这个数的长度了）
- embstr：字符串值，这个字符串值的长度小于39字节
- raw：字符串值，这个字符串值的长度大于39字节

embstr和raw的**区别**：

- raw分配内存和释放内存的次数是两次，embstr是一次
- embstr编码的数据保存在一块**连续**的内存里面

编码之间的**转换**：

- int类型如果存的**不再是一个整数值**，则会从int转成raw
- embstr是只读的，在修改的时候回从embstr转成raw

## 3.2 列表(list)

在上面的图我们知道list类型有两种**编码格式**：

- ziplist：字符串元素的长度都小于64个字节`&&`总数量少于512个
- linkedlist：字符串元素的长度大于64个字节`||`总数量大于512个

```c
redis > RPUSH numbers 1 "three" 5
(integer) 3 
```

ziplist编码的列表结构：

![ziplistçåè¡¨ç»æ](https://segmentfault.com/img/remote/1460000016837810)

linkedlist编码的列表结构：

![linkedlistç¼ç çåè¡¨ç»æ](https://segmentfault.com/img/remote/1460000016837811)

编码之间的**转换：**

- 原本是ziplist编码的，如果保存的数据长度太大或者元素数量过多，会转换成linkedlist编码的。

## 3.3 哈希(hash)

在上面的图我们知道hash类型有两种**编码格式**：

- ziplist：key和value的字符串长度都小于64字节`&&`键值对总数量小于512
- hashtable：key和value的字符串长度大于64字节`||`键值对总数量大于512

ziplist编码的哈希结构：

![ziplist编码的哈希结构1](https://segmentfault.com/img/remote/1460000016837812)
![ziplist编码的哈希结构2](https://segmentfault.com/img/remote/1460000016837813)

hashtable编码的哈希结构：

![hashtable编码的哈希结构](https://segmentfault.com/img/remote/1460000016837814)

编码之间的**转换：**

- 原本是ziplist编码的，如果保存的数据长度太大或者元素数量过多，会转换成hashtable编码的。

## 3.4 集合(set)

在上面的图我们知道set类型有两种**编码格式**：

- intset：保存的元素全都是整数`&&`总数量小于512
- hashtable：保存的元素不是整数`||`总数量大于512

intset编码的集合结构：

![intset编码的集合结构](https://segmentfault.com/img/remote/1460000016837815)

hashtable编码的集合结构：

![hashtable编码的集合结构](https://segmentfault.com/img/remote/1460000016837816)

编码之间的**转换：**

- 原本是intset编码的，如果保存的数据不是整数值或者元素数量大于512，会转换成hashtable编码的。

## 3.5 有序集合(sortset)

在上面的图我们知道set类型有两种**编码格式**：

- ziplist：元素长度小于64`&&`总数量小于128
- skiplist：元素长度大于64`||`总数量大于128

ziplist编码的有序集合结构：

![ziplist编码的有序集合结构1](https://segmentfault.com/img/remote/1460000016837817)

![ziplist编码的有序集合结构2](https://segmentfault.com/img/remote/1460000016837818)

skiplist编码的有序集合结构：

![skiplist编码的有序集合结构](https://segmentfault.com/img/remote/1460000016837819)

有序集合(sortset)对象**同时采用skiplist和哈希表来实现**：

- skiplist能够达到插入的时间复杂度为O(logn)，根据成员查分值的时间复杂度为O(1)

编码之间的**转换：**

- 原本是ziplist编码的，如果保存的数据长度大于64或者元素数量大于128，会转换成skiplist编码的。

## 3.6 Redis对象一些细节

- 服务器在执行某些命令的时候，会**先检查给定的键的类型**能否执行指定的命令。
  - 比如我们的数据结构是sortset，但你使用了list的命令。这是不对的，服务器会检查一下我们的数据结构是什么才会进一步执行命令
- Redis的对象系统带有**引用计数**实现的**内存回收机制**。
  - 对象不再被使用的时候，对象所占用的内存会释放掉
- Redis会共享值为0到9999的字符串对象
- 对象**会记录自己的最后一次被访问时间**，这个时间可以用于计算对象的空转时间。

至于我们在使用的时候挑选哪些数据结构作为存储，可以简单看看：

- string-->简单的`key-value`
- list-->有序列表(底层是双向链表)-->可做简单队列
- set-->无序列表(去重)-->提供一系列的交集、并集、差集的命令
- hash-->哈希表-->存储结构化数据
- sortset-->有序集合映射(member-score)-->排行榜

# 4 Redis服务器中的数据库

Redis服务器中也有数据库这么一个概念。如果不指定具体的数量，默认会有**16**个数据库，数据库与数据库之间的数据是**隔离**的。

## 4.1 Redis数据库的原理

Redis服务器用redisServer结构体来表示，其中redisDb是一个数组，用来保存所有的数据库，dbnum代表数据库的数量(这个可以配置，默认是16)

```c
struct redisServer{  
    //redisDb数组,表示服务器中所有的数据库
    redisDb *db;      
    //服务器中数据库的数量
    int dbnum;  
}; 
```

我们知道Redis是C/S结构，Redis客户端通过redisClient结构体来表示：

```c
typedef struct redisClient{   
    //客户端当前所选数据库
    redisDb *db;     
}redisClient;
```

Redis客户端连接Redis服务端时的示例图：

![Rediså®¢æ·ç«¯è¿æ¥Redisæå¡ç«¯æ¶çç¤ºä¾å¾](https://segmentfault.com/img/remote/1460000016951871?w=641&h=421)

Redis中对每个数据库用redisDb结构体来表示：

```c
typedef struct redisDb { 
    int id;         // 数据库ID标识
    dict *dict;     // 键空间，存放着所有的键值对              
    dict *expires;  // 过期哈希表，保存着键的过期时间                          
    dict *watched_keys; // 被watch命令监控的key和相应client    
    long long avg_ttl;  // 数据库内所有键的平均TTL（生存时间）     
} redisDb;
```

从代码上我们可以发现最重要的应该是`dict *dict`，它用来存放着所有的键值对。对于`dict`数据结构(哈希表)我们在上一篇也已经详细说了。一般我们将存储所有键值对的`dict`称为**键空间**。

键空间示意图：

![é®ç©ºé´ç¤ºæå¾](https://segmentfault.com/img/remote/1460000016951872?w=1066&h=665)

Redis的数据库就是使用字典(哈希表)来作为底层实现的，对**数据库的增删改查都是构建在字典(哈希表)的操作之上的**。

例如：

```c
redis > GET message
"hello world"
```

![æ¥æ¾é®çç¤ºæå¾](https://segmentfault.com/img/remote/1460000016951873?w=1067&h=628)

## 4.2 键的过期时间

Redis是基于内存，内存是比较昂贵的，容量肯定比不上硬盘的。就我们现在一台普通的机子，可能就8G内存，但硬盘随随便便都1T了。

因为我们的内存是**有限**的。所以我们**会干掉不常用的数据，保留常用的数据**。这就需要我们设置一下键的过期(生存)时间了。

- 设置键的**生存**时间可以通过`EXPIRE`或者`PEXPIRE`命令。
- 设置键的**过期**时间可以通过`EXPIREAT`或者`PEXPIREAT`命令。

其实`EXPIRE`、`PEXPIRE`、`EXPIREAT`这三个命令都是通过`PEXPIREAT`命令来实现的。

我们在redisDb结构体中还发现了`dict *expires;`属性，存放所有键过期的时间。

```c
// 设置了message键的过期时间为1391234400000
redis > PEXPIREAT message 1391234400000
(integer) 1
```

![æ°å¢ä¸ä¸ªè¿ææ¶é´çé®](https://segmentfault.com/img/remote/1460000016951874?w=887&h=620)

既然有设置过期(生存)时间的命令，那肯定也有移除过期时间，查看剩余生存时间的命令了：

- PERSIST(移除过期时间)
- TTL(Time To Live) 返回剩余生存时间，以秒为单位
- PTTL以毫秒为单位返回键的剩余生存时间

### 4.2.1 过期策略

上面我们已经能够了解到：过期键是保存在哈希表中了。那这些过期键到了过期的时间，就会立马被删除掉吗？？

要回答上面的问题，需要我们了解一下删除策略的知识，删除策略可分为三种：

- 定时删除(对内存友好，对CPU不友好)
  - 到时间点上就把所有过期的键删除了。
- 惰性删除(对CPU极度友好，对内存极度不友好)
  - 每次从键空间取键的时候，判断一下该键是否过期了，如果过期了就删除。
- 定期删除(折中)
  - **每隔**一段时间去删除过期键，**限制**删除的执行时长和频率。

Redis采用的是**惰性删除+定期删除**两种策略，所以说，在Redis里边如果过期键到了过期的时间了，未必被立马删除的！

### 4.2.2 内存淘汰机制

如果定期删除漏掉了很多过期key，也没及时去查(没走惰性删除)，大量过期key堆积在内存里，导致redis内存块耗尽了，咋整？

我们可以设置内存最大使用量，当内存使用量超出时，会施行**数据淘汰策略**。

Redis的内存淘汰机制有以下几种：

![åå­æ·æ±°æºå¶](https://segmentfault.com/img/remote/1460000016951875?w=728&h=318)

一般场景：

使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是**热点数据**。可以将内存最大使用量设置为热点数据占用的内存量，然后启用allkeys-lru淘汰策略，将最近最少使用的数据淘汰。

# 5 Redis持久化

Redis是基于内存的，如果不想办法将数据保存在硬盘上，一旦Redis重启(退出/故障)，内存的数据将会全部丢失。

我们肯定不想Redis里头的数据由于某些故障全部丢失(导致所有请求都走MySQL)，即便发生了故障也希望可以将Redis原有的数据恢复过来，这就是持久化的作用。

Redis提供了两种不同的持久化方法来讲数据存储到硬盘里边：

- RDB(基于快照)，将某一时刻的所有数据保存到一个RDB文件中。
- AOF(append-only-file)，当Redis服务器执行**写命令**的时候，将执行的**写命令**保存到AOF文件中。

## 5.1 RDB(快照持久化)

RDB持久化可以**手动**执行，也可以根据服务器配置**定期**执行。RDB持久化所生成的RDB文件是一个经过**压缩**的二进制文件，Redis可以通过这个文件**还原**数据库的数据。

![RDBæä»¶è¿åæ°æ®](https://segmentfault.com/img/remote/1460000016951876?w=1092&h=212)

有两个命令可以生成RDB文件：

- `SAVE`会**阻塞**Redis服务器进程，服务器不能接收任何请求，直到RDB文件创建完毕为止。
- `BGSAVE`创建出一个**子进程**，由子进程来负责创建RDB文件，服务器进程可以继续接收请求。

Redis服务器在启动的时候，如果发现有RDB文件，就会**自动**载入RDB文件(不需要人工干预)

- 服务器在载入RDB文件期间，会处于阻塞状态，直到载入工作完成。

除了手动调用`SAVE`或者`BGSAVE`命令生成RDB文件之外，我们可以使用配置的方式来**定期**执行：

在默认的配置下，如果以下的条件被触发，就会执行`BGSAVE`命令

```c
save 900 1           # 在900秒(15分钟)之后，至少有1个key发生变化，
save 300 10          # 在300秒(5分钟)之后，至少有10个key发生变化
save 60 10000        # 在60秒(1分钟)之后，至少有10000个key发生变化
```

原理大概就是这样子的(结合上面的配置来看)：

```c
struct redisServer{
    // 修改计数器
    long long dirty;
    // 上一次执行保存的时间
    time_t lastsave;
    // 参数的配置
    struct saveparam *saveparams;
};
```

遍历参数数组，判断修改次数和时间是否符合，如果符合则调用`besave()`来生成RDB文件

![Redisæå¡å¨çç¶æ](https://segmentfault.com/img/remote/1460000016951877?w=935&h=340)

总结：通过手动调用`SAVE`或者`BGSAVE`命令或者配置条件触发，将数据库**某一时刻**的数据快照，生成RDB文件实现持久化。

## 5.2 AOF(文件追加)

上面已经介绍了RDB持久化是通过将某一时刻数据库的数据“快照”来实现的，下面我们来看看AOF是怎么实现的。

- AOF是通过保存Redis服务器所执行的**写命令**来记录数据库的数据的。

![AOFåçå¾](https://segmentfault.com/img/remote/1460000016951878?w=648&h=218)

比如说我们对空白的数据库执行以下写命令：

```c
redis> SET meg "hello"
OK
redis> SADD fruits "apple" "banana" "cherry"
(integer) 3
redis> RPUSH numbers 128 256 512
(integer) 3 
```

Redis会产生以下内容的AOF文件：

![AOFæä»¶](https://segmentfault.com/img/remote/1460000016951879?w=1145&h=132)

这些都是以Redis的命令**请求协议格式**保存的。

AOF持久化功能的实现可以分为3个步骤：

- 命令追加：命令写入aof_buf缓冲区
- 文件写入：调用flushAppendOnlyFile函数，考虑是否要将aof_buf缓冲区写入AOF文件中
- 文件同步：考虑是否将内存缓冲区的数据真正写入到硬盘

![AOFæä¹åæ­¥éª¤](https://segmentfault.com/img/remote/1460000016951880?w=1129&h=491)

flushAppendOnlyFile函数的行为由服务器配置的**appendfsyn选项**来决定的：

```c
appendfsync always     # 每次有数据修改发生时都会写入AOF文件。
appendfsync everysec   # 每秒钟同步一次，该策略为AOF的默认策略。
appendfsync no         # 从不同步。高效但是数据不会被持久化。
```

下面来看一下AOF是如何载入与数据还原的：

- 创建一个**伪客户端**(本地)来执行AOF的命令，直到AOF命令被全部执行完毕。

![redisä¼ªå®¢æ·ç«¯è½½å¥AOFæä»¶](https://segmentfault.com/img/remote/1460000016951881?w=618&h=494)

### 5.2.1 AOF重写

从前面的示例看出，我们写了三条命令，AOF文件就保存了三条命令。如果我们的命令是这样子的：

```c
redis > RPUSH list "Java" "3y"
(integer)2
redis > RPUSH list "Java3y"
integer(3)
redis > RPUSH list "yyy"
integer(4)
```

同样地，AOF也会保存3条命令。我们会发现一个问题：上面的命令是可以**合并**起来成为1条命令的，并不需要3条。这样就可以**让AOF文件的体积变得更小**。

AOF重写由Redis自行触发(参数配置)，也可以用`BGREWRITEAOF`命令**手动触发**重写操作。

要值得说明的是：**AOF重写不需要对现有的AOF文件进行任何的读取、分析。AOF重写是通过读取服务器当前数据库的数据来实现的**！

比如说现在有一个Redis数据库的数据如下：

![Redisæ°æ®åºçæ°æ®](https://segmentfault.com/img/remote/1460000016951882?w=1087&h=587)

新的AOF文件的命令如下，**没有一条是多余的**！

![AOFéååçå½ä»¤](https://segmentfault.com/img/remote/1460000016951883?w=480&h=328)

### 5.2.2 AOF后台重写

Redis将AOF重写程序放到**子进程**里执行(`BGREWRITEAOF`命令)，像`BGSAVE`命令一样fork出一个子进程来完成重写AOF的操作，从而不会影响到主进程。

AOF后台重写是不会阻塞主进程接收请求的，新的写命令请求可能会导致**当前数据库和重写后的AOF文件的数据不一致**！

为了解决数据不一致的问题，Redis服务器设置了一个**AOF重写缓冲区**，这个缓存区会在服务器**创建出子进程之后使用**。

![AOFåå°éåè¿ç¨](https://segmentfault.com/img/remote/1460000016951884?w=1342&h=955)

## 5.3 RDB和AOF对过期键的策略

RDB持久化对过期键的策略：

- 执行`SAVE`或者`BGSAVE`命令创建出的RDB文件，程序会对数据库中的过期键检查，**已过期的键不会保存在RDB文件中**。
- 载入RDB文件时，程序同样会对RDB文件中的键进行检查，**过期的键会被忽略**。

AOF持久化对过期键的策略：

- 如果数据库的键已过期，但还没被惰性/定期删除，AOF文件不会因为这个过期键产生任何影响(也就说会保留)，当过期的键被删除了以后，会追加一条DEL命令来显示记录该键被删除了
- 重写AOF文件时，程序会对RDB文件中的键进行检查，**过期的键会被忽略**。

复制模式：

- **主服务器来控制**从服务器统一删除过期键(保证主从服务器数据的一致性)

## 5.4 RDB和AOF用哪个？

RDB和AOF并不互斥，它俩可以**同时使用**。

- RDB的优点：载入时**恢复数据快**、文件体积小。
- RDB的缺点：会一定程度上**丢失数据**(因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。)
- AOF的优点：丢失数据少(默认配置只丢失一秒的数据)。
- AOF的缺点：恢复数据相对较慢，文件体积大

如果Redis服务器**同时开启**了RDB和AOF持久化，服务器会**优先使用AOF文件**来还原数据(因为AOF更新频率比RDB更新频率要高，还原的数据更完善)

# 6 基础铺垫

## 6.1 网络编程

网络编程可简单分为TCP和UPD两种，一般我们更多关注的是TCP。TCP网络编程在Java中封装成Socket和SocketServer，我们来回顾一下最简单的TCP网络编程吧：

TCP客户端

```java
public class ClientDemo {
    public static void main(String[] args) throws IOException {
        //创建发送端的Socket对象
        Socket s = new Socket("192.168.1.106",8888);
        
        //Socket对象可以获取输出流
        OutputStream os = s.getOutputStream();
        os.write("hello,tcp,我来了".getBytes());

        s.close();
    }
}
```

TCP服务端：

```java
public class ServerDemo {
    public static void main(String[] args) throws IOException {
        //创建接收端的Socket对象
        ServerSocket ss = new ServerSocket(8888);

        //监听客户端连接，返回一个对应的Socket对象
        //侦听并接受到此套接字的连接，此方法会阻塞
        Socket s = ss.accept();

        //获取输入流，读取数据
        InputStream is = s.getInputStream();

        byte[] bys = new byte[1024];
        int len = is.read(bys);
        String str = new String (bys,0,len);

        String ip = s.getInetAddress().getHostAddress();
        System.out.println(ip + "    ---" +str);

        //释放资源
        s.close();
    }
}
```

上面的代码就可以实现：**客户端向服务器发送数据，服务端能够接收客户端发送过来的数据**。

## 6.2 IO多路复用

Java的NIO也是基于IO多路复用模型的：

- I/O多路复用的特点是通过一种机制**一个进程能同时等待多个文件描述符**，而这些文件描述符其中的任意一个进入**读就绪状态、等等**，`select()`函数就可以返回。
- select/epoll的优势并不是对于单个连接能处理得更快，而是**在于能处理更多的连接**。

说白了，使用IO多路复用机制的，一般自己会有一套**事件机制**，使用**一个**线程或者进程监听这些事件，如果这些事件被触发了，则调用对应的函数来处理。

# 7 Redis事件

Redis服务器是一个**事件驱动程序**，主要处理以下两类事件：

- 文件事件：文件事件其实就是**对Socket操作的抽象**，Redis服务器与Redis客户端的通信会产生文件事件，服务器通过监听并处理这些事件来完成一系列的网络操作
- 时间事件：时间事件其实就是对**定时操作的抽象**，前面我们已经讲了RDB、AOF、定时删除键这些操作都可以由服务端去定时或者周期去完成，底层就是通过触发时间事件来实现的！

## 7.1 文件事件

Redis开发了自己的网络事件处理器，这个处理器被称为**文件事件处理器**。

文件事件处理器由四部分组成：

![æä»¶äºä»¶å¤çå¨ç»æ](https://segmentfault.com/img/remote/1460000016964514?w=1208&h=552)

文件事件处理器使用I/O多路复用程序来**同时监听多个Socket**。当被监听的Socket准备好执行连接应答(accept)、读取(read)等等操作时，与操作相对应的文件事件就会产生，根据文件事件来为Socket关联对应的事件处理器，从而实现功能。

要值得注意的是：Redis中的I/O多路复用程序会将所有**产生事件的Socket放到一个队列**里边，然后通过这个队列以有序、同步、每次一个Socket的方式向文件事件分派器传送套接字。也就是说：当上一个Socket处理完毕后，I/O多路复用程序才会向文件事件分派器传送下一个Socket。

首先，IO多路复用程序首先会监听着Socket的`AE_READABLE`事件，该事件对应着**连接应答处理器**。

- 可以简单理解成`SocketServet.accpet()`

![çå¬çSocketçAE_READABLEäºä»¶](https://segmentfault.com/img/remote/1460000016964515)

此时，一个名字叫做3y的Socket要连接服务器啦。服务器会用**连接应答处理器**处理。创建出客户端的Socket，并将客户端的Socket与命令请求处理器进行关联，使得客户端可以向服务器发送命令请求。

- 相当于`Socket s = ss.accept();`，创建出客户端的Socket，然后将该Socket关联**命令请求处理器**
- 此时客户端就可以向主服务器发送命令请求了

![å®¢æ·ç«¯è¯·æ±è¿æ¥ï¼æå¡å¨åå»ºåºå®¢æ·ç«¯Scoketï¼å³èå½ä»¤è¯·æ±å¤çå¨](https://segmentfault.com/img/remote/1460000016964516?w=1761&h=585)

假设现在客户端发送一个命令请求`set Java3y "关注、点赞、评论" `，客户端Socket将产生`AE_READABLE`事件，**引发命令请求处理器执行**。处理器读取客户端的命令内容，然后传给对应的程序去执行。

客户端发送完命令请求后，**服务端总得给客户端回应的**。此时服务端会将客户端的Scoket的`AE_WRITABLE`事件与命令回复处理器关联。

![å®¢æ·ç«¯çScoketçAE_WRITABLEäºä»¶ä¸å½ä»¤åå¤å¤çå¨å³è](https://segmentfault.com/img/remote/1460000016964517)

最后客户端尝试读取命令回复时，客户端Socket**产生**AE_WRITABLE事件，触发命令回复处理器执行。当把所有的回复数据写入到Socket之后，服务器就会**解除**客户端Socket的AE_WRITABLE事件与命令回复处理器的关联。

![Redisäºä»¶äº¤äºè¿ç¨](https://segmentfault.com/img/remote/1460000016964518?w=539&h=424)

## 7.2 时间事件

持续运行的Redis服务器会**定期**对自身的资源和状态进行检查和调整，这些定期的操作由**serverCron**函数负责执行，它的主要工作包括：

- 更新服务器的统计信息(时间、内存占用、数据库占用)
- 清理数据库的过期键值对
- AOF、RDB持久化
- 如果是主从服务器，对从服务器进行定期同步
- 如果是集群模式，对集群进行定期同步和连接

Redis服务器将时间事件放在一个**链表**中，当时间事件执行器运行时，会遍历整个链表。时间事件包括：

- **周期性事件**(Redis一般只执行serverCron时间事件，serverCron时间事件是周期性的)
- 定时事件

## 7.3 时间事件和文件事件

- 文件事件和时间事件之间是**合作**关系，服务器会轮流**处理**这两种事件，并且处理事件的过程中不会发生抢占。
- 时间事件的实际处理事件通常会比设定的到达时间**晚**一些

# 8 Redis单线程为什么快？

1. 纯内存操作
2. 核心是基于非阻塞的IO多路复用机制
3. 单线程避免了多线程的频繁上下文切换问题

# 9 客户端与服务器

服务器使用clints**链表**连接多个客户端状态，新添加的客户端状态会被放到链表的末尾

![å®¢æ·ç«¯--é¾è¡¨](https://segmentfault.com/img/remote/1460000016964519)

- 一个服务器可以与多个客户端建立网络连接，每个**客户端可以向服务器发送命令请求**，而服务器则接收并处理客户端发送的命令请求，并向客户端返回命令回复。
- Redis服务器使用**单线程单进程**的方式处理命令请求。在数据库中保存**客户端执行命令所产生的数据**，并通过**资源管理来维持**服务器自身的运转。

## 9.1 客户端

**Redis客户端的属性**(客户端状态、输入/输出缓冲区、命令参数、命令函数等等)

```c
typedef struct redisClient{ 
    //客户端状态的输入缓冲区用于保存客户端发送的命令请求,最大1GB,否则服务器将关闭这个客户端
    sds querybuf;   
    //负责记录argv数组的长度。
    int argc;   
    // 命令的参数
    robj **argv;  
    // 客户端要执行命令的实现函数
    struct redisCommand *cmd, *lastcmd;  
    //记录了客户端的角色(role),以及客户端所处的状态。 (REDIS_SLAVE | REDIS_MONITOR | REDIS_MULTI) 
    int flags;             
    //记录客户端是否通过了身份验证
    int authenticated;       
    //时间相关的属性
    time_t ctime;           /* Client creation time */       
    time_t lastinteraction; /* time of the last interaction, used for timeout */
    time_t obuf_soft_limit_reached_time;        
    //固定大小的缓冲区用于保存那些长度比较小的回复
    /* Response buffer */
    int bufpos;
    char buf[REDIS_REPLY_CHUNK_BYTES];   
    //可变大小的缓冲区用于保存那些长度比较大的回复
    list *reply; //可变大小缓冲区由reply 链表和一个或多个字符串对象组成
    //...
}
```

## 9.2 服务端

**服务器章节**中主要讲解Redis服务器读取客户端发送过来的命令是如何解析，以及初始化的过程。

服务器从启动到能够处理客户端的命令请求需要执行以下的步骤：

- 初始化服务器状态
- 载入服务器配置
- 初始化服务器的数据结构
- 还原数据库状态
- 执行事件循环

```python
def main():
    init_server();
    while server_is_not_shutdown();
        aeProcessEvents()
    clean_server();
```

从客户端发送命令到完成主要包括的步骤：

- 客户端将命令请求发送给服务器
- 服务器读取命令请求，分析出**命令参数**
- 命令执行器根据参数**查找命令的实现函数**，执行实现函数并得出命令回复
- 服务器将命令回复返回给客户端

# 10 主从架构

## 10.1 为什么要主从架构

Redis也跟关系型数据(MySQL)一样，如果有过多请求还是撑不住的。

因为Redis如果只有一台服务器的话，那随着请求越来越多：

- **Redis的内存是有限的**，可能放不下那么多的数据
- 单台Redis**支持的并发量也是有限的**。
- **万一这台Redis挂了**，所有的请求全走关系数据库了，那就更炸了。

显然，出现的上述问题是因为一台Redis服务器不够，所以多搞几台Redis服务器就可以了

为了实现我们服务的**高可用性**，可以将这几台Redis服务器做成是**主从**来进行管理

![ä¸»ä»æ¶æ](https://segmentfault.com/img/remote/1460000017170695)

## 10.2 主从架构的特点

下面我们来看看Redis的主从架构特点：

- **主**服务器负责接收**写**请求
- **从**服务器负责接收**读**请求
- 从服务器的数据由主服务器**复制**过去。主从服务器的数据是**一致**的

![ä¸»ä»æ¶æç¹ç¹](https://segmentfault.com/img/remote/1460000017170696)

主从架构的**好处**：

- 读写分离(主服务器负责写，从服务器负责读)
- 高可用(某一台从服务器挂了，其他从服务器还能继续接收请求，不影响服务)
- 处理更多的并发量(每台从服务器**都可以接收读请求**，读QPS就上去了)

主从架构除了上面的形式，也有下面这种的(只不过用得比较少)：

![ä»æå¡å¨åæçä»æå¡å¨](https://segmentfault.com/img/remote/1460000017170697)

# 11 复制功能

主从架构的特点之一：主服务器和从服务器的数据是**一致**的。

因为主服务器是能接收写请求的，主服务器处理完写请求，会做什么来保证主从数据的一致性呢？如果主从服务器断开了，过一阵子才重连，又会怎么处理呢？下面将会了解到这些细节~

在Redis中，用户可以通过执行SALVEOF命令或者设置salveof选项，让一个服务器去复制(replicate)另一个服务器，我们称呼被复制的服务器为主服务器(master)，而对主服务器进行复制的服务器则被称为从服务器(salve)



复制功能分为两个操作：

- 同步(sync)：将从服务器的数据库状态**更新至**主服务器的数据库状态
- 命令传播(command propagate)：主服务器的数据库状态**被修改**，导致主从服务器的数据库状态**不一致**，让主从服务器的数据库状态**重新回到一致状态**。

![ä¸»ä»æ°æ®ä¸è´æ§](https://segmentfault.com/img/remote/1460000017170699)

从服务器对主服务器的**同步又可以分为两种情况**：

- 初次同步：从服务器**没有复制过任何**的主服务器，或者从服务器要复制的主服务器跟上次复制的主服务器**不一样**。
- 断线后同步：处于**命令传播阶段**的主从服务器因为**网络原因**中断了复制，从服务器通过**自动重连**重新连接主服务器，并继续复制主服务器

在Redis2.8以前，断线后复制这部分其实缺少的只是**部分的数据**，但是要让主从服务器**重新执行SYNC命令**，这样的做法是非常低效的。(因为执行SYNC命令是把**所有的数据**再次同步，而不是只同步丢失的数据)

接下来我们来详细看看Redis2.8以后复制功能是怎么实现的：

## 11.1 复制的前置工作

首先我们来看一下**前置的工作**：

- 从服务器设置主服务器的IP和端口
- 建立与主服务器的Socket连接
- 发送PING命令(检测Socket读写是否正常与主服务器的通信状况)
- 身份验证(看有没有设置对应的验证配置)
- 从服务器给主服务器发送端口的信息，主服务器记录监听的端口

![Rediså¤å¶çåç½®å·¥ä½](https://segmentfault.com/img/remote/1460000017170700)

Redis从2.8版本开始，使用PSYNC命令来**替代**SYNC命令执行复制时同步的操作。

PSYNC命令具有**完整**重同步和**部分**重同步两种模式(其实就跟上面所说的初次复制和断线后复制差不多个意思)。

## 11.2 完整重同步

下面先来看看**完整**重同步是怎么实现的：

- 从服务器向主服务器发送PSYNC命令
- 收到PSYNC命令的主服务器执行BGSAVE命令，在后台**生成一个RDB文件**。并用一个**缓冲区**来记录从现在开始执行的所有**写命令**。
- 当主服务器的BGSAVE命令执行完后，将生成的RDB文件发送给从服务器，**从服务器接收和载入RBD文件**。将自己的数据库状态更新至与主服务器执行BGSAVE命令时的状态。
- 主服务器将所有缓冲区的**写命令发送给从服务器**，从服务器执行这些写命令，达到数据最终一致性。

![å®æ´éåæ­¥](https://segmentfault.com/img/remote/1460000017170701)

## 11.2 部分重同步

接下来我们来看看**部分**重同步，部分重同步可以让我们断线后重连**只需要同步缺失的数据**(而不是Redis2.8之前的同步全部数据)，这是符合逻辑的！

部分重同步功能由以下部分组成：

- 主从服务器的**复制偏移量**
- 主服务器的**复制积压缓冲区**
- 服务器运行的ID(**run ID**)

首先我们来解释一下上面的名词：

复制偏移量：执行复制的双方都会**分别维护**一个复制偏移量

- 主服务器每次传播N个字节，就将自己的复制偏移量加上N
- 从服务器每次收到主服务器的N个字节，就将自己的复制偏移量加上N

通过**对比主从复制的偏移量**，就很容易知道主从服务器的数据是否处于一致性的状态！

![å¤å¶åç§»é](https://segmentfault.com/img/remote/1460000017170702)

那断线重连以后，从服务器向主服务器发送PSYNC命令，报告现在的偏移量是36，那么主服务器该对从服务器执行完整重同步还是部分重同步呢？？这就交由**复制积压缓冲区**来决定。

当主服务器进行命令传播时，不仅仅会将写命令发送给所有的从服务器，还会将写命令**入队到复制积压缓冲区**里面(这个大小可以调的)。如果复制积压缓冲区**存在**丢失的偏移量的数据，那就执行部分重同步，否则执行完整重同步。

服务器运行的ID(**run ID**)实际上就是用来比对ID是否相同。如果不相同，则说明从服务器断线之前复制的主服务器和当前连接的主服务器是两台服务器，这就会进行完整重同步。

![åæ­¥çæµç¨](https://segmentfault.com/img/remote/1460000017170703?w=1093&h=829)

## 11.3 命令传播

当完成了同步之后，主从服务器就会进入命令传播阶段。这时主服务器只要将自己的写命令发送给从服务器，而从服务器接收并执行主服务器发送过来的写命令，就可以保证主从服务器一直保持数据一致了！

在命令传播阶段，从服务器默认会以每秒一次的频率，向服务器发送命令`REPLCONF ACK <replication_offset>` 其中replication_offset是从服务器当前的复制偏移量

发送这个命令主要有三个作用：

- **检测主从服务器的网络状态**
- 辅助实现min-slaves选项
- 检测命令丢失

# 12 哨兵机制

如果从服务器挂了，没关系，我们一般会有多个从服务器，其他的请求可以交由没有挂的从服务器继续处理。如果主服务器挂了，怎么办？因为我们的写请求由主服务器处理，只有一台主服务器，那就无法处理写请求了？

Redis提供了**哨兵(Sentinal)机制**供我们解决上面的情况。如果主服务器挂了，我们可以将从服务器**升级**为主服务器，等到旧的主服务器(挂掉的那个)重连上来，会将它(挂掉的主服务器)变成从服务器。这个过程叫做**主备切换**(故障转移)

在正常的情况下，主从加哨兵(Sentinal)机制是这样子的：

![æ­£å¸¸æåµä¸](https://segmentfault.com/img/remote/1460000017250993)

主服务器挂了，主从复制操作就中止了，并且哨兵系统是可以察觉出主服务挂了。：

![Sentinelå¯ä»¥å¯è§ä¸»æå¡æçº¿ï¼å¤å¶æä½ä¸­æ­¢ã](https://segmentfault.com/img/remote/1460000017250994?w=1247&h=658)

Redis提供哨兵机制可以将**选举**一台从服务器变成主服务器

![éä¸¾ä¸å°ä»æå¡å¨åæä¸»æå¡å¨](https://segmentfault.com/img/remote/1460000017250995?w=1369&h=721)

然后旧的主服务器如果重连了，会变成从服务器：

![æ§çä¸»æå¡å¨å¦æéè¿äºï¼ä¼åæä»æå¡å¨](https://segmentfault.com/img/remote/1460000017250996?w=1467&h=713)

哨兵(Sentinal)机制主要用于实现Redis的**高可用性**，主要的功能如下：

- Sentinel**不停地监控**Redis主从服务器是否正常工作

- 如果某个Redis实例有故障，那么哨兵负责**发送消息通知**管理员

- 如果主服务器挂掉了，会**自动**将从服务器提升为主服务器(包括配置都会修改)。

- Sentinel可以作为**配置中心**，能够提供当前主服务器的信息。

下面来具体讲讲Sentinel是如何将从服务器提升为主服务器的。

## 12.1 启动和初始化Sentinel

首先我们要知道的是：Sentinel本质上只是一个**运行在特殊模式下的Redis服务器**。因为Sentinel做的事情和Redis服务器是不一样的，所以它们的初始化是有所区别的(比如，Sentinel在初始化的时候并不会载入AOF/RDB文件，因为Sentinel根本就不用数据库)。

然后，在启动的时候会将普通Redis服务器的代码替换成**Sentinel专用代码**。(所以Sentinel虽然作为Redis服务器，但是它不能执行SET、DBSIZE等等命令，因为命令表的代码被替换了)

接着，初始化Sentinel的状态，并根据给定的配置文件**初始化**Sentinel监视的**主服务器列表**。

![åå§å](https://segmentfault.com/img/remote/1460000017250997?w=1304&h=712)

最后，Sentinel会创建两个**连向主服务器的网络连接**：

- 命令连接(发送和接收命令)
- 订阅连接(订阅主服务器的`_sentinel_:hello`频道)

![åå»ºç½ç»è¿æ¥](https://segmentfault.com/img/remote/1460000017250998)

## 12.2 获取和更新信息

Sentinel通过主服务器发送INFO命令来获得主服务器属下所有从服务器的地址信息，并为这些从服务器创建相应的实例结构。

![æ´æ°å®ä¾ç»æ](https://segmentfault.com/img/remote/1460000017250999)

当发现有**新的从服务器出现时**，除了创建对应的从服务器实例结构，Sentinel还会创建命令连接和订阅连接。

![åå»ºè¿æ¥](https://segmentfault.com/img/remote/1460000017251000?w=581&h=462)

在Sentinel运行的过程中，通过命令连接会以每两秒一次的频率向**监视的主从服务器**的`_sentinel_:hello频道`发送命令(主要发送Sentinel本身的信息，监听主从服务器的信息)，并通过订阅连接接收`_sentinel_:hello频道`的信息。这样一来一回，我们就可以**更新每个Sentinel实例结构的信息**。

## 12.3 判断主服务器是否下线了

判断主服务器是否下线有两种情况：

- 主观下线
  - Sentinel会以每秒一次的频率向与它创建命令连接的实例(包括主从服务器和其他的Sentinel)**发送PING命令**，通过PING命令返回的信息判断实例是否在线
  - 如果一个**主服务器**在`down-after-milliseconds`毫秒内连续向Sentinel发送**无效回复**，那么当前Sentinel就会**主观认为**该主服务器已经下线了。
- 客观下线
  - 当Sentinel将一个主服务器判断为主观下线以后，为了确认该主服务器是否真的下线，它会向同样监视该主服务器的Sentinel**询问**，看它们是否也认为该主服务器是否下线。
  - 如果**足够多**的Sentinel认为该主服务器是下线的，那么就判定该主服务为客观下线，并对主服务器执行故障转移操作。

在多少毫秒内无效回复才认定主服务器是主观下线的，以及有多少个Sentinel认为主服务器是下线才认定为客观下线。这都是**可以配置**的

## 12.4 选举领头Sentinel和故障转移

当一个主服务器认为为客观下线以后，监视这个下线的主服务器的各种Sentinel会进行协商，**选举出一个领头的Sentinel**，领头的Sentinel会对下线的主服务器执行故障转移操作。

选举领头Sentinel的规则也比较多，总的来说就是**先到先得**(哪个快，就选哪个)

选举出领头的Sentinel之后，领头的Sentinel会对已下线的主服务器执行故障转移操作，包括三个步骤：

- 在已下线主服务器**属下的从服务器中**，挑选一个转换为主服务器
- 让已下线主服务器属下的所有从服务器改为**复制新的主服务器**
- 已下线的主服务器**重新连接时**，让他成为新的主服务器的从服务器

挑选某一个从服务器作为主服务器也是有**策略**的，大概如下：

1. 跟master断开连接的时长
2. slave优先级
3. 复制offset
4. run id

## 12.5 Redis还是会**丢失数据**的

丢失数据有两种情况：

- 异步复制导致的数据丢失
  - **有部分数据还没复制到从服务器，主服务器就宕机了**，此时这些部分数据就丢失了
- 脑裂导致的数据丢失
  - 有时候主服务器脱离了正常网络，跟其他从服务器不能连接。此时哨兵可能就会**认为主服务器下线了**(然后开启选举，将某个从服务器切换成了主服务器)，但是实际上主服务器还运行着。这个时候，集群里就会有两个服务器(也就是所谓的脑裂)。
  - 虽然某个从服务器被切换成了主服务器，但是可能客户端**还没来得及切换到新的主服务器**，客户端还继续写向旧主服务器写数据。旧的服务器重新连接时，会作为从服务器复制新的主服务器(这意味着旧数据丢失)。

可以通过以下两个配置**尽量**减少数据丢失的可能：

```java
min-slaves-to-write 1
min-slaves-max-lag 10
```

# 13 缓存雪崩

## 13.1 什么是缓存雪崩？

**如果我们的缓存挂掉了，这意味着我们的全部请求都跑去数据库了**。

![å¦æç¼å­ææäºï¼å¨é¨è¯·æ±è·å»æ°æ®åºäº](https://segmentfault.com/img/remote/1460000017882768)

在前面学习我们都知道Redis不可能把所有的数据都缓存起来(**内存昂贵且有限**)，所以Redis需要对数据设置过期时间，并采用的是惰性删除+定期删除两种策略对过期键删除。

如果缓存数据**设置的过期时间是相同**的，并且Redis恰好将这部分数据全部删光了。这就会导致在这段时间内，这些缓存**同时失效**，全部请求到数据库中。

**这就是缓存雪崩**：

- Redis挂掉了，请求全部走数据库。
- 对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。

缓存雪崩如果发生了，很可能就把我们的数据库**搞垮**，导致整个服务瘫痪！

## 13.2 如何解决缓存雪崩？

对于“对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。”这种情况，非常好解决：

- 解决方法：在缓存的时候给过期时间加上一个**随机值**，这样就会大幅度的**减少缓存在同一时间过期**。

对于“Redis挂掉了，请求全部走数据库”这种情况，我们可以有以下的思路：

- 事发前：实现Redis的**高可用**(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。
- 事发中：万一Redis真的挂了，我们可以设置**本地缓存(ehcache)+限流(hystrix)**，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)
- 事发后：redis持久化，重启后自动从磁盘上加载数据，**快速恢复缓存数据**。

# 14 缓存穿透

## 14.1 什么是缓存穿透

比如，我们有一张数据库表，ID都是从1开始的(**正数**)：

但是可能有黑客想把我的数据库搞垮，每次请求的ID都是**负数**。这会导致我的缓存就没用了，请求全部都找数据库去了，但数据库也没有这个值啊，所以每次都返回空出去。

缓存穿透是指查询一个一定**不存在的数据**。由于缓存不命中，并且出于容错考虑，如果从**数据库查不到数据则不写入缓存**，这将导致这个不存在的数据**每次请求都要到数据库去查询**，失去了缓存的意义。

![ç¼å­ç©¿é](https://segmentfault.com/img/remote/1460000017882770)

**这就是缓存穿透**：

- 请求的数据在缓存大量不命中，导致请求走数据库。

缓存穿透如果发生了，也可能把我们的数据库**搞垮**，导致整个服务瘫痪！

## 14.2 如何解决缓存穿透？

解决缓存穿透也有两种方案：

- 由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用布隆过滤器(BloomFilter)或者压缩filter**提前拦截**，不合法就不让这个请求到数据库层！
- 当我们从数据库找不到的时候，我们也将这个**空对象设置到缓存里边去**。下次再请求的时候，就可以从缓存里边获取了。
  - 这种情况我们一般会将空对象设置一个**较短的过期时间**。

# 15 缓存与数据库双写一致

## 15.1 对于读操作，流程是这样的

上面讲缓存穿透的时候也提到了：如果从数据库查不到数据则不写入缓存。

一般我们对**读操作**的时候有这么一个**固定的套路**：

- 如果我们的数据在缓存里边有，那么就直接取缓存的。
- 如果缓存里没有我们想要的数据，我们会先去查询数据库，然后**将数据库查出来的数据写到缓存中**。
- 最后将数据返回给请求

## 15.2 什么是缓存与数据库双写一致问题？

如果仅仅查询的话，缓存的数据和数据库的数据是没问题的。但是，当我们要**更新**时候呢？各种情况很可能就**造成数据库和缓存的数据不一致**了。

- 这里不一致指的是：**数据库的数据跟缓存的数据不一致**

![æ°æ®åºåç¼å­çæ°æ®ä¸ä¸è´](https://segmentfault.com/img/remote/1460000017882771)

从理论上说，只要我们设置了**键的过期时间**，我们就能保证缓存和数据库的数据**最终是一致**的。因为只要缓存数据过期了，就会被删除。随后读的时候，因为缓存里没有，就可以查数据库的数据，然后将数据库查出来的数据写入到缓存中。

除了设置过期时间，我们还需要做更多的措施来**尽量避免**数据库与缓存处于不一致的情况发生。

## 15.3 对于更新操作

一般来说，执行更新操作时，我们会有两种选择：

- 先操作数据库，再操作缓存
- 先操作缓存，再操作数据库

首先，要明确的是，无论我们选择哪个，我们都希望这**两个操作要么同时成功，要么同时失败**。所以，这会演变成一个**分布式事务**的问题。

所以，**如果原子性被破坏了**，可能会有以下的情况：

- **操作数据库成功了，操作缓存失败了**。
- **操作缓存成功了，操作数据库失败了**。

如果第一步已经失败了，我们直接返回Exception出去就好了，第二步根本不会执行。

### 15.3.1 操作缓存

操作缓存也有两种方案：

- 更新缓存
- 删除缓存

一般我们都是采取**删除缓存**缓存策略的，原因如下：

1. 高并发环境下，无论是先操作数据库还是后操作数据库而言，如果加上更新缓存，那就**更加容易**导致数据库与缓存数据不一致问题。(删除缓存**直接和简单**很多)
2. 如果每次更新了数据库，都要更新缓存【这里指的是频繁更新的场景，这会耗费一定的性能】，倒不如直接删除掉。等再次读取时，缓存里没有，那我到数据库找，在数据库找到再写到缓存里边(体现**懒加载**)

基于这两点，对于缓存在更新时而言，都是建议执行**删除**操作！

### 15.3.2 先更新数据库，再删除缓存

正常的情况是这样的：

- 先操作数据库，成功；
- 再删除缓存，也成功；

如果原子性被破坏了：

- 第一步成功(操作数据库)，第二步失败(删除缓存)，会导致**数据库里是新数据，而缓存里是旧数据**。
- 如果第一步(操作数据库)就失败了，我们可以直接返回错误(Exception)，不会出现数据不一致。

如果在高并发的场景下，出现数据库与缓存数据不一致的**概率特别低**，也不是没有：

- 缓存**刚好**失效
- 线程A查询数据库，得一个旧值
- 线程B将新值写入数据库
- 线程B删除缓存
- 线程A将查到的旧值写入缓存

要达成上述情况，还是说一句**概率特别低**：

因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，**而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存**，所有的这些条件都具备的概率基本并不大。

对于这种策略，其实是一种设计模式：`Cache Aside Pattern`

![åä¿®æ¹æ°æ®åºï¼åå é¤ç¼å­](https://segmentfault.com/img/remote/1460000017882772)

**删除缓存失败的解决思路**：

- 将需要删除的key发送到消息队列中
- 自己消费消息，获得需要删除的key
- **不断重试删除操作，直到成功**

### 15.3.3 先删除缓存，再更新数据库

正常情况是这样的：

- 先删除缓存，成功；
- 再更新数据库，也成功；

如果原子性被破坏了：

- 第一步成功(删除缓存)，第二步失败(更新数据库)，数据库和缓存的数据还是一致的。
- 如果第一步(删除缓存)就失败了，我们可以直接返回错误(Exception)，数据库和缓存的数据还是一致的。

看起来是很美好，但是我们在并发场景下分析一下，就知道还是有问题的了：

- 线程A删除了缓存
- 线程B查询，发现缓存已不存在
- 线程B去数据库查询得到旧值
- 线程B将旧值写入缓存
- 线程A将新值写入数据库

所以也会导致数据库和缓存不一致的问题。

**并发下解决数据库与缓存不一致的思路**：

- 将删除缓存、修改数据库、读取缓存等的操作积压到**队列**里边，实现**串行化**。

![å°æä½ç§¯åå°éåä¸­](https://segmentfault.com/img/remote/1460000017882773)

## 15.4 对比两种策略

我们可以发现，两种策略各自有优缺点：

- 先删除缓存，再更新数据库
  - 在高并发下表现不如意，在原子性被破坏时表现优异
- 先更新数据库，再删除缓存(`Cache Aside Pattern`设计模式)
  - 在高并发下表现优异，在原子性被破坏时表现不如意